<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>toyvmm book (en)</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded "><a href="quickstart.html">QuickStart</a></li><li class="chapter-item expanded "><a href="01_running_tiny_code_in_vm.html">Running Tiny Code in VM</a></li><li class="chapter-item expanded "><a href="02_load_linux_kernel.html">Load Linux Kernel</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="02-1_overview_of_booting_linux.html">02-1. Overview of Booting Linux</a></li><li class="chapter-item expanded "><a href="02-2_elf_binary_format_and_vmlinux_structure.html">02-2. ELF binary format and vmlinux structure</a></li><li class="chapter-item expanded "><a href="02-3_load_initrd.html">02-3. Load initrd</a></li><li class="chapter-item expanded "><a href="02-4_setup_registers_of_vcpu.html">02-4. Setup registers of vcpu</a></li><li class="chapter-item expanded "><a href="02-5_serial_console_implementation.html">02-5. Serial Console implementation</a></li><li class="chapter-item expanded "><a href="02-6_toyvmm_implementation.html">02-6. ToyVMM implementation</a></li></ol></li><li class="chapter-item expanded "><a href="03_virtio.html">Virtio</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="03-1_virtio.html">03-1. Virtio</a></li><li class="chapter-item expanded "><a href="03-2_implement_virtio_in_toyvmm.html">03-2. Implement virtio in ToyVMM</a></li><li class="chapter-item expanded "><a href="03-3_virtio-net.html">03-3. Implement virtio-net device</a></li><li class="chapter-item expanded "><a href="03-4_virtio-blk.html">03-4. Implement virtio-blk device</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">toyvmm book (en)</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        <a href="https://github.com/aztecher/toyvmm" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                                                
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<h2 id="what-is-toyvmm"><a class="header" href="#what-is-toyvmm">What is ToyVMM?</a></h2>
<p>ToyVMM is a project being developed for the purpose of learning virtualization technology.
ToyVMM aims to accomplish the following</p>
<p>Code-based understanding of KVM-based virtualization technologies
Learn about the modern virtualization technology stack by using libraries managed by rust-vmm
The rust-vmm libraries are also used as a base for well-known OSS such as firecracker and provides the functionality needed to create custom VMMs.</p>
<h2 id="disclaimer"><a class="header" href="#disclaimer">Disclaimer</a></h2>
<p>While every effort has been made to provide correct information in this publication, the authors do not necessarily guarantee that all information is accurate.
Therefore, the authors cannot be held responsible for the results of development, prototyping, or operation based on this information.
If you find any errors in the contents of this document, please correct or report them as PR or Issue.</p>
<h2 id="whats-next"><a class="header" href="#whats-next">What's Next?</a></h2>
<p>If you would like to try ToyVMM first, please refer to <a href="./quickstart.html">QuickStart</a>.
To learn more about KVM-based virtualization through ToyVMM, please refer to <a href="./01_running_tiny_code_in_vm.html">01. Running Tiny Code in VM</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quickstart"><a class="header" href="#quickstart">QuickStart</a></h1>
<p>This quickstart documents are based on the commit ID of <code>58cf0f68a561ee34a28ae4e73481f397f2690b51</code>.</p>
<h3 id="architecture--os"><a class="header" href="#architecture--os">Architecture &amp; OS</a></h3>
<p>ToyVMM only supports <strong>x86_64</strong> Linux for Guest OS.<br />
ToyVMM has been confirmed to work with Rocky Linux 8.6, 9.1 and Ubuntu 18.04, 22.04 as the Hypervisor OS.</p>
<h3 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h3>
<p>ToyVMM requires <a href="https://www.linux-kvm.org/page/Main_Page">the KVM Linux kernel module.</a></p>
<h3 id="run-virtual-machine-using-toyvmm"><a class="header" href="#run-virtual-machine-using-toyvmm">Run Virtual Machine using ToyVMM</a></h3>
<p>Following command builds toyvmm from source, downloads the kernel binary and rootfs needed to start the VM, and starts the VM.</p>
<pre><code class="language-bash"># download and build toyvmm from source.
git clone https://github.com/aztecher/toyvmm.git
cd toyvmm
mkdir build
CARGO_TARGET_DIR=./build cargo build --release

# Download a linux kernel binary.
wget https://s3.amazonaws.com/spec.ccfc.min/img/quickstart_guide/x86_64/kernels/vmlinux.bin

# Download a rootfs.
wget https://s3.amazonaws.com/spec.ccfc.min/ci-artifacts/disks/x86_64/ubuntu-18.04.ext4

# Run virtual machine based on ToyVMM!
sudo ./build/release/toyvmm vm run --config examples/vm_config.json
</code></pre>
<p>After the guest OS startup sequence is output, the login screen is displayed, so enter both username and password as 'root' to login.</p>
<h3 id="disk-io-in-virtual-machine"><a class="header" href="#disk-io-in-virtual-machine">Disk I/O in Virtual Machine.</a></h3>
<p>Since we have implemented virtio-blk, the virtual machine is capable of operating block devices.<br />
Now it recognizes the ubuntu18.04.ext4 disk image as a block device and mounts it as the root filesystem.</p>
<pre><code class="language-bash">lsblk
&gt; NAME MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
&gt; vda  254:0    0  384M  0 disk /
</code></pre>
<p>Therefore, if you create a file in the VM and then recreate the VM using the same image, the file you created will be found.
This behavior is significantly different from a initramfs (rootfs that is extracted on RAM).</p>
<pre><code class="language-bash"># Create 'hello.txt' in VM.
echo &quot;hello virtual machine&quot; &gt; hello.txt
cat hello.txt
&gt; hello virtual machine

# Rebooting will cause the ToyVMM process to terminate.
reboot -f

# In the host, please restart VM and login again.
# Afterward, you can found the file you created in the VM during its previous run.
cat hello.txt
&gt; hello virtual machine
</code></pre>
<h3 id="network-io-in-virtual-mahcine"><a class="header" href="#network-io-in-virtual-mahcine">Network I/O in Virtual Mahcine.</a></h3>
<p>Since we have implemented virtio-net, the virtual machine is capable of operating network device.<br />
Now, it recognizes the <code>eth0</code> network interface.</p>
<pre><code class="language-bash">ip link show eth0
&gt; 2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000
&gt;     link/ether 52:5f:7f:b3:f8:81 brd ff:ff:ff:ff:ff:ff
</code></pre>
<p>And toyvmm creates the host-side tap device named <code>vmtap0</code> that connect to the virtual machine interface.</p>
<pre><code class="language-bash">ip link show vmtap0
&gt; 334: vmtap0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UNKNOWN mode DEFAULT group default qlen 1000
&gt;     link/ether 26:e9:5c:02:3c:19 brd ff:ff:ff:ff:ff:ff
</code></pre>
<p>Therefore, by assigning appropriate IP addresses to the interfaces on both the VM side and the Host side, communication can be established between the HV and the VM.</p>
<pre><code class="language-bash"># Assign ip address 192.168.0.10/24 to 'eth0' in vm.
ip addr add 192.168.0.10/24 dev eth0

# Assign ip address 192.168.0.1/24 to 'vmtap0' in host.
sudo ip addr add 192.168.0.1/24 dev vmtap0

# Host -&gt; VM. ping to VM interface ip from host.
ping -c 1 192.168.0.10

# VM -&gt; Host. Ping to Host interface ip from vm.
ping -c 1 192.168.0.1
</code></pre>
<p>Additionally, by setting the default route on the VM side, and configuring iptables and enabling IP forwarding on the host side, you can also allow the VM to access the Internet.<br />
However, this will not be covered in detail here.</p>
<h3 id="whats-next-1"><a class="header" href="#whats-next-1">What's next?</a></h3>
<p>If you are not familiar with KVM-based VMs, I suggest you start reading from <a href="./01_running_tiny_code_in_vm.html">01. Running Tiny Code in VM</a>.
If not, please read the topics that interest you.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="01-running-tiny-code-in-vm"><a class="header" href="#01-running-tiny-code-in-vm">01. Running Tiny Code in VM</a></h1>
<p>Tiny code execution is no longer supported in the current latest commit.</p>
<p>You may be able to verify it by checking out past commits, but please be aware that resolving package dependencies may be challenging.</p>
<p>This chapter is documented in a way that you can get a sense of its behavior without actually running it, so please feel reassured about that.</p>
<h3 id="deepdive-toyvmm-instruction-and-how-to-run-tiny-code-in-vm"><a class="header" href="#deepdive-toyvmm-instruction-and-how-to-run-tiny-code-in-vm">DeepDive ToyVMM instruction and how to run tiny code in VM</a></h3>
<p>This <code>main</code> function is a program that starts a VM using the KVM mechanism and executes the following small code inside the VM</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>code = &amp;[
	0xba, 0xf8, 0x03, /* mov $0x3f8, %dx */
	0x00, 0xd8,       /* add %bl, %al */
	0x04, b'0',       /* add $'0', %al */
	0xee,             /* out %al, (%dx) */
	0xb0, '\n',       /* mov $'\n', %al */
	0xee,             /* out %al, (%dx) */
	0xf4,             /* hlt */
];
<span class="boring">}
</span></code></pre></pre>
<p>This code perform several register operations, but the initial state of the CPU regisers for this VM is set as follows.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    regs.rip = 0x1000;
    regs.rax = 2;
    regs.rbx = 2;
    regs.rflags = 0x2;
    vcpu.set_sregs(&amp;sregs).unwrap();
    vcpu.set_regs(&amp;regs).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>This will output the result of calculations (2 + 2) inside the VM from the IO Port, followed by a newline code as well.<br />
As you can see the result of running ToyVMM, hex value 0x34 (= '4') and 0xa (= New Line) are catched from I/O port</p>
<h3 id="hows-work-above-code-with-rust-vmm-libraries"><a class="header" href="#hows-work-above-code-with-rust-vmm-libraries">How's work above code with rust-vmm libraries</a></h3>
<p>Now, the following crate provided by rust-vmm is used to run these codes.</p>
<pre><code class="language-bash"># Please see Cargo.toml
kvm-bindings
kvm-ioctls
vmm-sys-util
vm-memory
</code></pre>
<p>I omit to describe about <a href="https://github.com/rust-vmm/vmm-sys-util">vmm-sys-util</a> because it is only used to create temporary files at this point, so there is nothing special to mention about it.</p>
<p>I will go through the code in order and describe how each crate is related to that.<br />
In this explanation, we will focus primary on the perspective of <strong>what ioctl is performed as a result of a function call</strong> (This is because the interface to manipulate KVM from the user space relies on the iocl system call)<br />
Also, please note that explanations of unimportant variables may be omitted.<br />
It should be noted that what is described here is not only the ToyVMM implementation, but also the firecracker implementation in a similaer form.</p>
<p>First, we need to open <code>/dev/kvm</code> and acquire the file descriptor. This can be done by <code>Kvm::new()</code> of <a href="https://github.com/rust-vmm/kvm-ioctls"><code>kvm_ioctls</code></a> crate. Following this process, the <a href="https://github.com/rust-vmm/kvm-ioctls/blob/d12f5776be0937a14da1ad8f9736653e8a2ad5ba/src/ioctls/system.rs#L69-L78"><code>Kvm::open_with_cloexec</code></a> function issues an <code>open</code> system call as follows, returns a file descriptor as <code>Kvm</code> structure</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let ret = unsafe { open(&quot;/dev/kvm\0&quot;.as_ptr() as *const c_char, open_flags) };
<span class="boring">}
</span></code></pre></pre>
<p>The result obtained from above is used to call the method <code>create_vm</code>, which results in the following <code>ioctl</code> being issued</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>vmfd = ioctl(kvmfd, KVM_CREATE_VM, 0)

where
  vmfd: from /dev/kvm
<span class="boring">}
</span></code></pre></pre>
<p>Please keep in mind that the file descriptor returned from above function will be used later when preparing the CPU.<br />
Anyway, we finish to crete a VM but it has no memory, cpu.</p>
<p>Now, the next step is to prepare memory!
In <code>kvm_ioctls</code>'s example, memory is prepared as follows</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// First, setup Guest Memory using mmap
let load_addr: *mut u8 = unsafe {
    libc::mmap(
        null_mut(),
        mem_size, // 0x4000
        libc::PROT_READ | libc::PROT_WRITE,
        libc::MAP_ANONYMOUS | libc::MAP_SHARED | libc::MAP_NORESERVE,
        -1,
        0,
    ) as *mut u8
};

// Second, setup kvm_userspace_memory_region sructure using above memory
// kvm_userspace_memory_region is defined in kvm_bindings crate
let mem_region = kvm_userspace_memory_region {
    slot,
    guest_phys_addr: guest_addr,  // 0x1000
    memory_size: mem_size as u64, // 0x4000
    userspace_addr: load_addr as u64,
    flags: KVM_MEM_LOG_DIRTY_PAGES,
};
unsafe { vm.set_user_memory_region(mem_region).unwrap() };

// retrieve slice from pointer and length (slice::form_raw_parts_mut)
//   &gt; https://doc.rust-lang.org/beta/std/slice/fn.from_raw_parts_mut.html
// and write asm_code into this slice (&amp;[u8], &amp;mut [u8], Vec&lt;u8&gt; impmenent the Write trait!)
//   &gt; https://doc.rust-lang.org/std/primitive.slice.html#impl-Write
unsafe {
    let mut slice = slice::from_raw_parts_mut(load_addr, mem_size);
    slice.write(&amp;asm_code).unwrap();
}
<span class="boring">}
</span></code></pre></pre>
<p>Check <code>set_user_memory_region</code>. This function will issue the following ioctl as a result, attach the memory to VM</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ioctl(vmfd, KVM_SET_USER_MEMORY_REGION, &amp;mem_region)
<span class="boring">}
</span></code></pre></pre>
<p>ToyVMM, on the other hand, provides a utility functions for memory preparation.<br />
This difference is due to the fact that ToyVMM's implementation is similaer to firecracker's, but they are essentially doing the same thing.</p>
<p>Let's look at the whole implementation first</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// The following `create_region` functions operate based on file descriptor, so first, create a temporary file and write asm_code to it.
let mut file = TempFile::new().unwrap().into_file();
assert_eq!(unsafe { libc::ftruncate(file.as_raw_fd(), 4096 * 10) }, 0);
let code: &amp;[u8] = &amp;[
    0xba, 0xf8, 0x03, /* mov $0x3f8, %dx */
    0x00, 0xd8,       /* add %bl, %al */
    0x04, b'0',       /* add $'0', %al */
    0xee,             /* out %al, %dx */
    0xb0, b'\n',      /* mov $'\n', %al */
    0xee,             /* out %al, %dx */
    0xf4,             /* hlt */
];
file.write_all(code).expect(&quot;Failed to write code to tempfile&quot;);

// create_region funcion create GuestRegion (The details are described in the following)
let mut mmap_regions = Vec::with_capacity(1);
let region = create_region(
    Some(FileOffset::new(file, 0)),
    0x1000,
    libc::PROT_READ | libc::PROT_WRITE,
    libc::MAP_NORESERVE | libc::MAP_PRIVATE,
    false,
).unwrap();

// Vec named 'mmap_regions' contains the entry of GuestRegionMmap
mmap_regions.push(GuestRegionMmap::new(region, GuestAddress(0x1000)).unwrap());

// guest_memory represents as the vec of GuestRegion
let guest_memory = GuestMemoryMmap::from_regions(mmap_regions).unwrap();
let track_dirty_page = false;

// setup Guest Memory
vm.memory_init(&amp;guest_memory, kvm.get_nr_memslots(), track_dirty_page).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>The <code>create_vm</code> consequently performs a mmap in the following way and returns a part of the structure (GuestMmapRegion) representing the GuestMemory</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn create_region(
    maybe_file_offset: Option&lt;FileOffset&gt;,
    size: usize,
    prot: i32,
    flags: i32,
    track_dirty_pages: bool,
) -&gt; Result&lt;GuestMmapRegion, MmapRegionError&gt; {

...

let region_addr = unsafe {
    libc::mmap(
        region_start_addr as *mut libc::c_void,
        size,
        prot,
        flags | libc::MAP_FIXED,
        fd,
        offset as libc::off_t,
    )
};
let bitmap = match track_dirty_pages {
    true =&gt; Some(AtomicBitmap::with_len(size)),
    false =&gt; None,
};
unsafe {
    MmapRegionBuilder::new_with_bitmap(size, bitmap)
        .with_raw_mmap_pointer(region_addr as *mut u8)
        .with_mmap_prot(prot)
        .with_mmap_flags(flags)
        .build()
}
<span class="boring">}
</span></code></pre></pre>
<p>Let's check the structure about Memory here.
In <code>src/kvm/memory.rs</code>, the following Memory structure is defined based on <a href="https://github.com/rust-vmm/vm-memory">vm-memory</a> crate</p>
<pre><code>pub type GuestMemoryMmap = vm_memory::GuestMemoryMmap&lt;Option&lt;AtomicBitmap&gt;&gt;;
pub type GuestRegionMmap = vm_memory::GuestRegionMmap&lt;Option&lt;AtomicBitmap&gt;&gt;;
pub type GuestMmapRegion = vm_memory::MmapRegion&lt;Option&lt;AtomicBitmap&gt;&gt;;
</code></pre>
<p>The <code>MmapRegionBuilder</code> is also defined in the <code>vm-memory</code> crate, and this <code>build</code> method creates the <code>MmapRegion</code>.</p>
<p>This time, since we have performed the mmap myself in advance and passed that address to <code>with_raw_mmap_pointer</code>, <a href="https://github.com/rust-vmm/vm-memory/blob/f6ef1b619b126324830c87a3554b7082a0490ae0/src/mmap_unix.rs#L145-L147">use that area to initialize</a>. Otherwise, <a href="https://github.com/rust-vmm/vm-memory/blob/f6ef1b619b126324830c87a3554b7082a0490ae0/src/mmap_unix.rs#L164-L173">mmap is performed in the <code>build</code> method</a>. In any case, this <code>build</code> method will get the <code>MmapRegion</code> structure, but defines a synonym as described above, which is returned as the <code>GuestMmapRegion</code>. By calling the <code>create_region</code> function once, you can allocate and obtain one region of GuestMemory based on the information(<code>size</code>, <code>flags</code>, ...etc) specified in the argument.</p>
<p>The region allocated here is only mmapped from the virtual address space of the VMM process, and no further information is available. To use this area as Guest Memory, a <code>GuestRegionMmap</code> structure is created from this area. This is simple, specify the corresponding <code>GuestAddress</code> for this region and initialize <code>GuestRegionMmap</code> with a tuple of mmapped area and GuestAddress. In following code, the initialized <code>GuestRegionMmap</code> is pushed to Vec for subsequent processing.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>map_regions.push(GuestRegionMmap::new(region, GuestAddress(0x1000)).unwrap());
<span class="boring">}
</span></code></pre></pre>
<p>Now, the <code>mmap_regions: Vec&lt;GuestRegionMmap&gt;</code> created as above represents the entire memory of the Guest VM, and each region that makes up the guest memory holds information on the area allocated by the VMM for the region and the top address of the Guest side.
The <code>GuestMemoryMmap</code> structure representing the Guest Memory is initialized from this Vec information and set to VM by the <code>memory_init</code> method.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let guest_memory = GuestMemoryMmap::from_regions(mmap_regions).unwrap();
vm.memory_init(&amp;guest_memory, kvm.get_nr_memslots(), track_dirty_page).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>Next, let's check the operation of this <code>memory_init</code>. This calls <code>set_kvm_memory_regions</code> and the actual process is described there.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn set_kvm_memory_regions(
    &amp;self,
    guest_mem: &amp;GuestMemoryMmap,
    track_dirty_pages: bool,
    ) -&gt; Result&lt;()&gt; {
    let mut flags = 0u32;
    if track_dirty_pages {
        flags |= KVM_MEM_LOG_DIRTY_PAGES;
    }
    guest_mem
        .iter()
        .enumerate()
        .try_for_each(|(index, region)| {
            let memory_region = kvm_userspace_memory_region {
                slot: index as u32,
                guest_phys_addr: region.start_addr().raw_value() as u64,
                memory_size: region.len() as u64,
                userspace_addr: guest_mem.get_host_address(region.start_addr()).unwrap() as u64,
                flags,
            };
            unsafe { self.fd.set_user_memory_region(memory_region) }
        })
    .map_err(Error::SetUserMemoryRegion)?;
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>Here we can see that <code>set_user_memory_region</code> is called using the necessary information while iterating the region.
In other words, it is processing the same as the example code except that there may be more than one region.</p>
<p>Now that we've gone through the explanation of memory preparation, let's take a look at the <code>vm-memory</code> crate!
The information presented here is only the minimum required, so please refer to <a href="https://github.com/rust-vmm/vm-memory/blob/main/DESIGN.md">Design</a> or other sources for more details.
This will also be related to the above iteration, where we were able to call methods such as <code>sart_addr()</code> and <code>len()</code> to construct the necessary information for <code>set_user_memory_region</code>.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>GuestAddress (struct) : Represent Guest Physicall Address (GPA)
FileOffset(struct) : Represents the start point within a 'File' that backs a 'GuestMemoryRegion'

GuestMemoryRegion(trait) : Represents a continuous region of guest physical memory / trait
GuestMemory(trait) : Represents a container for a immutable collection of GuestMemoryRegion object / trait

MmapRegion(struct) : Helper structure for working with mmaped memory regions
GuestRegionMmap(struct &amp; implement GuestMemoryRegion trait) : Represents a continuous region of the guest's physical memory that is backed by a mapping in the virtual address space of the calling process
GuestMemoryMmap(struct &amp; implement GuestMemory trait) : Represents the entire physical memory of the guest by tracking all its memory regions
<span class="boring">}
</span></code></pre></pre>
<p><a href="https://github.com/rust-vmm/vm-memory/blob/f6ef1b619b126324830c87a3554b7082a0490ae0/src/mmap.rs#L436">Since <code>GuestRegionMmap</code> implements the <code>GuestMemoryRegion</code> trait</a>, there are implementations of functions such as <code>start_addr()</code> and <code>len()</code>, which were used in the above interation.
The following figure briefly summarizes the relationship between these structures</p>
<img src="./01_figs/vm-memory_overview.svg" width="100%">
<p>As you can see, what is being done is essentially the same.</p>
<p>The final step is prepareing vCPU (vCPU is a CPU to be attached to a virtual machine).<br />
Currently, a VM has been created and memory containing instructions has been inserted, but these is no CPU, so the instructions can't be executed. Therefore, let's create a vCPU, associate it with the VM, and execute the instruction by running the vCPU!</p>
<p>Using the file descriptor obtained during VM creaion (<code>vmfd</code>), the resulting <code>ioctl</code> will be issued as follows.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>vcpufd = ioctl(vmfd, KVM_CREATE_VCPU, 0)
<span class="boring">}
</span></code></pre></pre>
<p>The <code>create_vm</code> method that was just issued to obtain the <code>vmfd</code> is designed to return a <code>kvm_ioctls::VmFd</code> strucure as a result, and by execuing the <code>create_vcpu</code> method, which is a method of this structure, the above ioctl is consequently issued and returns the result as a <code>kvm_ioctls::VcpuFd</code> structure.</p>
<p><code>VcpuFd</code> provides utilities for getting and setting various CPU states.<br />
For example, if you want o get/set a register set from the vCPU, you would normally issue the following <code>ioctl</code></p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ioctl(vcpufd, KVM_GET_SREGS, &amp;sregs);
ioctl(vcpufd, KVM_SET_SREGS, &amp;sregs);
<span class="boring">}
</span></code></pre></pre>
<p>For these, the following methods are available in <code>kvm_ioctls::VcpuFd</code></p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>get_sregs(&amp;self) -&gt; Result&lt;kvm_sregs&gt;
set_sregs(&amp;self, sregs: &amp;kvm_sregs) -&gt; Result&lt;()&gt;
<span class="boring">}
</span></code></pre></pre>
<p><code>VcpuFd</code> also provids a method called <code>run</code>, which issues the following insructions to actually run the vCPU.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ioctl(vcpufd, KVM_RUN, NULL)
<span class="boring">}
</span></code></pre></pre>
<p>and then, we can aquire return values that has the type <code>Result&lt;VcpuExit&gt;</code> resulting this method.</p>
<p>When running vCPU, exit occurs for various reasons. This is an instruction that the CPU cannot handle, and the OS usually tries to deal with it by invoking the corresponding handler.<br />
If this type of exit comes back from the VM's vCPU, as in the case, it will be necessary to write the appropriate code to handle the situation.<br />
<code>VcpuExit</code> is defined in <code>kvm_ioctls::VcpuExit</code> as enum.<br />
When Exit are occurred on several reasons in running vCPU, the exit reasons that are defined in kvm.h in linux kernel are wrapped to <code>VcpuExit</code>.<br />
Therefore, it is sufficient to write a process that pattern matches this result and appropriately handles the error to be handled.</p>
<p>Now, there is a instruction that execute outputting values through I/O port and this will occur the <code>KVM_EXIT_IO_OUT</code>.<br />
<code>VcpuExit</code> wrap this exit reason as <code>IoOut</code>.</p>
<p>Originally (in C programm as example), we require to calculate appropriate offset to get output data from I/O port, but now, this process are implemented in <code>run</code> method and returned as VcpuExit that contains necessary values.<br />
So, we don't have to write these unsafe code (pointer offset calculation) and handle these exit as you will.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>loop {
    match vcpu.run().expect(&quot;vcpu run failed&quot;) {
        kvm_ioctls::VcpuExit::IoOut(addr, data) =&gt; {
            println!(
                &quot;Recieved I/O out exit. \
                Address: {:#x}, Data(hex): {:#x}&quot;,
                addr, data[0],
            );
        },
        kvm_ioctls::VcpuExit::Hlt =&gt; {
            break;
        }
        exit =&gt; panic!(&quot;unexpected exit reason: {:?}&quot;, exit),
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>In above, only handle <code>KVM_EXIT_IO_OUT</code> and <code>KVM_EXIT_HLT</code>, and the others will be processed as panic. (Although all exits should be handled, I want to focus on the description of KVM API example and keep it simply)</p>
<p>Since we are here, let's take a look at the processing of the <code>run</code> method in some detail.<br />
Let's check the processing of <code>KVM_EXIT_IO_OUT</code>.</p>
<p>If you look at the <a href="https://lwn.net/Articles/658511/">LWN article</a>, you will see that it calculates the offset and outputs the necessary information in the following way.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>case KVM_EXIT_IO:
    if (run-&gt;io.direction == KVM_EXIT_IO_OUT &amp;&amp;
	    run-&gt;io.size == 1 &amp;&amp;
	    run-&gt;io.port == 0x3f8 &amp;&amp;
	    run-&gt;io.count == 1)
	putchar(*(((char *)run) + run-&gt;io.data_offset));
    else
	errx(1, &quot;unhandled KVM_EXIT_IO&quot;);
    break;
<span class="boring">}
</span></code></pre></pre>
<p>On the other hand, <code>run</code> method implemented in <code>kvm_ioctl::VcpuFd</code> is like bellow</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>...
let run = self.kvm_run_ptr.as_mut_ref();
match run.exit_reason {
    ...
    KVM_EXIT_IO =&gt; {
        let run_start = run as *mut kvm_run as *mut u8;
        // Safe because the exit_reason (which comes from the kernel) told us which
        // union field to use.
        let io = unsafe { run.__bindgen_anon_1.io };
        let port = io.port;
        let data_size = io.count as usize * io.size as usize;
        // The data_offset is defined by the kernel to be some number of bytes into the
        // kvm_run stucture, which we have fully mmap'd.
        let data_ptr = unsafe { run_start.offset(io.data_offset as isize) };
        // The slice's lifetime is limited to the lifetime of this vCPU, which is equal
        // to the mmap of the `kvm_run` struct that this is slicing from.
        let data_slice = unsafe {
            std::slice::from_raw_parts_mut::&lt;u8&gt;(data_ptr as *mut u8, data_size)
        };
        match u32::from(io.direction) {
            KVM_EXIT_IO_IN =&gt; Ok(VcpuExit::IoIn(port, data_slice)),
            KVM_EXIT_IO_OUT =&gt; Ok(VcpuExit::IoOut(port, data_slice)),
            _ =&gt; Err(errno::Error::new(EINVAL)),
        }
    }
		...
<span class="boring">}
</span></code></pre></pre>
<p>Let me explain a little. The <code>kvm_run</code> is provided by the <a href="https://github.com/rust-vmm/kvm-bindings"><code>kvm-bindings</code></a> crate, which is a structure automatically generated from a header file using <a href="https://github.com/rust-lang/rust-bindgen"><code>bindgen</code></a>, so it is a structure like the linux kernel's <code>kvm_run</code> converted directory to Rust.<br />
First, <code>kvm_run</code> is obtained in the form of a pointer, a method of obtaining a pointer often used in Rust.<br />
This correspoinds to the first address of the <code>kvm_run</code> structure which is bound to <code>run_start</code> variable.<br />
And the information corresponding to <code>run-&gt;io(.member)</code> can be obtained from <code>run.__bindgen_anon_1.io</code>, although it is a bit tricky. The field named <code>__bindgen_anon_1</code> is the effect of automatic generation by <code>bindgen</code>.<br />
The data we want is at the first address of <code>kvm_run</code> plus <code>io.data_offset</code>. This process is performed in <code>run_start.offset(io.data_offset as isize)</code>. And the data size can be calculated from <code>io-&gt;size</code> and <code>io-&gt;count</code> (in the LWN example, it is 1byte, so it's taken directory from the offset by putchar). This part is calculated and stored in the value <code>data_size</code>, and <code>std::slice::from_raw_parts_mut</code> actually retrieves the data using this size.<br />
Finally, checking <code>io.direction</code>, we change the wrap type for <code>KVM_EXIT_IO_IN</code> or <code>KVM_EXIT_IO_OUT</code> respectively, and return the descired information such as <code>port</code> and <code>data_slice</code> together.</p>
<p>As can be seen from the above, what is being done is clear.<br />
However, it still contains many unsafe operations because it involves pointer manipuration.<br />
We can see that by using these libraries, we are able to implement VMM on a stable implementation.</p>
<p>Well, it's ben a long time comming, but let's take a look back at the rust-vmm crates we're using again.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>kvm-bindings : Library that includes structures automatically generated from kvm.h by bindgen.
kvm-ioctls : Library that hides ioctl and unsafe processes related to kvm operations and provides user-friendly sructures, functions and methods.  
vm-memory : Library that provides structures and operations to the Memory
<span class="boring">}
</span></code></pre></pre>
<p>This knowledge will come up again and again in future discussion and is basic and important.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="load-linux-kernel"><a class="header" href="#load-linux-kernel">Load Linux Kernel</a></h1>
<p>In this section, we will explain upon the implementation of launching a Guest VM as the first step in VMM. While our VMM has minimal functionality, booting the Linux Kernel demands a variety of knowledge.</p>
<p>In this section, we will explain the essential aspects of launching a Guest VM and delve into how it is implemented in ToyVMM. To achieve this, we will divide it into several detailed chapters and provide explanations for each topic.</p>
<p>The topics are as follows:</p>
<ul>
<li><a href="./02-1_overview_of_booting_linux.html">02-1. Overview of Booting Linux</a></li>
<li><a href="./02-2_elf_binary_format_and_vmlinux_structure.html">02-2. ELF binary format and vmlinux structure</a></li>
<li><a href="./02-3_loading_initrd.html">02-3. Loading initrd</a></li>
<li><a href="./02-4_setup_registers_of_vcpu.html">02-4. Setup registers of vcpu</a></li>
<li><a href="./02-5_serial_console_implementation.html">02-5. Serial console implementation</a></li>
<li><a href="./02-6_toyvmm_implementation.html">02-6. ToyVMM implementation</a></li>
</ul>
<p>Additionally, this document is based on the following commit numbers:</p>
<ul>
<li>ToyVMM: <code>27fdf196dfb31938f24785ca64e7233a6dc8fceb</code></li>
<li>Firecracker: <code>4bf121fc032cc2d94a20a3625f2af3918545154a</code></li>
</ul>
<p>If you refer to this document while inspecting ToyVMM's code, it may be beneficial.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview-of-booting-linux"><a class="header" href="#overview-of-booting-linux">Overview of Booting Linux</a></h1>
<h3 id="general-booting-mechanism"><a class="header" href="#general-booting-mechanism">General Booting Mechanism</a></h3>
<p>In Linux, the operating system starts by executing programs in the following order:</p>
<ol>
<li>BIOS</li>
<li>Boot Loader (GRUB)</li>
<li>Linux Kernel (vmlinuz)</li>
<li>init</li>
</ol>
<p>The BIOS program is stored in the ROM on the motherboard. When you power on your computer, the CPU is instructed to start executing code from a specific address mapped to this ROM area. The BIOS performs hardware detection and initialization, then searches for the OS boot drive (HDD/SSD, USB flash drive, etc.). During this process, the boot drive needs to be formatted in either MBR or GPT format, depending on the BIOS type, as shown in the table below:</p>
<table><thead><tr><th>BIOS \ DISK Format</th><th>MBR</th><th>GPT</th></tr></thead><tbody>
<tr><td>Legacy BIOS</td><td>◯</td><td>-</td></tr>
<tr><td>UEFI</td><td>◯ *</td><td>◯</td></tr>
</tbody></table>
<p>* UEFI supports Legacy Boot Mode and thus supports MBR.</p>
<p>Next, I will explain the process of searching for the OS when using MBR. But before going into details, let's briefly review the structure of MBR. The MBR structure explained here assumes HDD/SSD or USB flash memory and implicitly assumes the presence of the Partition Entry, as described later. Please note that this document uses the terms provided on <a href="https://en.wikipedia.org/wiki/Master_boot_record">Wikipedia</a>, so keep that in mind.</p>
<p>MBR is a 512-byte sector located at the beginning of the boot drive and consists of three main parts:</p>
<ol>
<li>Bootstrap code area (446 bytes)</li>
<li>Partition Entry (64 bytes = 16 bytes * 4)</li>
<li>Boot Signature (2 bytes)</li>
</ol>
<p>I won't go into the details of MBR here, but the Boot code area contains machine code programs (Boot Loaders) to boot the OS, and the Partition Entry stores information about the logical partitions on that disk. It's worth noting that the Boot code area is only 446 bytes in size, so Boot Loaders are typically stored elsewhere. A minimal program is placed in the Boot code area to load the actual Boot Loader into memory.<br />
The critical part here is the &quot;Boot Signature,&quot; which contains a 2-byte value used to ensure that the drive is a bootable device. When the BIOS searches for the OS boot drive, it reads the first sector (512 bytes), checks if the last 2 bytes (Boot Signature) are <code>0x55</code> and <code>0xAA</code>, and identifies the drive as a bootable disk. It loads the first sector (512 bytes) from that disk into memory at <code>0x7c00 - 0x7fff</code> and begins executing the program from <code>0x7c00</code>.</p>
<p>Now, as a simple validation, let's check the Boot Signature on your machine. In this example, you are using a virtual machine with the boot drive labeled as <code>vda</code>. On a regular machine, it might be something like <code>sda</code>. By writing the first sector's content to a file and examining the 2 bytes at an offset of 510 bytes, you should see the <code>0x55</code> <code>0xAA</code> signature as expected.</p>
<pre><code class="language-bash">$ lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0     11:0    1    2M  0 rom
vda    252:0    0  300G  0 disk
├─vda1 252:1    0    1M  0 part
└─vda2 252:2    0  300G  0 part /

$ sudo dd if=/dev/vda of=mbr bs=512 count=1
1+0 records in
1+0 records out
512 bytes (512 B) copied, 0.000214802 s, 2.4 MB/s

$ hexdump -s 510 -C mbr
000001fe  55 aa                                             |U.|
00000200
</code></pre>
<p>Now, back to our discussion. After confirming the Boot Signature, the BIOS identifies the disk as a bootable disk and loads the first sector (512 bytes) from it into memory at address <code>0x7c00</code>. The program execution starts from <code>0x7c00</code>.</p>
<p>Moving on, once the Boot Loader is loaded into memory, it takes on the responsibility of loading the Linux Kernel and initramfs from the disk and starting the kernel. In recent years, GRUB has become a common choice as a Boot Loader. I'll skip the detailed workings of the Boot Loader for now. The essential point is that the Boot Loader needs to load the specified kernel and initrd from the disk.</p>
<p>To achieve this, one straightforward method would be to inform the Boot Loader of the location of the kernel file on the disk. However, if you look at the contents of <code>grub.cfg</code>, you'll notice that the kernel and initrd locations are specified in the form of file paths. This means that the Boot Loader must have the ability to interpret the file system. In practice, several Boot Loaders can interpret various file systems and locate the kernel based on directory path information. However, it's essential to note that Boot Loaders are limited to supporting specific file system formats, and they cannot interpret other formats. The Boot Loader loads the specified kernel and RAM disk from <code>grub.cfg</code>, and by jumping to the kernel's entry point, it hands over the execution to the kernel, completing its own processing.</p>
<p>Before delving into the details of the kernel's processing, let's briefly organize some information about the kernel file. The kernel file is generally named <code>vmlinuz*</code>. You might be familiar with a kernel file located at <code>/boot/vmlinuz-*</code>, which is believed to be the kernel. However, this file is in the <code>bzImage</code> format. You can easily check this using the <code>file</code> command. The <code>bzImage</code> includes the actual kernel binary along with several other files used for low-level initialization. In this document, I'll refer to the kernel file in the <code>bzImage</code> format as <code>vmlinuz</code> and the actual kernel binary in executable format as <code>vmlinux.bin</code>.</p>
<p>When control is handed over from the BootLoader to <code>vmlinuz</code>, <code>vmlinuz</code> performs low-level initialization, then decompresses the kernel core, loads it into memory, and transfers control to the kernel's entry routine. Once all initialization processes are completed, the kernel creates a <code>tmpfs</code> filesystem, unpacks the <code>initramfs</code> placed in RAM by the BootLoader into it, and starts the <code>init</code> script located in the root directory.</p>
<p>This <code>init</code> script prepares to mount the main filesystem stored on the disk and mounts other important filesystems. <code>initramfs</code> contains various device drivers and allows mounting root filesystems in different formats. After this is done, the root is switched to the main root filesystem, and the <code>/sbin/init</code> binary stored there is executed.</p>
<p><code>/sbin/init</code> is the first process to be launched in the system (with PID=1), and it serves as the parent for all other processes responsible for starting other processes. There are various implementations of <code>init</code>, such as <code>SysVinit</code> and <code>Upstart</code>, but what is commonly used in recent systems like CentOS and Ubuntu is <code>Systemd</code>. The ultimate responsibility of <code>init</code> is to further prepare the system and ensure that the necessary services are running and the system is in a state where users can log in when the boot process is complete.</p>
<p>This is a very high-level overview of the process from powering on to the OS booting up.</p>
<h3 id="initrd-and-initramfs"><a class="header" href="#initrd-and-initramfs">initrd and initramfs</a></h3>
<p>In the previously discussed Linux boot process, we introduced <code>initramfs</code>, a file system that is unpacked into memory. However, what we often encounter is <code>/boot/initrd.img</code>. Here, we will explain the differences between <code>initrd</code> and <code>initramfs</code>.</p>
<p><code>initrd</code> stands for &quot;initial RAM <strong>disk</strong>, while <code>initramfs</code> stands for &quot;initial RAM <strong>File System</strong>&quot;. Although they are different in nature, they serve the same purpose, which is to provide the necessary commands, libraries, and modules for mounting the root file system and launching the <code>/sbin/init</code> script located in the root file system. </p>
<p>The challenge that both <code>initrd</code> and <code>initramfs</code> address is that the system you want to boot originally resides in some storage device. To load it, you need appropriate device drivers and a file system for mounting. </p>
<p><code>initrd</code> and <code>initramfs</code> both address this issue, but they use different methods. As their names suggest, <code>initrd</code> uses a block device, while <code>initramfs</code> uses a RAM file system based on <code>tmpfs</code>. Traditionally, <code>initrd</code> was used, but starting from Kernel 2.6, <code>initramfs</code> became available, and it is now the more common choice. </p>
<p>The shift from <code>initrd</code> to <code>initramfs</code> occurred because <code>initrd</code> had several issues:</p>
<ol>
<li>
<p>A RAM disk is a mechanism that creates a pseudo block device in RAM, treating it as if it were a secondary storage device. However, because of this behavior, it inadvertently consumes memory cache, similar to regular block devices, leading to unnecessary memory usage. Furthermore, mechanisms such as paging come into play, consuming more memory capacity.</p>
</li>
<li>
<p>A RAM disk requires a file system driver, such as ext2, to format and interpret its data.</p>
</li>
<li>
<p>RAM disks have a fixed size, which can lead to problems; if they are too small, they may not accommodate all the necessary scripts, and if they are too large, they waste memory.</p>
</li>
</ol>
<p>To address these issues, <code>initramfs</code> was developed. It is a lightweight, memory-based file system that can be flexibly sized and is based on <code>tmpfs</code>. It is not a block device, so it doesn't interfere with memory caching or paging, and it doesn't require file system drivers for block devices. Additionally, it resolves the fixed size problem.
Whether using <code>initrd</code> or <code>initramfs</code>, both methods provide tools inside them to mount the root file system and switch to it. The startup script, <code>/sbin/init</code>, located in the file system, is then executed.</p>
<h4 id="inspecting-the-contents-of-initramfs"><a class="header" href="#inspecting-the-contents-of-initramfs">Inspecting the contents of initramfs</a></h4>
<p>Let's unpack and examine the contents of an <code>initramfs</code>. We'll use an Ubuntu 20.04.2 LTS <code>initrd</code> for this example. (Note: The file named <code>initrd</code> is actually a proper <code>initramfs</code>). An <code>initramfs</code> consists of several files concatenated in CPIO format. When you extract it directly using the <code>cpio</code> command, you'll see only the initial files (like <code>AuthenticAMD.bin</code>) as follows:</p>
<pre><code class="language-bash">$ mkdir initrd-work &amp;&amp; cd initrd-work
$ sudo cp /boot/initrd.img ./
$ cat initrd.img | cpio -idvm
.
kernel
kernel/x86
kernel/x86/microcode
kernel/x86/microcode/AuthenticAMD.bin
62 blocks
</code></pre>
<p>You can extract all the files using a combination of <code>dd</code> and <code>cpio</code>, but there's a handy tool called <code>unmkinitramfs</code> that can do this for you:</p>
<pre><code class="language-bash">$ mkdir extract
$ unmkinitramfs initrd.img extract
$ ls extract
early  early2  main
</code></pre>
<p>After extracting, you'll see directories like <code>early</code>, <code>early2</code>, and <code>main</code>. For instance, <code>early</code> contains the same files that were seen when extracted with <code>cpio</code>. The most crucial part is under <code>main</code>, where the contents of the file system root are stored:</p>
<pre><code class="language-bash">$ ls extract/early/kernel/x86/microcode
AuthenticAMD.bin
$ ls extract/early2/kernel/x86/microcode
GenuineIntel.bin
$ ls extract/main
bin  conf  cryptroot  etc  init  lib  lib32  lib64  libx32  run  sbin  scripts  usr  var
</code></pre>
<p>By chrooting into this extracted content, you can pseudo-operate the Linux boot-time RAM filesystem and understand what operations can be performed:</p>
<pre><code>$ sudo chroot extract/main /bin/sh

BusyBox v1.30.1 (Ubuntu 1:1.30.1-4ubuntu6.3) built-in shell (ash)
Enter 'help' for a list of built-in commands.

# ls
scripts    init       run        etc        var        usr        conf
lib64      bin        lib        libx32     lib32      sbin       cryptroot
# pwd
/
# which mount
/usr/bin/mount
# exit
</code></pre>
<p>As shown above, there is an <code>init</code> script file in the root directory, which is the script executed after extracting <code>initramfs</code>. The <code>init</code> script reads the contents of <code>/proc/cmdline</code> and extracts disk information (e.g., <code>root=/dev/sda1</code>) to perform the necessary mounting operations. If this information is missing, this <code>init</code> script in the Ubuntu 20.04LTS initrd would encounter an error.</p>
<p>In the case of ToyVMM, we use an <code>initramfs</code> based on <code>firecracker-initrd</code>.
Therefore, the behavior might differ slightly.</p>
<h4 id="about-firecracker-initrd"><a class="header" href="#about-firecracker-initrd">About firecracker-initrd</a></h4>
<p>In ToyVMM, we use <a href="https://github.com/marcov/firecracker-initrd">firecracker-initrd</a>. Firecracker-initrd creates an initrd.img (<code>initramfs</code>) based on Alpine Linux. Unlike the Ubuntu initrd we discussed earlier, it does not include additional CPIO files like microcode, so you can simply extract it to see the root filesystem:</p>
<pre><code>$ cat initrd.img | cpio -idv
$ ls
bin  dev  etc  home  init  initrd.img  lib  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
</code></pre>
<p>Alpine Linux typically unpacks a filesystem into RAM during normal boot, and then the OS starts. Afterward, decisions like whether to write the OS to a disk using <code>setup-alpine</code> depend on specific needs. In ToyVMM, when you boot a VM using this initramfs, it doesn't immediately mount the root file system by default. Instead, it simply unpacks the file system into RAM, and Alpine Linux starts. This is different from the traditional approach where you load the boot area into secondary storage and inform the init script via <code>/proc/cmdline</code>.</p>
<h2 id="boot-sequence-of-linux-kernel-in-toyvmm"><a class="header" href="#boot-sequence-of-linux-kernel-in-toyvmm">Boot Sequence of Linux Kernel in ToyVMM</a></h2>
<p>Now, let's compare what we've discussed so far with the Linux boot process in ToyVMM:</p>
<table><thead><tr><th>Boot Process (on Linux)</th><th>ToyVMM</th></tr></thead><tbody>
<tr><td>BIOS</td><td>Not implemented yet</td></tr>
<tr><td>Boot Loader</td><td><strong>Requires implementation: Loading vmlinux/initrd.img, basic setup</strong></td></tr>
<tr><td>Linux Kernel</td><td>Processed by <code>vmlinux.bin</code></td></tr>
<tr><td>init</td><td>Processed by <code>init</code> scripts (from firecracker-initrd's <code>initrd.img</code>)</td></tr>
</tbody></table>
<p>The current implementation of ToyVMM does not support loading <code>bzImage</code> and instead uses the ELF binary <code>vmlinux.bin</code>. It currently omits BIOS-related functions.</p>
<p>For the Boot Loader's tasks, such as loading <code>vmlinux.bin</code> and <code>initrd.img</code> into memory, implementation is needed. The Linux Kernel itself is processed by <code>vmlinux.bin</code>, while the <code>init</code> process is handled by the <code>init</code> scripts found in <code>initrd.img</code> from the <code>firecracker-initrd</code>.</p>
<p>For more detailed implementation instructions, you can refer to <a href="./02-6_minimal_vmm_implementation.html">02-6_minimal_vmm_implementation</a>.</p>
<p>References</p>
<ul>
<li><a href="https://www.hazymoon.jp/OpenBSD/arch/i386/stand/mbr/mbr_structure.html">MBR(Master Boot Records)の構造</a></li>
<li><a href="https://linux.die.net/man/4/initrd">Initrd(4) - Linux man page</a></li>
<li><a href="https://gihyo.jp/admin/serial/01/ubuntu-recipe/0384">Initramfsのしくみ</a></li>
<li><a href="https://wiki.gentoo.org/wiki/Initramfs/Guide/ja">Initramfs/ガイド</a></li>
<li><a href="https://0xax.gitbooks.io/linux-insides/content/Booting/">Kernel Boot Process</a></li>
<li><a href="https://www.baeldung.com/linux/initrd-vs-initramfs">What's the Difference Between initrd and initramfs</a></li>
<li><a href="https://wiki.bit-hive.com/linuxkernelmemo/pg/bzImage">bzImage</a></li>
<li><a href="http://www.seinan-gu.ac.jp/%7Eshito/old_pages/hacking/sh/boot_shutdown.html">Initデーモンを理解する</a></li>
<li><a href="https://keichi.dev/post/linux-boot/">Linuxがブートするまで</a></li>
<li><a href="http://archive.linux.or.jp/JF/JFdocs/kernel-docs-2.6/filesystems/ramfs-rootfs-initramfs.txt.html">filesystems/ramfs-rootfs-initramfs.txt</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="elf-binary-format-and-vmlinux-structure"><a class="header" href="#elf-binary-format-and-vmlinux-structure">ELF binary format and vmlinux structure</a></h1>
<p>At the time of writing this document, the kernel used to boot a VM in ToyVMM assumes an ELF-formatted <code>vmlinux.bin</code>. Therefore, within the VMM, it's necessary to interpret the ELF format and load the kernel into the memory area prepared for the VM appropriately. This process is implemented in the <a href="https://github.com/rust-vmm/linux-loader">rust-vmm/linux-loader</a> crate. While ToyVMM abstracts this implementation by using the crate, it is essential to understand how it works. Hence, this section provides an explanation of loading ELF binaries.</p>
<h2 id="elf-binary-format"><a class="header" href="#elf-binary-format">ELF Binary Format</a></h2>
<p>The ELF file format consists of the following components:</p>
<img src="../02_figs/elf_format.svg" width="100%">
<p>As shown above, the ELF file format primarily consists of an <code>ELF Header</code>, <code>Program Header Table</code>, <code>Segments (Sections)</code>, and <code>Section Header Table</code>. When used by a system loader, ELF files treat the entries in the <code>Program Header Table</code> as a collection of <code>Segments</code>, while compilers, assemblers, and linkers treat entries in the <code>Section Header Table</code> as a collection of <code>Sections</code>.</p>
<p>The <code>ELF Header</code> contains overall information about the ELF file. Each entry in the <code>Program Header Table</code>, known as a <code>Program Header</code>, holds header information about the corresponding <code>Segment</code>. Therefore, the number of <code>Program Headers</code> corresponds to the number of <code>Segments</code>. Furthermore, each <code>Segment</code> can be divided into multiple <code>Sections</code>, and the <code>Section Header Table</code> contains header information for these <code>Sections</code>.</p>
<p>The <code>ELF Header</code> always starts at the beginning of the file offset and holds information necessary for reading ELF data. Here are some excerpts from the <code>ELF Header</code>. For a comprehensive overview, please refer to the <a href="https://linuxjm.osdn.jp/html/LDP_man-pages/man5/elf.5.html">Man page of ELF</a>.</p>
<table><thead><tr><th>Attribute</th><th>Meaning</th></tr></thead><tbody>
<tr><td><code>e_entry</code></td><td>Virtual address representing the entry point to start this ELF process</td></tr>
<tr><td><code>e_phoff</code></td><td>File offset value to the location of the <code>Program Header Table</code></td></tr>
<tr><td><code>e_shoff</code></td><td>File offset value to the location of the <code>Section Header Table</code></td></tr>
<tr><td><code>e_phentsize</code></td><td>Size of one entry in the <code>Program Header Table</code></td></tr>
<tr><td><code>e_phnum</code></td><td>Number of entries in the <code>Program Header Table</code></td></tr>
<tr><td><code>e_shentsize</code></td><td>Size of one entry in the <code>Section Header Table</code></td></tr>
<tr><td><code>e_shnum</code></td><td>Number of entries in the <code>Section Header Table</code></td></tr>
</tbody></table>
<p>From the above excerpts, you can see that it's possible to extract information about each entry in the <code>Program Header</code> and <code>Section Header</code>.</p>
<p>Now, let's focus on the contents of the <code>Program Header</code>.</p>
<table><thead><tr><th>Attribute</th><th>Meaning</th></tr></thead><tbody>
<tr><td><code>p_type</code></td><td>Represents the type of the <code>Segment</code> pointed to by this <code>Program Header</code>, providing hints on how to interpret it</td></tr>
<tr><td><code>p_offset</code></td><td>File offset value to the <code>Segment</code> pointed to by this <code>Program Header</code></td></tr>
<tr><td><code>p_paddr</code></td><td>In systems where physical addresses are meaningful, this value points to the physical address of the <code>Segment</code> pointed to by this <code>Program Header</code></td></tr>
<tr><td><code>p_filesz</code></td><td>Byte size of the file image of the <code>Segment</code> pointed to by this <code>Program Header</code></td></tr>
<tr><td><code>p_memsz</code></td><td>Byte size of the memory image of the <code>Segment</code> pointed to by this <code>Program Header</code></td></tr>
<tr><td><code>p_flags</code></td><td>Flags that indicate information about the <code>Segment</code> pointed to by this <code>Program Header</code>, such as executable, writable, and readable</td></tr>
</tbody></table>
<p>As mentioned earlier, by interpreting the contents of the <code>Program Header</code>, you can obtain information about the position, size, and how to interpret the respective segment. For our purposes, understanding the structure of the <code>Program Header</code> is sufficient, so we will omit details about the <code>Section Header</code> and other components.</p>
<p>Now, the <code>vmlinux.bin</code> we will be working with has five <code>Program Header</code> entries, with the first four having a <code>p_type</code> value of <code>PT_LOAD</code>, and the last one having <code>PT_NOTE</code>. Let's extract some details about <code>PT_LOAD</code> and <code>PT_NOTE</code> from the <a href="https://linuxjm.osdn.jp/html/LDP_man-pages/man5/elf.5.html">Man page of ELF</a>:</p>
<table><thead><tr><th><code>p_type</code></th><th>Meaning</th></tr></thead><tbody>
<tr><td><code>PT_LOAD</code></td><td>Represents a loadable <code>Segment</code> described by <code>p_filesz</code> and <code>p_memsz</code>.</td></tr>
<tr><td><code>PT_NOTE</code></td><td>Contains auxiliary information for location and size.</td></tr>
</tbody></table>
<p>In the case of <code>PT_LOAD</code>, the byte sequence of the file is associated with the beginning of the memory segment. You can load the segment's contents into memory by copying the data from the address corresponding to the segment's memory address, calculated using <code>p_offset</code>, for the size specified by <code>p_memsz</code>.</p>
<p>With this minimal knowledge of ELF, let's proceed to analyze the content of <code>vmlinux.bin</code>.</p>
<h2 id="analyzing-vmlinux"><a class="header" href="#analyzing-vmlinux">Analyzing vmlinux</a></h2>
<p>Let's analyze the content of <code>vmlinux</code> now. Some of the information we'll extract will be crucial for future tasks. The <code>readelf</code> command is a powerful tool for dumping ELF-formatted files in a human-readable format. In this section, we will display the ELF Header (<code>-h</code>) and Program Header (<code>-l</code>) of <code>vmlinux.bin</code>.</p>
<pre><code class="language-bash">$ readelf -h -l vmlinux.bin
ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF64
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              EXEC (Executable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x1000000
  Start of program headers:          64 (bytes into file)
  Start of section headers:          21439000 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           56 (bytes)
  Number of program headers:         5
  Size of section headers:           64 (bytes)
  Number of section headers:         36
  Section header string table index: 35

Program Headers:
  Type           Offset             VirtAddr           PhysAddr
                 FileSiz            MemSiz              Flags  Align
  LOAD           0x0000000000200000 0xffffffff81000000 0x0000000001000000
                 

 0x0000000000b72000 0x0000000000b72000  R E    0x200000
  LOAD           0x0000000000e00000 0xffffffff81c00000 0x0000000001c00000
                  0x00000000000b0000 0x00000000000b0000  RW     0x200000
  LOAD           0x0000000001000000 0x0000000000000000 0x0000000001cb0000
                  0x000000000001f658 0x000000000001f658  RW     0x200000
  LOAD           0x00000000010d0000 0xffffffff81cd0000 0x0000000001cd0000
                  0x0000000000133000 0x0000000000413000  RWE    0x200000
  NOTE           0x0000000000a031d4 0xffffffff818031d4 0x00000000018031d4
                  0x0000000000000024 0x0000000000000024         0x4

Section to Segment mapping:
  Segment Sections...
   00     .text .notes __ex_table .rodata .pci_fixup __ksymtab __ksymtab_gpl __kcrctab __kcrctab_gpl __ksymtab_strings __param __modver
   01     .data __bug_table .vvar
   02     .data..percpu
   03     .init.text .altinstr_aux .init.data .x86_cpu_dev.init .parainstructions .altinstructions .altinstr_replacement .iommu_table .apicdrivers .exit.text .smp_locks .data_nosave .bss .brk
   04     .notes
</code></pre>
<p>From the ELF Header, we can see that the &quot;Entry point address&quot; (<code>e_entry</code> value) represents the address (<code>0x0100_0000</code>) where the ELF process starts, which is essential. This value is returned as the result of loading the kernel using <code>rust-vmm/linux-loader</code>, and it's also the value to set in the vCPU's <code>eip</code> (instruction pointer) to start the process.</p>
<p>The <code>e_phnum</code> value in the ELF Header (<code>Number of program headers</code>) is <code>5</code>, which matches the number of Program Headers (<code>Program Header Table</code> entries). The Program Headers are displayed next, with the first four having a <code>Type</code> of <code>LOAD</code>, and the last one being <code>NOTE</code>. Additionally, the first and fourth <code>LOAD</code> entries are marked as executable, indicating that executable code is present around these segments. The first entry is especially important as it likely corresponds to the entry point of the kernel's executable code.</p>
<h2 id="implementation-in-toyvmm"><a class="header" href="#implementation-in-toyvmm">Implementation in ToyVMM.</a></h2>
<p>In ToyVMM, the loading of <code>vmlinux</code> is done within the <code>load_kernel</code> function in <code>src/builder.rs</code>. This function takes <code>boot_config</code> information, which includes the path to the kernel file, and the memory (<code>guest_memory</code>) allocated for the VM.</p>
<p>Within <code>load_kernel</code>, <code>rust-vmm/linux-loader</code>'s <code>Elf</code> structure (imported as <code>Loader</code>) is used. This structure implements the <code>KernelLoader</code> trait, and its <code>load</code> function is responsible for loading ELF-formatted kernels into <code>guest_memory</code>. Here's an excerpt from the code:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use linux_loader::elf::Elf as Loader;

let entry_addr = Loader::load::&lt;File, memory::GuestMemoryMmap&gt;(
    guest_memory,
    None,
    &amp;mut kernel_file,
    Some(GuestAddress(arch::x86_64::get_kernel_start())),
).map_err(StartVmError::KernelLoader)?;
<span class="boring">}
</span></code></pre></pre>
<p>Now, let's delve deeper into the implementation of <code>linux-loader</code>. In <code>linux-loader</code>, the <code>KernelLoader</code> trait is defined, and its definition looks like this:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Trait that specifies kernel image loading support.
pub trait KernelLoader {
    /// How to load a specific kernel image format into the guest memory.
    ///
    /// # Arguments
    ///
    /// * `guest_mem`: [`GuestMemory`] to load the kernel in.
    /// * `kernel_offset`: Usage varies between implementations.
    /// * `kernel_image`: Kernel image to be loaded.
    /// * `highmem_start_address`: Address where high memory starts.
    ///
    /// [`GuestMemory`]: https://docs.rs/vm-memory/latest/vm_memory/guest_memory/trait.GuestMemory.html
    fn load&lt;F, M: GuestMemory&gt;(
        guest_mem: &amp;M,
        kernel_offset: Option&lt;GuestAddress&gt;,
        kernel_image: &amp;mut F,
        highmem_start_address: Option&lt;GuestAddress&gt;,
    ) -&gt; Result&lt;KernelLoaderResult&gt;
    where
        F: Read + Seek;
}
<span class="boring">}
</span></code></pre></pre>
<p>As inferred from the comments, this trait requires the <code>load</code> function to be implemented, which should load a specific kernel image format into the guest memory.
In the case of <code>linux-loader</code>, there are implementations for x86_64 that support loading ELF format kernels, and it also appears to have implementations for bzImage format kernels. However, for this discussion, let's focus on the ELF implementation.</p>
<p>The <code>load</code> function, which is expected to be implemented for ELF, performs the following steps:</p>
<ol>
<li>Extract the data from the beginning of the ELF file up to the size of the ELF header.</li>
<li>Create an instance of the <code>KernelLoaderResult</code> struct named <code>loader_result</code> and store the value of the ELF header's <code>e_entry</code> field in its <code>kernel_load</code> member. This value represents the address where the system will initially transfer control, which is essentially the starting point of the process.</li>
<li>Seek within the ELF file to the address where the program header table is located (determined by <code>e_phoff</code>), and then loop over all program headers (up to <code>e_phnum</code>) in the ELF file.</li>
<li>While looping over the program headers, perform the following actions:
<ul>
<li>Seek within the ELF file to the location of the segment corresponding to the currently inspected program header (determined by <code>p_offset</code>).</li>
<li>Write the data from <code>kernel_image</code> (which has already been seeked to the beginning of the segment's data) into the guest memory, starting from the address calculated from <code>mem_offset</code> to the size of the segment (<code>p_filesz</code>).</li>
<li>Update the value of <code>kernel_end</code> (the address of the end of the loaded segment in GuestMemory) and store the larger value between <code>loader_result.kernel_end</code> and the newly calculated value in <code>loader_result.kernel_end</code>.</li>
</ul>
</li>
<li>After looping through all program headers, return <code>loader_result</code> as the final result.</li>
</ol>
<p>This code essentially interprets and loads ELF files according to the ELF format. The returned <code>KernelLoaderResult</code> struct contains important information about the starting and ending positions of the kernel in GuestMemory, with the starting position being particularly crucial for use in <a href="./02-4_setup_registers_of_vcpu.html">Setup registers of vCPU</a>.</p>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><a href="https://valinux.hatenablog.com/entry/20200910">vmlinux</a></li>
<li><a href="https://www.hazymoon.jp/OpenBSD/annex/elf.html">ELF Formatについて</a></li>
<li><a href="https://linuxhint.com/understanding_elf_file_format/">Understanding the ELF File Format</a></li>
<li><a href="https://qiita.com/niwaka_dev/items/b915d1ffc7a677c74959">ELF形式のヘッダ部分を解析する単純なプログラムを作ってみた</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="loading-initrd"><a class="header" href="#loading-initrd">Loading initrd</a></h1>
<p>In this document, we will discuss loading and configuring <code>initrd</code> (<code>initramfs</code>) in order to boot a VM. When we mention <code>initrd</code> in the following sections, we are implicitly referring to <code>initramfs</code>. A detailed explanation of <code>initramfs</code> itself can be found in <a href="./02-1_overview_of_booting_linux.html">Overview of booting Linux</a>, so please refer to that section for more information.</p>
<h2 id="loading-initrd-and-setting-up-kernel-header-parameters"><a class="header" href="#loading-initrd-and-setting-up-kernel-header-parameters">Loading initrd and setting up kernel header parameters</a></h2>
<p>The function responsible for loading <code>initrd</code> is implemented as <code>load_initrd</code>. It takes two arguments: the memory allocated for the Guest and a mutable reference to the <code>File</code> structure representing the opened <code>initrd</code> file (implementing <code>Read</code> and <code>Seek</code> traits).</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn load_initrd&lt;F&gt;(
    vm_memory: &amp;memory::GuestMemoryMmap,
    image: &amp;mut F,
) -&gt; std::result::Result&lt;InitrdConfig, StartVmError&gt;
where F: Read + Seek {
    let size: usize;
    // Get image size
    match image.seek(SeekFrom::End(0)) {
        Err(e) =&gt; return Err(StartVmError::InitrdRead(e)),
        Ok(0) =&gt; {
            return Err(StartVmError::InitrdRead(io::Error::new(
                io::ErrorKind::InvalidData,
                &quot;Initrd image seek returned a size of zero&quot;,
            )))
        }
        Ok(s) =&gt; size = s as usize,
    };
    // Go back to the image start
    image.seek(SeekFrom::Start(0)).map_err(StartVmError::InitrdRead)?;
    // Get the target address
    let address = arch::initrd_load_addr(vm_memory, size)
        .map_err(|_| StartVmError::InitrdLoad)?;

    // Load the image into memory
    //   - read_from is defined as trait methods of Bytes&lt;A&gt;
    //     and GuestMemoryMmap implements this trait.
    vm_memory
        .read_from(GuestAddress(address), image, size)
        .map_err(|_| StartVmError::InitrdLoad)?;

    Ok(InitrdConfig{
        address: GuestAddress(address),
        size,
    })
}
<span class="boring">}
</span></code></pre></pre>
<p>The function performs the following steps:</p>
<ol>
<li>Retrieves the size of the <code>initrd</code> by seeking to the end of the file and then returning to the start.</li>
<li>Calculates the target address in Guest memory where the <code>initrd</code> should be loaded.</li>
<li>Loads the contents of the <code>initrd</code> file into the specified Guest memory address.</li>
<li>Returns an <code>InitrdConfig</code> structure containing the Guest memory address and size of the loaded <code>initrd</code>.</li>
</ol>
<p>Once the <code>initrd</code> is loaded into memory, we need to configure the kernel's setup header. This header information is defined by the <a href="https://docs.kernel.org/x86/boot.html#the-real-mode-kernel-header">Boot Protocol</a>. In ToyVMM, these settings are primarily configured in the <code>configure_system</code> function. The table below outlines the relevant settings, which are documented in the Boot Protocol:</p>
<table><thead><tr><th>Offset/Size</th><th>Name</th><th>Meaning</th><th>ToyVMM value</th></tr></thead><tbody>
<tr><td>01FE/2</td><td>boot_flag</td><td>0xAA55 magic number</td><td>0xaa55</td></tr>
<tr><td>0202/4</td><td>header</td><td>Magic signature &quot;HdrS&quot; (0x53726448)</td><td>0x5372_6448</td></tr>
<tr><td>0210/1</td><td>type_of_loader</td><td>Boot loader identifier</td><td>0xff (undefined)</td></tr>
<tr><td>0218/4</td><td>ramdisk_image</td><td>initrd load address (set by boot loader)</td><td>GUEST ADDRESS OF INITRD</td></tr>
<tr><td>021C/4</td><td>ramdisk_size</td><td>initrd size (set by boot loader)</td><td>SIZE OF INITRD</td></tr>
<tr><td>0228/4</td><td>cmd_line_ptr</td><td>32-bit pointer to the kernel command line</td><td>0x20000</td></tr>
<tr><td>0230/4</td><td>kernel_alignment</td><td>Physical addr alignment required for kernel</td><td>0x0100_0000</td></tr>
<tr><td>0238/4</td><td>cmdline_size</td><td>Maximum size of the kernel command line</td><td>SIZE OF CMDLINE STRING</td></tr>
</tbody></table>
<p>These values are written to Guest memory starting at address <code>0x7000</code>. The <code>0x7000</code> address is also stored in RSI, a vCPU register, for reference during VM startup. For details on vCPU register setup, please refer to <a href="./02-4_setup_registers_of_vcpu">Setup registers of vCPU</a>.</p>
<h2 id="setup-e820"><a class="header" href="#setup-e820">Setup E820</a></h2>
<p>Configuring the E820 for the Guest OS allows reporting of available memory regions to the OS and BootLoader. The settings for this are aligned with the implementation in Firecracker. The following code illustrates how the E820 entries are added based on the Guest memory configuration:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>add_e820_entry(&amp;mut params, 0, EBDA_START, E820_RAM)?;
let first_addr_past_32bits = GuestAddress(FIRST_ADDR_PAST_32BITS);
let end_32bit_gap_start = GuestAddress(MMIO_MEM_START);
let himem_start = GuestAddress(HIGH_MEMORY_START);
let last_addr = guest_mem.last_addr();
if last_addr &lt; end_32bit_gap_start {
    add_e820_entry(
        &amp;mut params,
        himem_start.raw_value() as u64,
        last_addr.unchecked_offset_from(himem_start) as u64 + 1,
        E820_RAM)?;
} else {
    add_e820_entry(
        &amp;mut params,
        himem_start.raw_value(),
        end_32bit_gap_start.unchecked_offset_from(himem_start),
        E820_RAM)?;
    if last_addr &gt; first_addr_past_32bits {
        add_e820_entry(
            &amp;mut params,
            first_addr_past_32bits.raw_value(),
            last_addr.unchecked_offset_from(first_addr_past_32bits) + 1,
            E820_RAM)?;
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>It would be better to understand the design of the entire address space for the Guest VM, considering the code for starting a Guest VM in ToyVMM. Therefore, I'll list the current memory design for the Guest in the following table. Please note that this information may change in the future.</p>
<table><thead><tr><th>Guest Address</th><th>Contents</th><th>Note</th></tr></thead><tbody>
<tr><td>0x0 - 0x9FBFF</td><td>E820</td><td></td></tr>
<tr><td>0x7000 - 0x7FFF</td><td>Boot Params (Header)</td><td>ZERO_PAGE_START(=0x7000)</td></tr>
<tr><td>0x9000 - 0x9FFF</td><td>PML4</td><td>Now only 1 entry (8byte), maybe expand later</td></tr>
<tr><td>0xA000 - 0xAFFF</td><td>PDPTE</td><td>Now only 1 entry (8byte), maybe expand later</td></tr>
<tr><td>0xB000 - 0xBFFF</td><td>PDE</td><td>Now 512 entry (4096byte)</td></tr>
<tr><td>0x20000 -</td><td>CMDLINE</td><td>Size depends on cmdline parameter len</td></tr>
<tr><td>0x100000</td><td></td><td>HIGH_MEMORY_START</td></tr>
<tr><td>0x100000 - 0x7FFFFFF</td><td>E820</td><td></td></tr>
<tr><td>0x100000 - 0x20E3000</td><td>vmlinux.bin</td><td>Size depends on vmlinux.bin's size</td></tr>
<tr><td>0x6612000 - 0x7FFF834</td><td>initrd.img</td><td>Size depends on initrd.img's size</td></tr>
<tr><td>0x7FFFFFF</td><td>GuestMemory last address</td><td>based on (128 &lt;&lt; 20 = 128MB = 0x8000000) - 1</td></tr>
<tr><td>0xD0000000</td><td></td><td>MMIO_MEM_START（4GB - 768MB）</td></tr>
<tr><td>0xD0000000 - 0xFFFFFFFF</td><td></td><td>MMIO_MEM_START - FIRST_ADDR_PAST_32BIT</td></tr>
<tr><td>0x100000000</td><td></td><td>FIRST_ADDR_PAST_32BIT (4GB~)</td></tr>
</tbody></table>
<p>Upon examining the code, you can see that the address range that is designed independently of the GuestMemory size (roughly <code>0x0 ~ HIGH_MEMORY_START</code>) is commonly registered as &quot;Usable&quot; in the E820, ranging from <code>0</code> to <code>EBDA_START</code> (<code>0x9FBFF</code>).</p>
<p>Subsequently, the range registered in the E820 changes depending on how much GuestMemory is allocated. In the current implementation, the GuestMemory is set to reserve 128MB of memory by default, so the Guest Memory ranges from <code>0x0</code> to <code>0x7FF_FFFF</code>. In this range, <code>vmlnux.bin</code> content and <code>initrd.img</code> are mapped.</p>
<p>In other words, the logic <code>guest_mem.last_addr() = 0x7FF_FFFF &lt; 0xD000_0000 = end_32bit_gap_start</code> applies, so the range <code>HIGH_MEMORY_START ~ guest_mem.last_addr()</code> is additionally registered. In the future, as you expand, if the GuestMemory size exceeds 4GB, you will register the ranges <code>0x10_0000 ~ 0xD000_0000</code> and <code>0x1_000_0000 ~ guest_mem.last_addr()</code>.</p>
<p>You will be able to confirm the console output when starting the VM shortly. Here, I've provided part of the output to show that the E820 entries you configured are registered:</p>
<pre><code class="language-bash">[    0.000000] e820: BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007ffffff] usable
</code></pre>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<ul>
<li><a href="https://nishidy.hatenablog.com/entry/2016/09/08/230637">Linuxのブートシーケンスの基礎まとめ</a></li>
<li><a href="https://doc.kusakata.com/admin-guide/initrd.html">Linuxカーネルユーザ・管理者ガイド - 初期RAMdディスクを使用する</a></li>
<li><a href="https://manpages.ubuntu.com/manpages/bionic/ja/man4/initrd.4.html">initrd</a></li>
<li><a href="https://www.gcd.org/blog/2007/09/129/">initramfs(initrd)のinitをbusyboxだけで書いてみた</a></li>
<li>[initramfsとinitrdについて](https://blog.goo.ne.jp/pepolinux/e/4d1f4b6e0f5b5ed389f</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setup-registers-of-vcpu"><a class="header" href="#setup-registers-of-vcpu">Setup registers of vCPU</a></h1>
<p>In this document, we will describe the configuration of vCPU registers. While registers are commonly discussed collectively, there are various types of registers, making it complex to determine how to set each of them. The content related to registers explained in this document focuses solely on the aspect of starting a virtual machine (VM). Additionally, as we want to boot the Guest OS in 64-bit mode, we will briefly explain some settings required for transitioning to 64-bit mode and the associated paging.</p>
<h2 id="setup-vcpu-general-purpose-registers"><a class="header" href="#setup-vcpu-general-purpose-registers">Setup vCPU general-purpose registers</a></h2>
<p>Configuration of the vCPU's general-purpose registers can be done through the KVM <code>set_regs</code> API. For this example, we will set the values of the registers as follows (detailed explanations of each register are omitted):</p>
<table><thead><tr><th>Register</th><th>Value</th><th>Meaning</th></tr></thead><tbody>
<tr><td>RFLAGS</td><td>2</td><td>The bit at 0x02 must be set as a reserved bit</td></tr>
<tr><td>RIP</td><td>KERNEL START ADDRESS (<code>0x0100_0000</code>)</td><td>Address of the entry point obtained from the ELF</td></tr>
<tr><td>RSP</td><td>BOOT STACK POINTER (<code>0x8ff0</code>)</td><td>Address of the Stack Pointer used during boot</td></tr>
<tr><td>RBP</td><td>BOOT STACK POINTER (<code>0x8ff0</code>)</td><td>Set to match RSP before boot processing</td></tr>
<tr><td>RSI</td><td><code>boot_params</code> ADDRESS (<code>0x7000</code>)</td><td>Address where <code>boot_params</code> information is stored</td></tr>
</tbody></table>
<p>The RIP should store the instruction start address when the vCPU is launched. In this case, we specify the address of the kernel's entry point. Since we plan to execute in 64-bit Long Mode, RIP's address will be treated as a virtual memory address. However, to implement Paging with Identity Mapping, the virtual memory address will be equal to the physical memory address. For RSP and RBP, we put the addresses necessary for the boot stack. These values can be obtained from available memory. RSI should contain the address where the <code>boot_params</code> structure is stored. ToyVMM is created by mimicking Firecracker's values, so the address values stored in RSP, RBP, and RSI are mimicked from Firecracker.</p>
<h2 id="setup-vcpu-special-registers"><a class="header" href="#setup-vcpu-special-registers">Setup vCPU special registers</a></h2>
<p>Configuration of vCPU special registers can be done through the KVM <code>set_sregs</code> API. In this section, we will focus on the registers that are actually configured while briefly mentioning the background. The following explanations may introduce some unfamiliar terms. If you encounter such terms, please take the time to look them up.</p>
<h4 id="idt-interrupt-descriptor-table"><a class="header" href="#idt-interrupt-descriptor-table">IDT (Interrupt Descriptor Table)</a></h4>
<p>The <a href="https://wiki.osdev.org/Interrupt_Descriptor_Table">IDT (Interrupt Descriptor Table)</a> is a data structure that holds information about interrupts and exceptions in Protected Mode and Long Mode. Originally, in Real Mode, there was the Interrupt Vector Table (IVT), which served the purpose of informing the CPU where the Interrupt Service Routines (ISRs) were located. In other words, it held handlers for each interrupt or exception, allowing the system to determine which handler to invoke when they occurred.</p>
<p>In Protected Mode and Long Mode, the address representation is different from Real Mode, so IDT is a mechanism that provides similar capabilities but adapted to these modes. The IDT is a table with a maximum of 255 entries, and the IDT's address needs to be set in the IDTR register. When an interrupt occurs, the CPU references the IDT from the IDTR value and executes the specified interrupt handler.</p>
<p>According to the <a href="https://docs.kernel.org/x86/boot.html#id1">64-bit Boot Protocol</a>, interrupts should be set to &quot;Disabled.&quot; Therefore, the IDT-related configuration is omitted in the ToyVMM (Firecracker) implementation, and we won't delve into the details of the IDT here.</p>
<h4 id="segmentation-gdt-global-descriptor-table-ldt-local-descriptor-table"><a class="header" href="#segmentation-gdt-global-descriptor-table-ldt-local-descriptor-table">Segmentation, GDT (Global Descriptor Table), LDT (Local Descriptor Table)</a></h4>
<p>Before discussing GDT, let's briefly introduce segmentation. Memory segmentation is a memory management method where programs and data are managed in variable-sized blocks called segments. Segments are groups of information categorized by attributes in memory, and they are one of the memory management methods used to implement virtual memory and memory protection. In Linux, segmentation is used in conjunction with paging, assuming a flat memory model. For the rest of this discussion, we will proceed with this assumption.</p>
<p>The <a href="https://wiki.osdev.org/Interrupt_Descriptor_Table">GDT (Global Descriptor Table)</a> is a data structure used to manage memory segments. This structure closely resembles the IDT. The GDT is a table with multiple entries called Segment Descriptors, and the GDT's address needs to be set in the GDTR register. The entries in this table are accessed by the Segment Selector, and they provide information about which address range is covered, what operations are allowed in that region, and other details. The Segment Selector appears in Segmentation Registers and the format of each Entry in the IDT, such as the Gate Descriptor and Task State Segment. We will omit detailed explanations here, so please research further if needed.</p>
<p>The <a href="https://wiki.osdev.org/Local_Descriptor_Table">LDT (Local Descriptor Table)</a> is a data structure used to manage segments, similar to GDT. However, LDT can be held separately for each task or thread, distinguishing it from GDT. Having a separate GDT descriptor for each task allows segments to be shared among a task's own programs while keeping them separate from segments used by different tasks, enhancing security between tasks. Since LDT is not relevant to this implementation, we will also skip detailed explanations about it.</p>
<h3 id="gdt-setup-for-64-bit-mode"><a class="header" href="#gdt-setup-for-64-bit-mode">GDT setup for 64-bit mode</a></h3>
<p>As specified in the <a href="https://docs.kernel.org/x86/boot.html#id1">64-bit Boot Protocol</a>, in 64-bit mode, each Segment Descriptor must be set up as a 4G flat segment. Code and Data Segments should be assigned the appropriate permissions. The <a href="https://wiki.osdev.org/Global_Descriptor_Table">Global Descriptor Table</a> indicates that in 64-bit mode, base and limit are essentially ignored, and each Descriptor covers the entire linear address space, except for the flags. Therefore, it seems that the values for flags other than the flags are not critical. Nonetheless, in this example, explicit setup is done to ensure a flat segment. Additionally, it is mentioned that the values for <code>DS</code>, <code>ES</code>, and <code>SS</code> should be the same as <code>DS</code>, so this is implemented accordingly.</p>
<p>Subsequently, we will examine how these settings are configured in ToyVMM (you can read it as Firecracker). These settings are done in the <code>configure_seguments_and_sregs</code> function. To make it easier to understand, some comments have been added:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn configure_segments_and_sregs(sregs: &amp;mut kvm_sregs, mem: &amp;GuestMemoryMmap) -&gt; Result&lt;(), RegError&gt; {
    let gdt_table: [u64; BOOT_GDT_MAX as usize] = [
        gdt::gdt_entry(0, 0, 0),            // NULL
        gdt::gdt_entry(0xa09b, 0, 0xfffff), // CODE
        gdt::gdt_entry(0xc093, 0, 0xfffff), // DATA
        gdt::gdt_entry(0x808b, 0, 0xfffff), // TSS
    ];
    // &gt; https://wiki.osdev.org/Global_Descriptor_Table
    //
    //              55 52     47     40 39        31               16 15                0
    // CODE: 0b0..._1010_1111_1001_1011_0000_0000_0000_0000_0000_0000_1111_1111_1111_1111
    //              &lt;-f-&gt;     &lt;-Access-&gt;&lt;---------------------------&gt; &lt;----- limit -----&gt;
    // - Flags  : 1010      =&gt; G(limit is in 4KiB), L(Long mode)
    // - Access : 1001_1011 =&gt; P(must 1), S(code/data type), E(executable), RW(readable/writable), A(CPU access allowed)
    //   - 0xa09b of A,9,B represents above values
    //
    // DATA: 0b0..._1100_1111_1001_0011_0000_0000_0000_0000_0000_0000_1111_1111_1111_1111
    // - Flags  : 1100      =&gt; G(limit is in 4KiB), DB(32-bit protected mode)
    // - Access : 1001_0011 =&gt; P(must 1), S(code/data type), RW(readable/writable), A(CPU access allowed)
    //
    // TSS
    // - Flags  : 1000      =&gt; G(limit is in 4KiB)
    // - Access : 1000_1011 =&gt; P(must 1), E(executable), RW(readable/writable), A(CPU access allowed)
    //    - TSS requires to support Intel VT
    let code_seg = gdt::kvm_segment_from_gdt(gdt_table[1], 1);
    let data_seg = gdt::kvm_segment_from_gdt(gdt_table[2], 2);
    let tss_seg = gdt::kvm_segment_from_gdt(gdt_table[3], 3);

    // Write segments
    write_gdt_table(&amp;gdt_table[..], mem)?;
    sregs.gdt.base = BOOT_GDT_OFFSET as u64;
    sregs.gdt.limit = mem::size_of_val(&amp;gdt_table) as u16 - 1;

    write_idt_value(0, mem)?;
    sregs.idt.base = BOOT_IDT_OFFSET as u64;
    sregs.idt.limit = mem::size_of::&lt;u64&gt;() as u16 - 1;

    sregs.cs = code_seg;
    sregs.ds = data_seg;
    sregs.es = data_seg;
    sregs.fs = data_seg;
    sregs.gs = data_seg;
    sregs.ss = data_seg;
    sregs.tr = tss_seg;

    // 64-bit protected mode
    sregs.cr0 |= X86_CR0_PE;
    sregs.efer |= EFER_LME | EFER_LMA;
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>In the above code, a table with 4 entries is created as the GDT to set up. The first entry must be Null as required by the GDT. For the rest, it can be seen that settings for the CODE Segment, DATA Segment, and TSS Segment are made for the entire memory region.
The TSS setting is done to meet the requirements of Intel VT, and it's not substantially used within the scope of this document.</p>
<p>Now, when creating this GDT, a function called <code>gdt_entry</code> is called to create each entry. Here's the code for this function:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn gdt_entry(flags: u16, base: u32, limit: u32) -&gt; u64 {
    ((u64::from(base) &amp; 0xff00_0000u64) &lt;&lt; (56 - 24))
        | ((u64::from(flags) &amp; 0x0000_f0ffu64) &lt;&lt; 40)
        | ((u64::from(limit) &amp; 0x000f_0000u64) &lt;&lt; (48 - 16))
        | ((u64::from(base) &amp; 0x00ff_ffffu64) &lt;&lt; 16)
        | (u64::from(limit) &amp; 0x0000_ffffu64)
}
<span class="boring">}
</span></code></pre></pre>
<p>For this function, all entries have <code>0x0</code> as the base and <code>0xFFFFF</code> (<code>2^5 = 32-bit = 4GB</code>) as the limit, which makes it a flat segmentation. The <code>flags</code> argument for each entry is configured individually, which in turn corresponds to the values in GDT's <code>Flags</code> and <code>AccessByte</code>. If you look at the comments in the code, you can see the values returned by <code>gdt_entry</code> for each entry and what those values represent when parsed. According to the comments, as required by the <a href="https://docs.kernel.org/x86/boot.html#id1">64-bit Boot Protocol</a>, the CODE Segment has Execute/Read permission and the &quot;long mode (64-bit code segment)&quot; flag, while the DATA Segment has Read/Write permission.</p>
<p>The GDT created as mentioned above is written to GuestMemory using the <code>write_gdt_table</code> function, and the starting address of that is stored in <code>sregs.gdt.base</code>.</p>
<p>Regarding the subsequent IDT settings, as mentioned earlier, it appears to be disabled. Therefore, nothing is written to memory. However, the code decides on which address in GuestMemory to use and stores that address in <code>sregs.idt.base</code>.</p>
<p>Continuing, other register values are set. As mentioned earlier, <code>CS</code> is set with information about the CODE Segment, and <code>DS</code>, <code>ES</code>, <code>SS</code> are set with information about the DATA Segment, while <code>TR</code> is set with information about the TSS Segment. In the code above, <code>FS</code> and <code>GS</code> are also set with information about the DATA Segment, but these segment values may not need to be configured.</p>
<p>Finally, settings are made for CR0 and EFER registers, which will be explained later.</p>
<h3 id="64-bit-protected-mode"><a class="header" href="#64-bit-protected-mode">64-bit protected mode</a></h3>
<p>The <code>Long mode</code> is the native mode for x86_64 processors, offering several additional features compared to the legacy x86 mode. However, we won't go into the details of these additional features here. <code>Long mode</code> consists of two submodes: <code>64-bit mode</code> and <code>compatibility mode</code>.</p>
<p>To switch to 64-bit mode, you need to perform the following steps:</p>
<ol>
<li>Set <code>CR4.PAE</code> to enable Physical Address Extension (PAE).</li>
<li>Create the Page Table and load the address of the top-level page table into <code>CR3</code> register.</li>
<li>Set <code>CR0.PG</code> to enable Paging.</li>
<li>Set <code>EFER.LME</code> to enable Long Mode.</li>
</ol>
<p>Setting the values in the registers involves updating the corresponding fields in the <code>kvm_sregs</code> structure and then configuring them using <code>set_sregs</code>. The key part is creating the Page Table.</p>
<h4 id="4-level-page-table-for-entering-64-bit-mode"><a class="header" href="#4-level-page-table-for-entering-64-bit-mode">4-Level Page Table for entering 64-bit mode</a></h4>
<p>The processes related to booting the Linux Kernel are categorized into several stages based on the available memory address space. Immediately after booting, the process of setting up and interacting with physical memory addresses is known as <code>x16 Real-Mode</code>, which operates in a 16-bit memory alignment.</p>
<p>On the other hand, as many readers are aware, familiar operating systems like ours can be either 32-bit or 64-bit. These distinctions are made possible through a feature known as CPU mode switching, which transitions the CPU into modes called <code>x32 Protected Mode</code> and <code>x64 Long Mode</code>. Once switched to these modes, the CPU can only utilize virtual memory addresses.</p>
<p>Especially in the x64 CPU architecture, a 4-level page table is typically used to translate 64-bit virtual addresses into physical addresses. This means that before switching to <code>x64 Long Mode</code>, a 4-level page table must be constructed and conveyed to the CPU. This process is implemented as part of the BootLoader's functionality.</p>
<p>Now, another crucial point to consider is that while the RIP value currently contains the <strong>physical address</strong> value indicating the kernel's entry point, when handling it in <code>x64 Long Mode</code>, this address is used as a <strong>virtual address</strong>. Therefore, if this address were to be mapped to a different physical address, the OS would fail to boot.</p>
<p>Hence, at this stage, a simple page table is created where virtual memory addresses map to the same physical memory addresses. This is often referred to as Identity Mapping and addresses the issue mentioned above.</p>
<p>Note: It's important to note that the page table created by the BootLoader for x64 is a temporary requirement for executing the kernel. When we typically think of virtual memory addresses and page tables, we often associate them with user-space processes. However, the paging mechanism for user processes is implemented within the kernel and is configured when the kernel boots. Therefore, the mechanism for translating BootLoader's page table, whether it's Identity Mapping or not, has no impact on the paging mechanism for individual processes after the OS boots.</p>
<h4 id="page-table-implementation-in-toyvmm"><a class="header" href="#page-table-implementation-in-toyvmm">Page Table implementation in ToyVMM</a></h4>
<p>Let's dive into the specific implementation of ToyVMM to understand the Page Table configuration better. This implementation closely follows that of Firecracker.</p>
<p>Let's briefly discuss the structure of the 4-Level Page Table. Essentially, at each level, there exists a table with its own designation:</p>
<p>Level 4: Page Map Level 4 (PML4)
Level 3: Page Directory Pointer Table (PDPT)
Level 2: Page Directory Table (PDT)
Level 1: Page Tables (PT)</p>
<p>Each table can hold 512 entities, and one entity consists of 8 bytes (64 bits).
Therefore, the entire table size is 512 (entities) * 8 (bytes per entity) = 4096 bytes.
This size conveniently fits into a single page (4KB).</p>
<p>The structure of each level's entity is as follows:</p>
<img src="../02_figs/cr3_and_paging.svg" width="100%">
<blockquote>
<p>Source: <a href="https://alessandropellegrini.it/didattica/2017/aosv/1.Initial-Boot-Sequence.pdf">x86 Initial Boot Sequence</a> and <a href="https://wiki.osdev.org/Paging">OSdev/Paging</a></p>
</blockquote>
<p>From the above, it seems that the setup should satisfy the following conditions:</p>
<ol>
<li>Consider the data within CR3, which serves as the address of PML4, as ranging from bits 12 to 32+ in order to design the PML4 address.</li>
<li>To enable the PML4, set the 0th bit, and design the address of PDPT within the range of bits 12 to 32+.</li>
<li>To utilize the layout of PDPTE page directory, do not set the 7th bit of PDPTE, and design the address of PD within the range of bits 12 to 32+.</li>
<li>To allow 2MB pages in PDE, set the 7th bit and design the Physical Address within the range of bits 21 to 32+.</li>
<li>In Firecracker, it appears that 2MiB paging is implemented without using Level 1 Page Tables (i.e., without using 4KiB pages). ToyVMM's implementation follows suit.</li>
</ol>
<p>Now, let's extract the actual code from the implementation based on the above.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn setup_page_tables(sregs: &amp;mut kvm_sregs, mem: &amp;GuestMemoryMmap) -&gt; Result&lt;(), RegError&gt; {
    let boot_pml4_addr = GuestAddress(PML4_START);
    let boot_pdpte_addr = GuestAddress(PDPTE_START);
    let boot_pde_addr = GuestAddress(PDE_START);

    // Entry converting VA [0..512GB)
    mem.write_obj(boot_pdpte_addr.raw_value() as u64 | 0x03, boot_pml4_addr)
        .map_err(|_| RegError::WritePdpteAddress)?;
    // Entry covering VA [0..1GB)
    mem.write_obj(boot_pde_addr.raw_value() as u64 | 0x03, boot_pdpte_addr)
        .map_err(|_| RegError::WritePdpteAddress)?;
    // 512 MB entries together covering VA [0..1GB).
    // Note we are assuming CPU support 2MB pages (/proc/cpuinfo has 'pse').
    for i in 0..512 {
        mem.write_obj((i &lt;&lt; 21) + 0x83u64, boot_pde_addr.unchecked_add(i * 8))
            .map_err(|_| RegError::WritePdeAddress)?;
    }
    sregs.cr3 = boot_pml4_addr.raw_value() as u64;
    sregs.cr4 |= X86_CR4_PAE;
    sregs.cr0 |= X86_CR0_PG;
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>As seen, the implementation is quite simple.</p>
<p><code>PML4_START</code>, <code>PDPTE_START</code>, and <code>PDE_START</code> have hardcoded address values, which are <code>PML4_START=0x9000</code>, <code>PDPTE_START=0xa000</code>, and <code>PDE_START=0xb000</code>, respectively, meeting the requirements of the address designs mentioned above.</p>
<p>From the code, it's clear that there is only one <code>PML4</code> and one <code>PDPT</code> Table, and only the initial entry is set up. This is sufficient in this implementation because the kernel's address being translated by these page tables is <code>0x0100_0000</code>. These tables, specifically <code>PML4</code> and <code>PDPT</code>, will always look at the first entry (as described later), making this implementation suitable.</p>
<p>In <code>PML4</code>, the information about the starting address of <code>PDPT</code> is written by taking the logical OR of that address with <code>0x03</code>. Similarly, in <code>PDPT</code>, the starting address of <code>PD</code> is written by taking the logical OR of that address with <code>0x03</code>. The reason for using <code>0x03</code> here is to set the 0th and 1st bits of <code>PML4E</code> and <code>PDPTE</code>, which correspond to the R/W permission flag and the existence flag of that entry. These bits are essential in this case.</p>
<p>For <code>PD</code>, a loop is used to create 512 entries. It writes the value resulting from shifting the loop's index by 21 bits to the beginning of PD's address, every 8 bytes (1 entry size) from the starting address. The reason for using <code>0x83</code> here is to set the R/W permission flag, the existence confirmation flag, and the flag that determines whether to treat it as a 2MB page frame. This flag-setting allows using the value obtained by offsetting 21 bits from the index as the address (utilizing the layout of <code>PDE 2MB page</code> in the diagram). Therefore, for <code>PDE</code>, the entry at index 0 corresponds to an address of <code>0x0000_0000</code>, and the entry at index 1 corresponds to an address of <code>0x0010_0000</code>, and so on, based on the value from the loop described above.</p>
<p>Now, let's check whether the kernel's address stored in EIP (<code>0x0100_0000</code>) is correctly converted using the Page Table we just created! As mentioned earlier, when transitioning to <code>x64 Long Mode</code>, this kernel address is treated as a 64-bit virtual address. Currently, ToyVMM (and Firecracker) loads the kernel at physical address <code>0x0100_0000</code>, and this value is stored in the <code>eip</code> register.</p>
<p>Therefore, by treating <code>0x0100_0000</code> as a virtual address and using the conversion table mentioned above, we expect the result of the address translation to be <code>0x0100_0000</code>.</p>
<p>Let's calculate it explicitly. When converting a 64-bit virtual address with 4-Level Page Table, you split the lower 48 bits of the virtual address into groups of <code>9 + 9 + 9 + 9 + 12</code> bits each. These four groups of 9 bits are used as the index values for each Page table entry. You look up the layout of the identified entry in this way, then check the physical address of the next Page Table, and similarly determine the entry to be used in the next Page Table based on the physical address and virtual address. Continuing this process will eventually yield the desired physical address. Since Pages are at least 4KB in size, the address value is also in multiples of 4KB, so the final 12 bits of the virtual address serve as the offset (<code>2^12 = 4KB</code>).</p>
<img src="../02_figs/4-level-page-table_and_address_translation.svg" width="100%">
<p>Let's remember that in this case, we have set the flag in PDE to treat it as a 2MB page frame. In this scenario, the result obtained from PDE is used directly as the physical address mapping. The 9 bits that are not used for PTE are treated as an offset, adding up to a total offset of 21 bits when combined with the original 12 bits. This 21-bit offset corresponds to the 2MB size. Similarly, when you set the flag in PDPTE, it is treated as a 1GB page frame.</p>
<p>Based on the above discussion, let's convert <code>0x0100_0000</code>. In binary representation for clarity, it is <code>0b0..._0000_0001_0000_0000_0000_0000_0000_0000</code>. Following the virtual address conversion method, it breaks down as follows:</p>
<table><thead><tr><th>Entry index for</th><th>Range of Virtual Address</th><th>Value</th></tr></thead><tbody>
<tr><td>Page Map Level4 (PML4)</td><td>47 ~ 39 bit</td><td><code>0b0_0000_0000</code></td></tr>
<tr><td>Page Directory Pointer Table (PDPT)</td><td>38 ~ 30 bit</td><td><code>0b0_0000_0000</code></td></tr>
<tr><td>Page Directory Table (PDT)</td><td>29 ~ 21 bit</td><td><code>0b0_0000_1000</code></td></tr>
<tr><td>Page Tables (PT)</td><td>20 ~ 12 bit</td><td><code>0b0_0000_0000</code></td></tr>
<tr><td>-</td><td>11 ~ 0  bit (offset)</td><td><code>0b0_0000_0000</code></td></tr>
</tbody></table>
<p>From this breakdown, you can see that the index values for <code>PML4E</code> and <code>PDPTE</code> are <code>0</code>, so you'll check the 64 bits directly from the beginning of each table. As implemented, <code>PML4E</code> at index 0 contains the address of <code>PDPT</code>, and <code>PDPTE</code> at index 0 contains the address of <code>PDT</code>. So, you follow this structure to reach <code>PDT</code>.</p>
<p>Now, the PDE's index value is <code>0b0_0000_1000</code> from the virtual memory address above, so you will check the 8th entry in <code>PDT</code>. The value stored in this entry for the 2MB Page frame area is <code>0b0...0000_1000</code>. Therefore, when you add the 21-bit offset to this value, you get <code>0b1_0000_0000_0000_0000_0000_0000 = 0x100_0000</code> as the resulting physical address after conversion. This matches the input virtual address.
Hence, even after the conversion, the kernel's entry point will still be pointed to, and the kernel will begin execution in 64-bit long mode.</p>
<img src="../02_figs/virt_phys_address_translation_example.svg" width="100%">
<p>It's worth noting that this Page Table, as designed in this implementation, effectively enables Identity Mapping in the range of <code>2^21 ~ 2^30-1</code>.</p>
<p><strong>Note</strong><br />
Upon revisiting the Page Table created this time, it's important to note that there is only one Entry for PML4 and PDPT. As a result, the virtual memory address range that can be targeted is at most <code>2^31 - 1</code>. If you go beyond this range, there would be cases where indices other than 0 are used for PML4E and PDPTE.</p>
<p>Additionally, in the PD's Entry, the 2MB page frame is enabled. Therefore, the lower 21 bits of the virtual memory address are treated as an offset. Furthermore, since the PDE's address design corresponds to an index, this Page Table effectively enables <strong>Identity Mapping in the range of <code>2^21</code> to <code>2^30 - 1</code></strong>.</p>
<h2 id="what-to-do-next"><a class="header" href="#what-to-do-next">What to do next?</a></h2>
<p>Up to this point, it's possible to start a Guest VM just by combining the discussed concepts. However, in this state, the Guest VM can be started but cannot be interacted with, leaving the setup somewhat incomplete. To ensure that the started Guest VM is configured as expected and for further interactions, we need to create an interface to control the Guest VM. In the next chapter, we will discuss the use of <code>Serial</code> and how to implement it within ToyVMM to allow keyboard interactions after starting the Guest VM!</p>
<h2 id="references-2"><a class="header" href="#references-2">References</a></h2>
<ul>
<li><a href="https://docs.kernel.org/x86/boot.html#id1">The Linux/x86 Boot Protocol - 64-bit Boot Protocol</a></li>
<li><a href="https://postd.cc/linux-bootstrap-4/">Linux Insides: カーネル起動プロセス part4</a></li>
<li><a href="https://wiki.osdev.org/Interrupt_Descriptor_Table">Global Descriptor Table (wiki)</a></li>
<li><a href="https://wiki.osdev.org/Interrupt_Descriptor_Table">Interrupt Descriptor Tabke (wiki)</a></li>
<li><a href="https://wiki.osdev.org/Segmentation">Segmentation (wiki)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Control_register#CR3">Control register (wiki)</a></li>
<li><a href="https://wiki.osdev.org/Segmentation">Long mode (wiki)</a></li>
<li><a href="https://alessandropellegrini.it/didattica/2017/aosv/1.Initial-Boot-Sequence.pdf">x86 initial boot sequence</a></li>
<li><a href="https://back.engineering/23/08/2020/">Virtual Memory - Intro to Paging Tables</a></li>
<li><a href="https://os.phil-opp.com/paging-introduction/">Writing an OS in Rust - Introduction to Paging</a></li>
<li><a href="https://www.intel.com/content/dam/support/us/en/documents/processors/pentium4/sb/25366821.pdf">Intel 64 and IA-32 Architectures Software Developer's Manual</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="serial-console-implementation"><a class="header" href="#serial-console-implementation">Serial Console implementation</a></h1>
<h2 id="about-serial-uart-and-ttys0"><a class="header" href="#about-serial-uart-and-ttys0">About Serial UART and ttyS0</a></h2>
<p>UART(Universal Asynchronous Receiver/Transmitter) is an asynchronous serial communication standard used to connect computers and microcontrollers to peripheral devices. UART allows for the conversion of parallel and serial signals, enabling the conversion of input parallel data into serial data and transmitting it to the other party over a communication line. Integrated circuits designed for this purpose, known as 8250 UART devices, were manufactured, followed by various other families.</p>
<p>Now, in this case, we are attempting to boot the Guest OS (Linux), and having a serial console is quite useful for debugging and other purposes. A serial console sends all console outputs of the Guest to the serial port. With the serial terminal properly configured, you can remotely monitor the system's boot status or log in to the system via the serial port. In this instance, we will use this method to check the state of a Guest VM running on ToyVMM and perform operations within the Guest.</p>
<p>To output console messages to the serial port, it is necessary to set <code>console=ttyS0</code> as a kernel boot parameter. In the current implementation of ToyVMM, this value is provided as the default.</p>
<p>The challenge lies on the side that receives this, the serial terminal. Since the I/O port address corresponding to the serial port is fixed, ToyVMM's layer will receive instructions like <code>KVM_EXIT_IO</code> for the nearby address. In other words, it needs to properly handle output information to the serial console issued from the Guest OS and other necessary setup requests. This can be achieved by emulating the UART device. Furthermore, by emulating the device, if we can output console output to the standard output and reflect our standard input to the Guest VM, when starting the VM from ToyVMM, we can confirm the boot information and perform operations on the Guest from our local terminal.</p>
<p>In summary, we need to create something like the conceptual diagram below:</p>
<img src="../02_figs/overview_serial_device.svg" width="100%">
<p>We will explain this in detail in the following sections.</p>
<h2 id="serial-uart"><a class="header" href="#serial-uart">Serial UART</a></h2>
<p>For detailed information about Serial UART, you can refer to the following resources by Lammet Bies and Wikibooks, which provide rich information:</p>
<ul>
<li><a href="https://www.lammertbies.nl/comm/info/serial-uart">Serial UART information (Lammet Bies)</a></li>
<li><a href="https://en.wikibooks.org/wiki/Serial_Programming/8250_UART_Programming">Serial Programming / 8250 UART Programming (Wikibooks)</a></li>
</ul>
<p>The following figures are based on Lammet's document, with a brief explanation of each bit of each register. Although this diagram was created by me personally in writing this document, it is attached in the hope that it will help readers understand the meaning of each register and bit. However, the meaning of each register and bit is not explained in this document, so please refer to the above document for confirmation:</p>
<img src="../02_figs/serial_uart_registers.svg" width="100%">
<p>Basically, UART operations are performed by manipulating the registers and bits shown above. In our case, we need to emulate this in software, and we plan to do this using <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>. In the following sections, we'll briefly compare the implementation of <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a> with the above specifications.</p>
<h2 id="software-implementation-of-serial-device-using-rust-vmmvm-superio"><a class="header" href="#software-implementation-of-serial-device-using-rust-vmmvm-superio">Software Implementation of Serial Device using rust-vmm/vm-superio</a></h2>
<h3 id="initial-value-settingsrw-implementation"><a class="header" href="#initial-value-settingsrw-implementation">Initial Value Settings/RW Implementation</a></h3>
<p>Here, we will review the implementation of the serial device using <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a> while comparing it with the above specifications. I encourage you to obtain the code from the link provided and inspect it for yourself. The following content is based on version <code>vm-superio-0.6.0</code>, so please note that it may have changed in the latest code.</p>
<p>First, let's organize some initial values for certain variables. <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a> was originally designed for VMM usage, so it initializes certain register values and doesn't anticipate changes.</p>
<table><thead><tr><th>Variable</th><th>DEFAULT VALUE</th><th>Meaning</th><th>REGISTER</th></tr></thead><tbody>
<tr><td>baud_divisor_low</td><td>0x0c</td><td>Baud rate 9600 bps</td><td></td></tr>
<tr><td>baud_divisor_high</td><td>0x00</td><td>Baud rate 9600 bps</td><td></td></tr>
<tr><td>interrupt_enable</td><td>0x00</td><td>No interrupts enabled</td><td>IER</td></tr>
<tr><td>interrupt_identification</td><td>0b0000_0001</td><td>No pending interrupt</td><td>IIR</td></tr>
<tr><td>line_control</td><td>0b0000_0011</td><td>8-bit word length</td><td>LCR</td></tr>
<tr><td>line_status</td><td>0b0110_0000</td><td>(1)</td><td>LSR</td></tr>
<tr><td>modem_control</td><td>0b0000_1000</td><td>(2)</td><td>MCR</td></tr>
<tr><td>modem_status</td><td>0b1011_0000</td><td>(3)</td><td>MSR</td></tr>
<tr><td>scratch</td><td>0b0000_0000</td><td></td><td>SCR</td></tr>
<tr><td>in_buffer</td><td>Vec::new()</td><td>Vector values (buffer)</td><td>-</td></tr>
</tbody></table>
<ul>
<li>(1) Setting THR empty-related bits. Setting these bits means that data can be received at any time. This represents the assumption that it will be used as a virtual device.</li>
<li>(2) Many UARTs enable interrupts by default by setting Auxiliary Output 2 to 1.</li>
<li>(3) Connected state and hardware data flow initialization.</li>
</ul>
<p>Now, let's look at the processing when a write request is received. As a result of <code>KVM_EXIT_IO</code>, we receive the address where IO occurred and the data to be written. On the ToyVMM side, we calculate the appropriate device (in this case, the Serial UART device) and its offset from the base address based on these values and call the <code>write</code> function defined in <code>vm-superio</code>. The following content is a simplified table representing the processing of <code>Serial::write</code>. In general, it involves straightforward register value modification, with a few exceptions:</p>
<table><thead><tr><th>Variable</th><th>OFFSET(u8)</th><th>Additional Conditions</th><th>Write</th></tr></thead><tbody>
<tr><td>DLAB_LOW_OFFSET</td><td>0</td><td>is_dlab_set = true</td><td>Modify <code>self.baud_divisor_low</code></td></tr>
<tr><td>DLAB_HIGH_OFFSET</td><td>1</td><td>is_dlab_set = true</td><td>Modify <code>self.baud_divisor_high</code></td></tr>
<tr><td>DATA_OFFSET</td><td>0</td><td>- (is_dlab_set = false)</td><td>(1)</td></tr>
<tr><td>IER_OFFSET</td><td>1</td><td>- (is_dlab_set = false)</td><td>(2)</td></tr>
<tr><td>LCR_OFFSET</td><td>3</td><td>-</td><td>Modify <code>self.line_control</code></td></tr>
<tr><td>MCR_OFFSET</td><td>4</td><td>-</td><td>Modify <code>self.modem_control</code></td></tr>
<tr><td>SCR_OFFSET</td><td>7</td><td>-</td><td>Modify <code>self.scratch</code></td></tr>
</tbody></table>
<ul>
<li>(1) Depending on the current state of the Serial, we handle cases where LOOP_BACK_MODE (MCR bit 4) is enabled and when it is not enabled. 
<ul>
<li>If it is enabled, it simulates passing what is written to the transmit register directly to the receive register (loopback), which is not important in this context.</li>
<li>If it is not enabled, it writes the data to be written to the output and depends on the existing configuration to generate interrupts.
<ul>
<li>As shown in the table above, we do not support changing IIR due to write from outside, and the default value is set to <code>0b0000_0001</code>.</li>
<li>If the THR empty bit flag of IER is set for IER_OFFSET, it sets the corresponding flag for THR empty in IIR and triggers an interrupt.</li>
</ul>
</li>
</ul>
</li>
<li>(2) Among the bits of IER, only bits 0-3 are masked, and the result is written back to <code>self.interrupt_enable</code>.</li>
</ul>
<p>Next, let's look at the processing when a read request is received. Similarly, we present the processing of <code>Serial::read</code> in a simplified table. Unlike write, in the case of read, it mainly involves returning data as the result.</p>
<table><thead><tr><th>Variable</th><th>OFFSET(u8)</th><th>Additional Conditions</th><th>Read</th></tr></thead><tbody>
<tr><td>DLAB_LOW_OFFSET</td><td>0</td><td>is_dlab_set = true</td><td>Read <code>self.baud_divisor_low</code></td></tr>
<tr><td>DLAB_HIGH_OFFSET</td><td>1</td><td>is_dlab_set = true</td><td>Read <code>self.baud_divisor_high</code></td></tr>
<tr><td>DATA_OFFSET</td><td>0</td><td>- (is_dlab_set = false)</td><td>(1)</td></tr>
<tr><td>IER_OFFSET</td><td>1</td><td>- (is_dlab_set = false)</td><td>Read <code>self.interrupt_enable</code></td></tr>
<tr><td>IIR_OFFSET</td><td>2</td><td>-</td><td>(2)</td></tr>
<tr><td>LCR_OFFSET</td><td>3</td><td>-</td><td>Read <code>self.line_control</code></td></tr>
<tr><td>MCR_OFFSET</td><td>4</td><td>-</td><td>Read <code>self.modem_control</code></td></tr>
<tr><td>LSR_OFFSET</td><td>5</td><td>-</td><td>Read <code>self.line_status</code></td></tr>
<tr><td>MSR_OFFSET</td><td>6</td><td>-</td><td>(3)</td></tr>
<tr><td>SCR_OFFSET</td><td>7</td><td>-</td><td>Read <code>self.scratch</code></td></tr>
</tbody></table>
<ul>
<li>(1) Reads data from the buffer held by the Serial structure. In the current implementation, this buffer is only filled by write in loopback mode, so read operations related to this region are not issued in the boot sequence of the OS.</li>
<li>(2) Returns the result of <code>self.interrupt_identification</code> | <code>0b1100_0000 (FIFO enabled)</code> and resets it to the default value.</li>
<li>(3) Depending on whether the current state is loopback mode, it handles differently.
<ul>
<li>In the case of loopback, it adjusts appropriately (not important for this context).</li>
<li>In the case of non-loopback, it straightforwardly returns the value of <code>self.modem_status</code>.</li>
</ul>
</li>
</ul>
<h2 id="usage-of-rust-vmmvm-superio-in-toyvmm"><a class="header" href="#usage-of-rust-vmmvm-superio-in-toyvmm">Usage of rust-vmm/vm-superio in ToyVMM</a></h2>
<p>In ToyVMM, we use <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a> to handle <code>KVM_EXIT_IO</code> contents. Additionally, two things need to be considered:</p>
<ul>
<li>Outputting console output destined for the serial port to the standard output to allow monitoring of the boot sequence and internal state of the Guest VM.</li>
<li>Passing the content of standard input to the Guest VM.</li>
</ul>
<p>In the following sections, we'll go through each of these in order.</p>
<h3 id="outputting-console-output-destined-for-the-serial-port-to-standard-output"><a class="header" href="#outputting-console-output-destined-for-the-serial-port-to-standard-output">Outputting Console Output Destined for the Serial Port to Standard Output</a></h3>
<p>To monitor the boot sequence and internal state of the Guest VM, we will redirect console output destined for the serial port to the standard output. &quot;Console output destined for the serial port&quot; corresponds to the case of <code>KVM_EXIT_IO_OUT</code> where <code>KVM_EXIT_IO</code> is issued for the &quot;IO Port address for Serial&quot;. The code section below handles this:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>...
loop {
  match vcpu.run() {
      Ok(run) =&gt; match run {
          ...
          VcpuExit::IoOut(addr, data) =&gt; {
              io_bus.write(addr as u64, data);
          }
      ...  
      }
    }
}
...
<span class="boring">}
</span></code></pre></pre>
<p>Here, as a result of <code>KVM_EXIT_IO_OUT</code>, we receive the address and data to be written. On the ToyVMM side, we simply call <code>io_bus.write</code> with these values. The setup for this <code>io_bus</code> is done as follows:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut io_bus = IoBus::new();
let com_evt_1_3 = EventFdTrigger::new(EventFd::new(libc::EFD_NONBLOCK).unwrap());
let stdio_serial = Arc::new(Mutex::new(SerialDevice {
    serial: serial::Serial::with_events(
        com_evt_1_3.try_clone().unwrap(),
        SerialEventsWrapper {
            buffer_read_event_fd: None,
        },
        Box::new(std::io::stdout()),
    ),
}));
io_bus.insert(stdio_serial.clone(), 0x3f8, 0x8).unwrap();
vm.fd().register_irqfd(&amp;com_evt_1_3, 4).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>The setup above requires some explanation, so let's go through it step by step. In essence, it accomplishes the following:</p>
<ul>
<li>Initializes an I/O Bus represented by <code>IoBus</code> and initializes the eventfd for interrupts.</li>
<li>Initializes the Serial Device. During initialization, we provide an <code>eventfd</code> for generating interrupts in the Guest and an FD (<code>std::io::stdout()</code>) for standard output.</li>
<li>Registers the Serial Device we initialized with the <code>IoBus</code>. During registration, we specify <code>0x3f8</code> as the base and <code>0x8</code> as the range.
<ul>
<li>This means that the range of <code>0x8</code> starting from the base <code>0x3f8</code> represents the address space used by this Serial Device.</li>
</ul>
</li>
</ul>
<h4 id="handling-the-io-bus"><a class="header" href="#handling-the-io-bus">Handling the I/O Bus</a></h4>
<p>The address value passed via <code>KVM_EXIT_IO</code> becomes the value within the entire address space. On the other hand, the <code>read/write</code> implementation in <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a> works based on an offset value from the Serial Device's base address. Therefore, there's a need for processing to bridge this gap.</p>
<p>You could simply calculate the offset, but in Firecracker, considering future extensibility (using I/O Ports for devices other than Serial), there's a <code>Bus</code> structure representing the I/O Bus. This structure allows devices to be registered along with <code>BusRange</code> (a structure representing the base address and address range for devices on the bus). Furthermore, when an I/O at a specific address occurs, the mechanism checks that address, retrieves the device registered in the corresponding address range, and performs I/O on that device using the offset from the base address.</p>
<p>For instance, the <code>write</code> function is implemented as follows, where it retrieves the registered device and its offset based on the address information using the <code>get_device</code> function, and then calls the <code>write</code> function implemented in that device with the offset.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn write(&amp;self, addr: u64, data: &amp;[u8]) -&gt; bool {
    if let Some((offset, dev)) = self.get_device(addr) {
        // OK to unwrap as lock() failing is a serious error condition and should panic.
        dev.lock()
            .expect(&quot;Failed to acquire device lock&quot;)
            .write(offset, data);
        true
    } else {
        false
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>Let's consider the Serial device as an example. As mentioned earlier, <code>KVM_EXIT_IO_OUT</code> for the Serial device from the Guest VM occurs within an address range of 8 bytes with a base address of <code>0x3f8</code>. ToyVMM's IoBus also registers the Serial Device with the same address base and range. For example, when you trap an instruction that writes <code>0b1001_0011</code> to <code>0x3fb</code> as <code>KVM_EXIT_IO_OUT</code>, it interprets this instruction as writing <code>0b1001_0011</code> to <code>LCR</code> at the position <code>0x3</code> from the base address <code>0x3f8</code>.</p>
<h4 id="interrupt-notification-to-guest-vm-via-eventfdirqfd"><a class="header" href="#interrupt-notification-to-guest-vm-via-eventfdirqfd">Interrupt Notification to Guest VM via eventfd/irqfd</a></h4>
<p>Now, let's discuss KVM and interrupts. We will reference some Linux source code, mainly from version <code>v4.18</code>.</p>
<p>:warning: The following information is mainly based on source code and may not capture all the details of state transitions. If you find any inaccuracies, please let me know in the comments.</p>
<p>In <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>, during Serial initialization, it requires an <a href="https://docs.rs/vmm-sys-util/0.6.1/vmm_sys_util/eventfd/struct.EventFd.html"><code>EventFd</code></a> as its first argument. This is a wrapper for <a href="https://man7.org/linux/man-pages/man2/eventfd.2.html">eventfd</a> in Linux. Eventfd allows inter-process and process-to-kernel event notifications.</p>
<p>Next is irqfd. irqfd is a mechanism based on eventfd that allows injecting interrupts into a VM. In simple terms, it's like having one end of eventfd held by KVM, and the other end's notifications are interpreted as interrupts to the Guest VM. This irqfd-based interrupt is meant to emulate interrupts from the external world to the Guest VM, which corresponds to regular system interrupts from peripheral devices in a typical system. The reverse direction of interrupts is handled using the <code>ioeventfd</code> mechanism, which we'll omit for now.</p>
<p>Let's examine how irqfd is connected to Guest VM interrupts by looking at the source code. When you perform an ioctl with <code>KVM_IRQFD</code> against KVM, it goes through the KVM processing with the data passed to <code>kvm_irqfd</code> and <code>kvm_irqfd_assign</code>. In the <code>kvm_irqfd_assign</code> function, an instance of the <code>kvm_kernel_irqfd</code> structure is created. At this point, settings are made based on additional information passed during the ioctl. Particularly, the <code>gsi</code> field in the <code>kvm_kernel_irqfd</code> structure is set based on the value passed as an argument during the ioctl. This <code>gsi</code> corresponds to the index of the interrupt table for the Guest, so when making the ioctl, you specify which interrupt table entry you want to use along with the eventfd. ToyVMM sets this up with a line like this:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>vm.fd().register_irqfd(&amp;com_evt_1_3, 4).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>This is defined as a method in the <code>kvm_ioctl::VmFd</code> structure.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn register_irqfd(&amp;self, fd: &amp;EventFd, gsi: u32) -&gt; Result&lt;()&gt; {
    let irqfd = kvm_irqfd {
        fd: fd.as_raw_fd() as u32,
        gsi,
        ..Default::default()
    };
    // Safe because we know that our file is a VM fd, we know the kernel will only read
    // the correct amount of memory from our pointer, and we verify the return result.
    let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD(), &amp;irqfd) };
    if ret == 0 {
        Ok(())
    } else {
        Err(errno::Error::last())
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>In other words, in the aforementioned setup, the eventfd (<code>com_evt_1_3</code>) used by the Serial device has been configured with GSI=4 (the Guest VM's interrupt table index for the COM1 port). Therefore, any <code>write</code> operation performed on <code>com_evt_1_3</code> results in an interrupt being sent to the Guest VM as if it were generated from COM1. From the Guest's perspective, this means that an interrupt originated from the Serial device downstream of COM1, leading to the invocation of the Guest VM's COM1 interrupt handler.</p>
<p>Now, let's discuss the setup of the Guest-side Interrupt Table (GSI: Global System Interrupt Table) and how and when it's established. In short, these tables are set up by issuing an ioctl to KVM with <code>KVM_CREATE_IRQCHIP</code>. This operation creates two interrupt controllers, the <code>PIC</code> and <code>IOAPIC</code> (internally, the <code>kvm_pic_init</code> function handles PIC initialization, registers read/write ops, and sets it in <code>kvm-&gt;arch.vpic</code>. Similarly, <code>kvm_ioapic_init</code> initializes the IOAPIC, registers read/write ops, and sets it in <code>kvm-&gt;arch.vioapic</code>). These hardware components, such as the PIC and IOAPIC, are implemented within KVM for the purpose of acceleration, so there's no need to emulate them separately. While you could delegate this task to qemu, we'll omit this detail here since we're not using it.</p>
<p>Furthermore, the <code>kvm_setup_default_irq_routing</code> function sets up default IRQ routing. This process determines which handler will be invoked for each GSI-based interrupt. Let's take a closer look at the contents of <code>kvm_setup_default_irq_routing</code>. This function calls <code>kvm_set_irq_routing</code>, where the essential processing takes place. Here, a <code>kvm_irq_routing_table</code> is created and populated with <code>kvm_kernel_irq_routing_entry</code> structures that represent the mapping from GSI to IRQ.</p>
<p>The <code>kvm_kernel_irq_routing_entry</code> structures are populated using a loop that iterates through a <code>default_routing</code> array. Here's how <code>default_routing</code> is defined along with related macros:</p>
<pre><code class="language-C">#define SELECT_PIC(irq) \
    ((irq) &lt; 8 ? KVM_IRQCHIP_PIC_MASTER : KVM_IRQCHIP_PIC_SLAVE)

#define IOAPIC_ROUTING_ENTRY(irq) \
    { .gsi = irq, .type = KVM_IRQ_ROUTING_IRQCHIP, \
      .u.irqchip = { .irqchip = KVM_IRQCHIP_IOAPIC, .pin = (irq) } }

#define ROUTING_ENTRY1(irq) IOAPIC_ROUTING_ENTRY(irq)

#define PIC_ROUTING_ENTRY(irq) \
    { .gsi = irq, .type = KVM_IRQ_ROUTING_IRQCHIP, \
      .u.irqchip = { .irqchip = SELECT_PIC(irq), .pin = (irq) % 8 } }

#define ROUTING_ENTRY2(irq) \
    IOAPIC_ROUTING_ENTRY(irq), PIC_ROUTING_ENTRY(irq)

static const struct kvm_irq_routing_entry default_routing[] = {
    ROUTING_ENTRY2(0), ROUTING_ENTRY2(1),
    ROUTING_ENTRY2(2), ROUTING_ENTRY2(3),
    ROUTING_ENTRY2(4), ROUTING_ENTRY2(5),
    ROUTING_ENTRY2(6), ROUTING_ENTRY2(7),
    ROUTING_ENTRY2(8), ROUTING_ENTRY2(9),
    ROUTING_ENTRY2(10), ROUTING_ENTRY2(11),
    ROUTING_ENTRY2(12), ROUTING_ENTRY2(13),
    ROUTING_ENTRY2(14), ROUTING_ENTRY2(15),
    ROUTING_ENTRY1(16), ROUTING_ENTRY1(17),
    ROUTING_ENTRY1(18), ROUTING_ENTRY1(19),
    ROUTING_ENTRY1(20), ROUTING_ENTRY1(21),
    ROUTING_ENTRY1(22), ROUTING_ENTRY1(23),
};
</code></pre>
<p>As you can see, IRQ numbers 0-15 are passed to <code>ROUTING_ENTRY2</code>, and IRQ numbers 16-23 are passed to <code>ROUTING_ENTRY1</code>. <code>ROUTING_ENTRY2</code> calls both <code>IOAPIC_ROUTING_ENTRY</code> and <code>PIC_ROUTING_ENTRY</code>, while <code>ROUTING_ENTRY1</code> calls <code>IOAPIC_ROUTING_ENTRY</code> only, creating structures with the necessary information.</p>
<p>These structures are used to set up each <code>.u.irqchip.irqchip</code> value (<code>KVM_IRQCHIP_PIC_SLAVE</code>, <code>KVM_IRQCHIP_PIC_MASTER</code>, <code>KVM_IRQCHIP_IOAPIC</code>) appropriately in the <code>kvm_set_routing_entry</code> function, depending on the IRQ. This function performs callbacks (<code>kvm_set_pic_irq</code>, <code>kvm_set_ioapic_irq</code>) and any necessary configurations when an interrupt occurs. We'll discuss these callbacks in more detail later.</p>
<pre><code class="language-C">int kvm_set_routing_entry(struct kvm *kvm,
                          struct kvm_kernel_irq_routing_entry *e,
                          const struct kvm_irq_routing_entry *ue)
{
    /* We can't check irqchip_in_kernel() here as some callers are
     * currently initializing the irqchip. Other callers should therefore
     * check kvm_arch_can_set_irq_routing() before calling this function.
     */
    switch (ue-&gt;type) {
    case KVM_IRQ_ROUTING_IRQCHIP:
        if (irqchip_split(kvm))
            return -EINVAL;
        e-&gt;irqchip.pin = ue-&gt;u.irqchip.pin;
        switch (ue-&gt;u.irqchip.irqchip) {
        case KVM_IRQCHIP_PIC_SLAVE:
            e-&gt;irqchip.pin += PIC_NUM_PINS / 2;
            /* fall through */
        case KVM_IRQCHIP_PIC_MASTER:
            if (ue-&gt;u.irqchip.pin &gt;= PIC_NUM_PINS / 2)
                return -EINVAL;
            e-&gt;set = kvm_set_pic_irq;
            break;
        case KVM_IRQCHIP_IOAPIC:
            if (ue-&gt;u.irqchip.pin &gt;= KVM_IOAPIC_NUM_PINS)
                return -EINVAL;
            e-&gt;set = kvm_set_ioapic_irq;
            break;
        default:
            return -EINVAL;
        }
        e-&gt;irqchip.irqchip = ue-&gt;u.irqchip.irqchip;
        break;
...
</code></pre>
<p>Now, let's return to the discussion of <code>irqfd</code>. Although not mentioned earlier, the <code>kvm_irqfd_assign</code> function includes the <code>init_waitqueue_func_entry(&amp;irqfd-&gt;wait, irqfd_wakeup)</code> process, registering <code>irqfd_wakeup</code> with <code>&amp;irqfd-&gt;wait-&gt;func</code>. This function is called when an interrupt occurs, and it invokes <code>schedule_work(&amp;irqfd-&gt;inject)</code>.</p>
<p>The <code>inject</code> field is also initialized within the <code>kvm_irqfd_assign</code> function, resulting in a call to the <code>irqfd_inject</code> function. Inside <code>irqfd_inject</code>, the <code>kvm_set_irq</code> function is called. </p>
<p>The <code>kvm_set_irq</code> function lists entries with the incoming IRQ number and calls their <code>set</code> callbacks. This means that functions like <code>kvm_set_pic_irq</code> and <code>kvm_set_ioapic_irq</code>, as described earlier, will be called based on the routing information.</p>
<img src="../02_figs/kvm_irq_gsi_routing.svg" width="100%">
<p>The following explanation will go into a little more depth on interrupt processing, but since they are not necessary for understanding ToyVMM, you may skip to <a href="02-5_serial_console_implementation.html#toyvmm-serial-console">ToyVMM serial console</a>.</p>
<p>Let's take a closer look at the <code>kvm_set_pic_irq</code> handler, which is responsible for handling interrupts. While this discussion slightly deviates from the main topic, it's a good opportunity to explore it more thoroughly.
<code>kvm_set_pic_irq</code> simply utilizes the <code>kvm_pic_set_irq</code> function, passing the relevant parameters.</p>
<pre><code class="language-C">static int kvm_set_pic_irq(struct kvm_kernel_irq_routing_entry *e,
                           struct kvm *kvm, int irq_source_id, int level,
                           bool line_status)
{
    struct kvm_pic *pic = kvm-&gt;arch.vpic;
    return kvm_pic_set_irq(pic, e-&gt;irqchip.pin, irq_source_id, level);
}
</code></pre>
<p>Let's inspect the implementation of <code>kvm_pic_set_irq</code>:</p>
<pre><code class="language-C">int kvm_pic_set_irq(struct kvm_pic *s, int irq, int irq_source_id, int level)
{
    int ret, irq_level;

    BUG_ON(irq &lt; 0 || irq &gt;= PIC_NUM_PINS);

    pic_lock(s);
    irq_level = __kvm_irq_line_state(&amp;s-&gt;irq_states[irq],
                                     irq_source_id, level);
    ret = pic_set_irq1(&amp;s-&gt;pics[irq &gt;&gt; 3], irq &amp; 7, irq_level);
    pic_update_irq(s);
    trace_kvm_pic_set_irq(irq &gt;&gt; 3, irq &amp; 7, s-&gt;pics[irq &gt;&gt; 3].elcr,
                          s-&gt;pics[irq &gt;&gt; 3].imr, ret == 0);
    pic_unlock(s);

    return ret;
}
</code></pre>
<p>In <code>pic_set_irq1</code>, the IRQ level is set, and then <code>pic_update_irq</code> calls the <code>pic_irq_request</code> and updates the <code>kvm-&gt;arch.vpic</code> structure.</p>
<pre><code class="language-C">/*
 * raise irq to CPU if necessary. must be called every time the active
 * irq may changejjj
 */
static void pic_update_irq(struct kvm_pic *s)
{
	int irq2, irq;

	irq2 = pic_get_irq(&amp;s-&gt;pics[1]);
	if (irq2 &gt;= 0) {
		/*
		 * if irq request by slave pic, signal master PIC
		 */
		pic_set_irq1(&amp;s-&gt;pics[0], 2, 1);
		pic_set_irq1(&amp;s-&gt;pics[0], 2, 0);
	}
	irq = pic_get_irq(&amp;s-&gt;pics[0]);
	pic_irq_request(s-&gt;kvm, irq &gt;= 0);
}

/*
 * callback when PIC0 irq status changed
 */
static void pic_irq_request(struct kvm *kvm, int level)
{
	struct kvm_pic *s = kvm-&gt;arch.vpic;

	if (!s-&gt;output)
		s-&gt;wakeup_needed = true;
	s-&gt;output = level;

}
</code></pre>
<p>After that, <code>kvm_pic_set_irq</code> invokes <code>pic_unlock</code> function.<br />
This function is a little more import because if the <code>wakeup_needed</code> field is <code>true</code>, then invokes <code>kvm_vcpu_kick</code> function for vCPU.</p>
<pre><code class="language-C">static void pic_unlock(struct kvm_pic *s)
    __releases(&amp;s-&gt;lock)
{
    bool wakeup = s-&gt;wakeup_needed;
    struct kvm_vcpu *vcpu;
    int i;

    s-&gt;wakeup_needed = false;

    spin_unlock(&amp;s-&gt;lock);

    if (wakeup) {
        kvm_for_each_vcpu(i, vcpu, s-&gt;kvm) {
            if (kvm_apic_accept_pic_intr(vcpu)) {
                kvm_make_request(KVM_REQ_EVENT, vcpu);
                kvm_vcpu_kick(vcpu);
                return;
            }
        }
    }
}

void kvm_vcpu_kick(struct kvm_vcpu *vcpu)
{
    int me;
    int cpu = vcpu-&gt;cpu;

    if (kvm_vcpu_wake_up(vcpu))
        return;

    me = get_cpu();
    if (cpu != me &amp;&amp; (unsigned)cpu &lt; nr_cpu_ids &amp;&amp; cpu_online(cpu))
        if (kvm_arch_vcpu_should_kick(vcpu))
            smp_send_reschedule(cpu);
    put_cpu();
}
</code></pre>
<p>And the result of invoking <code>smp_send_reschedule</code> function in <code>kvm_vcpu_kick</code>, <code>native_smp_send_reschedule</code> function is called.</p>
<pre><code class="language-C">
static void native_smp_send_reschedule(int cpu)
{
    if (unlikely(cpu_is_offline(cpu))) {
        WARN_ON(1);
        return;
    }
    apic-&gt;send_IPI(cpu, RESCHEDULE_VECTOR);
}
</code></pre>
<p>By invoking <code>smp_send_reschedule</code>, an IPI (Inter-Processor Interrupt) is sent to another CPU, prompting it to reschedule. This results in an interrupt being inserted into the vCPU, causing a <code>VMExit</code>. Consequently, the vCPU is scheduled when the interrupt is delivered.</p>
<p>Now, let's briefly review the process of how interrupts are inserted. When <code>KVM_RUN</code> is executed, the following steps are performed (focusing solely on interrupt insertion, omitting other extensive processing):</p>
<pre><code>kvm_arch_vcpu_ioctl_run
 -&gt; vcpu_run
 -&gt; vcpu_enter_guest
 -&gt; inject_pending_event
 -&gt; kvm_cpu_has_injectable_intr
</code></pre>
<p>Within <code>kvm_cpu_has_injectable_intr</code>, the <code>kvm_cpu_has_extint</code> function is called. In this case, it likely returns <code>1</code>, probably based on the value of <code>s-&gt;output</code> set by <code>pic_irq_request</code>.</p>
<p>Therefore, the following part of the <code>inject_pending_event</code> function is reached:</p>
<pre><code class="language-C">	} else if (kvm_cpu_has_injectable_intr(vcpu)) {
		/*
		 * Because interrupts can be injected asynchronously, we are
		 * calling check_nested_events again here to avoid a race condition.
		 * See https://lkml.org/lkml/2014/7/2/60 for discussion about this
		 * proposal and current concerns.  Perhaps we should be setting
		 * KVM_REQ_EVENT only on certain events and not unconditionally?
		 */
		if (is_guest_mode(vcpu) &amp;&amp; kvm_x86_ops-&gt;check_nested_events) {
			r = kvm_x86_ops-&gt;check_nested_events(vcpu, req_int_win);
			if (r != 0)
				return r;
		}
		if (kvm_x86_ops-&gt;interrupt_allowed(vcpu)) {
			kvm_queue_interrupt(vcpu, kvm_cpu_get_interrupt(vcpu),
					    false);
			kvm_x86_ops-&gt;set_irq(vcpu);
		}
	}
</code></pre>
<p>Finally, <code>kvm_x86_ops-&gt;set_irq(vcpu)</code> is called, and this triggers the <code>vmx_inject_irq</code> callback function. In this process, it inserts the interrupt by setting <code>VMCS</code> (<code>Virtual Machine Control Structure</code>) with <code>VMX_ENTRY_INTR_INFO_FIELD</code>. While not elaborated on here, explaining <code>VMCS</code> would require delving into hypervisor implementation details, which is beyond the scope of this discussion. It may be added as supplementary information in the documentation in the future.</p>
<p>In summary, this is the flow of interrupt processing using the PIC as an example.</p>
<h4 id="toyvmm-serial-console"><a class="header" href="#toyvmm-serial-console">ToyVMM serial console</a></h4>
<p>Now, at this point, let's temporarily set aside the exploration of interrupts and return to discussing the implementation of ToyVMM. Considering the previous discussions, let's organize what processes are being executed within ToyVMM and what happens behind the scenes.</p>
<p>In ToyVMM, before performing <code>register_irqfd</code> as mentioned earlier, a function called <code>setup_irqchip</code> is actually executed. This function acts as a thin wrapper and internally makes calls to <code>create_irq_chip</code> and <code>create_pit2</code>. </p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(target_arch = &quot;x86_64&quot;)]
pub fn setup_irqchip(&amp;self) -&gt; Result&lt;()&gt; {
    self.fd.create_irq_chip().map_err(Error::VmSetup)?;
    let pit_config = kvm_pit_config {
        flags: KVM_PIT_SPEAKER_DUMMY,
        ..Default::default()
    };
    self.fd.create_pit2(pit_config).map_err(Error::VmSetup)
}
<span class="boring">}
</span></code></pre></pre>
<p>What's important here is the <code>create_irq_chip</code> function. Internally, it calls the <code>KVM_CREATE_IRQCHIP</code> API, as mentioned earlier, to initialize the interrupt controller and IRQ routing. Following this setup, <code>register_irqfd(&amp;com_evt_1_3, 4)</code> is executed on the configured Guest VM, which, as explained earlier, calls functions like <code>kvm_irqfd_assign</code> to set up interrupt handlers. This completes the setup of interrupt-related configurations using the KVM API.</p>
<p>Now, let's revisit the interrupts coming from <code>com_evt_1_3</code>. As previously discussed, one end of the interrupt is passed to KVM along with <code>GSI=4</code> through <code>register_irqfd</code>. Consequently, any <code>write</code> issued from the other end is treated as an interrupt to the Guest VM as if it were sent to the COM1 port. On the other hand, the other end of <code>com_evt_1_3</code> is passed to the Serial Device, making writes to the eventfd on the Serial Device side (occurring after processing through <code>Serial::write</code> or through the invocation of <code>Serial::enqueue_raw_byte</code>) the actual interrupt triggers. In essence, this setup enables the Guest VM and the software-implemented Serial Device to interact in a manner similar to regular server and Serial Device communication.</p>
<p>Furthermore, to represent a Serial Console, we've configured <code>stdout</code> as the destination for writes corresponding to the Serial Device's output in this case. Therefore, when handling <code>KVM_EXIT_IO_OUT</code> and writing to THR, the data is passed to <code>stdout</code>, resulting in console messages being output to standard output. This effectively realizes the desired Serial Console functionality.</p>
<h4 id="controlling-the-guest-vm-via-standard-input"><a class="header" href="#controlling-the-guest-vm-via-standard-input">Controlling the Guest VM via Standard Input</a></h4>
<p>Finally, to manipulate the Guest VM using standard input, we want to reflect the contents of standard input into the Guest VM. The <a href="https://docs.rs/vm-superio/0.1.1/vm_superio/serial/struct.Serial.html"><code>Serial</code></a> struct provided by <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a> offers a helper function called <a href="https://docs.rs/vm-superio/0.1.1/vm_superio/serial/struct.Serial.html#method.enqueue_raw_bytes"><code>enqueue_raw_bytes</code></a>. This helper function allows us to send data to the Guest VM without needing to handle low-level register operations or interrupts explicitly, as the function handles these operations internally.</p>
<p>To achieve this, we need to read input from the program and pass it directly to this method. We can set up standard input in raw mode, and the main thread can poll it while waiting for input. When input is received, we can use <code>enqueue_raw_bytes</code> to send it to the Guest VM. Since each vCPU of the Guest VM is executed in a separate thread, polling standard input in the main thread won't affect the processing of the Guest VM.</p>
<p>Here is a basic implementation:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let stdin_handle = io::stdin();
let stdin_lock = stdin_handle.lock();
stdin_lock
    .set_raw_mode()
    .expect(&quot;failed to set terminal raw mode&quot;);
let ctx: PollContext&lt;Token&gt; = PollContext::new().unwrap();
ctx.add(&amp;exit_evt, Token::Exit).unwrap();
ctx.add(&amp;stdin_lock, Token::Stdin).unwrap();
'poll: loop {
    let pollevents: PollEvents&lt;Token&gt; = ctx.wait().unwrap();
    let tokens: Vec&lt;Token&gt; = pollevents.iter_readable().map(|e| e.token()).collect();
    for &amp;token in tokens.iter() {
        match token {
            Token::Exit =&gt; {
                println!(&quot;vcpu requested shutdown&quot;);
                break 'poll;
            }
            Token::Stdin =&gt; {
                let mut out = [0u8; 64];
                tx.send(true).unwrap();
                match stdin_lock.read_raw(&amp;mut out[..]) {
                    Ok(0) =&gt; {
                        println!(&quot;eof!&quot;);
                    }
                    Ok(count) =&gt; {
                        stdio_serial
                            .lock()
                            .unwrap()
                            .serial
                            .enqueue_raw_bytes(&amp;out[..count])
                            .expect(&quot;failed to enqueue bytes&quot;);
                    }
                    Err(e) =&gt; {
                        println!(&quot;error while reading stdin: {:?}&quot;, e);
                    }
                }
            }
            _ =&gt; {}
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>This is a straightforward implementation, but it achieves the desired functionality.</p>
<h2 id="check-uart-request-when-booting-the-linux-kernel"><a class="header" href="#check-uart-request-when-booting-the-linux-kernel">Check UART Request When Booting the Linux Kernel</a></h2>
<p>In the previous sections, we discussed the software implementation of the Serial UART and how it's used internally within ToyVMM. While it works effectively, it's important to examine the UART communication during the Linux Kernel boot process.</p>
<p>Fortunately, due to the VMM's architecture, we need to handle <code>KVM_EXIT_IO</code>, which allows us to intercept all requests sent to the serial port by injecting debug code into this handling process.</p>
<p>I won't go into detail about the code inserted for debugging purposes here, as it's quite straightforward to insert debug code at the appropriate locations. Instead, I'll provide annotations in three specific formats to make it clear and understandable when looking at requests made to the <code>0x3f8 (COM1)</code> register during OS startup.</p>
<pre><code class="language-bash">[Format 1 - Read]
r($register) = $data
  - Description

- r           = Read operation
- $register   = The register corresponding to the offset calculated using the device's address (0x3f8)
- $data       = Data read from $register
- Description = Explanation

[Format 2 - Write]
w($register = $data)
  - Description

- w           = Write operation
- $register   = The register corresponding to the offset calculated using the device's address (0x3f8)
- $data       = Data to be written to $register
- Description = Explanation

[Format 3 - Write (character)]
w(THR = $data = 0xYY) -&gt; 'CHAR'

- w(THR ...)  = Write operation to THR
- $data       = Binary data to be written to $register
- 0xYY        = $data converted to hexadecimal
- 'CHAR'      = 0xYY converted to a character based on the ASCII code table
</code></pre>
<p>Now, the following is a somewhat lengthy representation of requests made to the <code>0x3f8 (COM1)</code> register during OS startup, formatted according to the above annotations:</p>
<pre><code class="language-bash"># Initial setup, configuring baud rate, etc.
w(IER = 0)
w(LCR = 10010011)
  - DLAB         = 1   (DLAB: DLL and DLM accessible)
  - Break signal = 0   (Break signal disabled)
  - Parity       = 010 (No parity)
  - Stop bits    = 0   (1 stop bit)
  - Data bits    = 11  (8 data bits)
w(DLL = 00001100)
w(DLM = 0)
  - DLL = 0x0C, DLM = 0x00 (Speed = 9600 bps)
w(LCR = 00010011)
  - DLAB         = 0   (DLAB: RBR, THR, and IER accessible)
  - Break signal = 0   (Break signal disabled)
  - Parity       = 010 (No parity)
  - Stop bits    = 0   (1 stop bit)
  - Data bits    = 11  (8 data bits)
w(FCR = 0)
w(MCR = 00000001)
  - Reserved            = 00
  - Autoflow control    = 0
  - Loopback mode       = 0
  - Auxiliary output 2  = 0
  - Auxiliary output 1  = 0
  - Request to send     = 0
  - Data terminal ready = 1
r(IER) = 0
w(IER = 0)

# From here, the actual console output is being received through the serial port,
# and write operations (in this case, writing to stdout) are happening.

# Checking the content of r(LSR) to determine whether to write the next character
r(LSR) = 01100000
  - Errornous data in FIFO         = 0
  - THR is empty, and line is idle = 1
  - THR is empty                   = 1
  - Break signal received          = 0
  - Framing error                  = 0
  - Parity error                   = 0
  - Overrun error                  = 0
  - Data available                 = 0
    - Bits 5 and 6 are related to character transmission and used by UART
    - If bits 5 and 6 are set, it means UART is ready to accept a new character
      - Bit 6 = '1' means that all characters have been transmitted
      - Bit 5 = '1' means that UART is capable of receiving more characters

# Since the next character write is accepted here, we write the character we want to output.
w(THR = 01011011 = 0x5b) -&gt; '['

# Following this, the same pattern repeats:
r(LSR) = 01100000
w(THR = 00100000 = 0x20) -&gt; ' '
# The above operation repeats 3 more times.
# ...

r(LSR) = 01100000
w(THR  = 00110000 = 0x30) -&gt; '0'
r(LSR) = 01100000
w(THR  = 00101110 = 0x2e) -&gt; '.'
r(LSR) = 01100000
w(THR  = 00110000 = 0x30) -&gt; '0'
# The above operation repeats 5 more times

r(LSR) = 01100000
w(THR  = 01011101 = 0x5d) -&gt; ']'
r(LSR) = 01100000
w(THR  = 00100000 = 0x20) -&gt; ' '
r(LSR) = 01100000
w(THR  = 01001100 = 0x4c) -&gt; 'L'
r(LSR) = 01100000
w(THR  = 01101001 = 0x69) -&gt; 'i'
r(LSR) = 01100000
w(THR  = 01101110 = 0x6e) -&gt; 'n'
r(LSR) = 01100000
w(THR  = 01110101 = 0x75) -&gt; 'u'
r(LSR) = 01100000
w(THR  = 01111000 = 0x78) -&gt; 'x'
r(LSR) = 01100000
w(THR  = 00100000 = 0x20) -&gt; ' '
r(LSR) = 01100000
w(THR  = 01110110 = 0x76) -&gt; 'v'
r(LSR) = 01100000
w(THR  = 01100101 = 0x65) -&gt; 'e'
r(LSR) = 01100000
w(THR  = 01110010 = 0x72) -&gt; 'r'
r(LSR) = 01100000
w(THR  = 01110011 = 0x73) -&gt; 's'
r(LSR) = 01100000
w(THR  = 01101001 = 0x69) -&gt; 'i'
r(LSR) = 01100000
w(THR  = 01101111 = 0x6f) -&gt; 'o'
r(LSR) = 01100000
w(THR  = 01101110 = 0x6e) -&gt; 'n'
r(LSR) = 01100000
w(THR  = 00100000 = 0x20) -&gt; ' '
r(LSR) = 01100000
w(THR  = 00110100 = 0x34) -&gt; '4'
r(LSR) = 01100000
w(THR  = 00101110 = 0x2e)-&gt; '.'
r(LSR) = 01100000
w(THR  = 00110001 = 0x31) -&gt; '1'
r(LSR) = 01100000
w(THR  = 00110100 = 0x34) -&gt; '4'
r(LSR) = 01100000
w(THR  = 00101110 = 0x2e) -&gt; '.'
r(LSR) = 01100000
w(THR  = 00110001 = 0x31) -&gt; '1'
r(LSR) = 01100000
w(THR  = 00110111 = 0x37) -&gt; '7'
r(LSR) = 01100000
w(THR  = 00110100 = 0x34) -&gt; '4'
r(LSR) = 01100000
w(THR  = 00100000 = 0x20) -&gt; ' '
r(LSR) = 01100000
w(THR  = 00101000 = 0x28) -&gt; '('
r(LSR) = 01100000
w(THR  = 01000000 = 0x40) -&gt; '@'
w(LSR) = 01100000
r(THR  = 00110101 = 0x35) -&gt; '5'
r(LSR) = 01100000
w(THR  = 00110111 = 0x37) -&gt; '7'
r(LSR) = 01100000
w(THR  = 01100101 = 0x65) -&gt; 'e'
r(LSR) = 01100000
w(THR  = 01100100 = 0x64) -&gt; 'd'
r(LSR) = 01100000
w(THR  = 01100101 = 0x65) -&gt; 'e'
r(LSR) = 01100000
w(THR  = 01100010 = 0x62) -&gt; 'b'
r(LSR) = 01100000
w(THR  = 01100010 = 0x62) -&gt; 'b'
r(LSR) = 01100000
w(THR  = 00111001 = 0x39) -&gt; '9'
r(LSR) = 01100000
w(THR  = 00111001 = 0x39) -&gt; '9'
r(LSR) = 01100000
w(THR  = 01100100 = 0x64) -&gt; 'd'
r(LSR) = 01100000
w(THR  = 01100010 = 0x62) -&gt; 'b'
r(LSR) = 01100000
w(THR  = 00110111 = 0x37) -&gt; '7'
r(LSR) = 01100000
w(THR  = 00101001 = 0x29) -&gt; ')'

# Concatenating the output, we get the following line:
[    0.000000] Linux version 4.14.174 (@57edebb99db7)

# This matches the content of the first line output during OS boot.
</code></pre>
<p>Of course, Linux Kernel startup UART requests continue beyond this, and more complex operations take place. However, I won't delve further into these requests here. If you are interested, I encourage you to explore them in detail.</p>
<h2 id="reference"><a class="header" href="#reference">Reference</a></h2>
<ul>
<li><a href="https://www.lammertbies.nl/comm/info/serial-uart">Serial UART information</a></li>
<li><a href="https://en.wikibooks.org/wiki/Serial_Programming/8250_UART_Programming">Wikibooks : Serial Programming / 8250 UART Programming</a></li>
<li><a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a></li>
<li><a href="https://en.wikipedia.org/wiki/Interrupt_request_(PC_architecture)">Interrupt request(PC architecture)</a></li>
<li><a href="https://www.kernel.org/doc/html/v4.15/admin-guide/serial-console.html">Linux Serial Console</a></li>
<li><a href="https://xzpeter.org/htmls/2017_12_07_kvm_irqfd/kvm_irqfd_implementation.html">KVM IRQFD Implementation</a></li>
<li><a href="https://rkx1209.hatenablog.com/entry/2016_01_01_101456">KVMのなかみ（KVM internals）</a></li>
<li><a href="https://syuu1228.github.io/howto_implement_hypervisor/part2.html">ハイパーバイザーの作り方~ちゃんと理解する仮想化技術~ 第2回 intel VT-xの概要とメモリ仮想化</a></li>
<li><a href="https://habr.com/en/post/446312/">External Interrupts in the x86 system. Part1. Interrupt controller evolution</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="toyvmm-implementation"><a class="header" href="#toyvmm-implementation">ToyVMM Implementation</a></h1>
<p>To summarize our previous discussions, we have successfully created a minimal VMM with essential features. This ToyVMM is a straightforward VMM with the following functionalities:</p>
<ul>
<li>It can boot a Guest OS using <code>vmlinuz</code> and <code>initrd</code>.</li>
<li>After the Guest OS boots, it can handle input and output as a Serial Terminal, allowing you to monitor and interact with the Guest's state.</li>
</ul>
<h2 id="run-the-linux-kernel"><a class="header" href="#run-the-linux-kernel">Run the Linux Kernel!</a></h2>
<p>Let's actually boot the Linux Kernel.</p>
<p>First, prepare <code>vmlinux.bin</code> and <code>initrd.img</code>. Place them in the root directory of the ToyVMM repository. You can download <code>vmlinux.bin</code> as follows:</p>
<pre><code class="language-bash"># Download vmlinux.bin
wget https://s3.amazonaws.com/spec.ccfc.min/img/quickstart_guide/x86_64/kernels/vmlinux.bin
cp vmlinux.bin &lt;TOYVMM WORKING DIRECTORY&gt;
</code></pre>
<p>For <code>initrd.img</code>, you can create it using <a href="https://github.com/marcov/firecracker-initrd">marcov/firecracker-initrd</a>, which includes an Alpine Linux root filesystem:</p>
<pre><code class="language-bash"># Create initrd.img
# Using marcov/firecracker-initrd (https://github.com/marcov/firecracker-initrd)
git clone https://github.com/marcov/firecracker-initrd.git
cd firecracker-initrd
bash ./build.sh
# After the above commands, the initrd.img file will be located in build/initrd.img.
# Please move it to the working directory of ToyVMM.
cp build/initrd.img &lt;TOYVMM WORKING DIRECTORY&gt;
</code></pre>
<p>With these preparations completed, let's launch the Guest VM:</p>
<pre><code class="language-bash">$ make run_linux
</code></pre>
<p>Here, we'll skip the output of the boot sequence, which will be displayed on the standard output. Once the boot is complete, you'll see the Alpine Linux screen, and it will prompt you for login credentials. You can log in using <code>root</code> as both the username and password:</p>
<pre><code>Welcome to Alpine Linux 3.15
Kernel 4.14.174 on an x86_64 (ttyS0)

(none) login: root
Password:
Welcome to Alpine!

The Alpine Wiki contains a large amount of how-to guides and general
information about administrating Alpine systems.
See &lt;http://wiki.alpinelinux.org/&gt;.

You can set up the system with the command: setup-alpine

You may change this message by editing /etc/motd.

login[1058]: root login on 'ttyS0'
(none):~#
</code></pre>
<p>Great! You have successfully booted the Guest VM and can operate it. You can also execute commands within the Guest VM. For example, running the basic <code>ls</code> command results in the following output:</p>
<pre><code>(none):~# ls -lat /
total 0
drwx------    3 root     root            80 Sep 23 06:44 root
drwxr-xr-x    5 root     root           200 Sep 23 06:44 run
drwxr-xr-x   19 root     root           400 Sep 23 06:44 .
drwxr-xr-x   19 root     root           400 Sep 23 06:44 ..
drwxr-xr-x    7 root     root          2120 Sep 23 06:44 dev
dr-xr-xr-x   12 root     root             0 Sep 23 06:44 sys
dr-xr-xr-x   55 root     root             0 Sep 23 06:44 proc
drwxr-xr-x    2 root     root          1780 May  7 00:55 bin
drwxr-xr-x   26 root     root          1040 May  7 00:55 etc
lrwxrwxrwx    1 root     root            10 May  7 00:55 init -&gt; /sbin/init
drwxr-xr-x    2 root     root          3460 May  7 00:55 sbin
drwxr-xr-x   10 root     root           700 May  7 00:55 lib
drwxr-xr-x    9 root     root           180 May  7 00:54 usr
drwxr-xr-x    2 root     root            40 May  7 00:54 home
drwxr-xr-x    5 root     root           100 May  7 00:54 media
drwxr-xr-x    2 root     root            40 May  7 00:54 mnt
drwxr-xr-x    2 root     root            40 May  7 00:54 opt
drwxr-xr-x    2 root     root            40 May  7 00:54 srv
drwxr-xr-x   12 root     root           260 May  7 00:54 var
drwxrwxrwt    2 root     root            40 May  7 00:54 tmp
</code></pre>
<p>Well done! At this point, you have created a minimal VMM. However, there are some limitations:</p>
<ul>
<li>It can only be operated through a serial console. You might want to implement virtio-net for networking.</li>
<li>Implementing virtio-blk for block devices.</li>
<li>Handling PCI devices is not yet supported.</li>
</ul>
<p>The creation of ToyVMM served several personal objectives, including:</p>
<ul>
<li>Deepening the understanding of virtualization.</li>
<li>Gaining a better understanding of virtio.</li>
<li>Learning about PCI passthrough:
<ul>
<li>Exploring technologies like VFIO.</li>
<li>Understanding peripheral technologies like mdev, libvfio, and VDPA.</li>
</ul>
</li>
</ul>
<p>While we have completed the creation of a minimal VMM, the direction you take it from here is up to you. ToyVMM is a great starting point, and you can choose to extend it in various ways. If you're reading this and you're an enthusiastic geek, I encourage you to give it a try! And if possible, I'd be delighted to receive feedback on ToyVMM.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="virtual-io-device-virtio"><a class="header" href="#virtual-io-device-virtio">Virtual I/O Device (Virtio)</a></h1>
<p>In this section, as the second step of VMM, we will delve into the implementation of Virtio.<br />
The Virtio specification is maintained by OASIS.<br />
The latest version appears to be <a href="http://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html">version 1.2</a>, which was published on July 1, 2022.<br />
The terminology related to Virtio in this document follows the definitions in version 1.2, so if you want to confirm the meaning of specific terms, please refer to the OASIS page.</p>
<p>In this section, we will cover fundamental knowledge about Virtio and its implementation.<br />
Additionally, as concrete implementations based on Virtio, we will work on <code>virtio-net</code> and <code>virtio-blk</code>.<br />
Once <code>virtio-net</code> is implemented, you will be able to communicate with a booted Guest VM over the network, enabling SSH login and internet connectivity.<br />
Moreover, with <code>virtio-blk</code> implemented, you will handle block devices, meaning DISK I/O, within the virtual machine.
With these two functionalities, you will have most of the requirements for a typical &quot;virtual machine&quot; in place, making Virtio implementation highly significant.</p>
<p>The topics in this section are structured as follows:</p>
<ul>
<li><a href="./03-1_virtio.html">03-1. Virtio</a></li>
<li><a href="./03-2_implement_virtio_in_toyvmm.html">03-2. Implement virtio in ToyVMM</a></li>
<li><a href="./03-3_virtio-net.html">03-3. Implement virtio-net</a></li>
<li><a href="./03-4_virtio-blk.html">03-4. Implement virtio-blk</a></li>
</ul>
<p>This document is based on the following commit numbers:</p>
<ul>
<li>ToyVMM: 58cf0f68a561ee34a28ae4e73481f397f2690b51</li>
<li>Firecracker: cfd4063620cfde8ab6be87ad0212ea1e05344f5c</li>
</ul>
<p>From this point onwards, we will explain the implemented source code using file names.<br />
Here are the actual file paths referred to by the file names mentioned in the explanations:</p>
<table><thead><tr><th>File Name Mentioned in Explanations</th><th>File Path</th></tr></thead><tbody>
<tr><td><code>mod.rs</code></td><td>src/vmm/src/devices/virtio/mod.rs</td></tr>
<tr><td><code>queue.rs</code></td><td>src/vmm/src/devices/virtio/queue.rs</td></tr>
<tr><td><code>mmio.rs</code></td><td>src/vmm/src/devices/virtio/mmio.rs</td></tr>
<tr><td><code>status.rs</code></td><td>src/vmm/src/devices/virtio/status.rs</td></tr>
<tr><td><code>virtio_device.rs</code></td><td>src/vmm/src/devices/virtio/virtio_device.rs</td></tr>
<tr><td><code>net.rs</code></td><td>src/vmm/src/devices/virtio/net.rs</td></tr>
<tr><td><code>block.rs</code></td><td>src/vmm/src/devices/virtio/block.rs</td></tr>
</tbody></table>
<p>Please note that these file paths may change in the future as source code is updated.<br />
Consider these file paths to be associated with the commit numbers mentioned earlier.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="virtio"><a class="header" href="#virtio">Virtio</a></h1>
<h3 id="what-is-virtual-io-device-virtio"><a class="header" href="#what-is-virtual-io-device-virtio">What is Virtual I/O Device (Virtio)?</a></h3>
<p>Virtio is a specification for virtual devices standardized by <a href="https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=virtio">OASIS</a>. It provides a virtual device interface for efficient data transfer and communication between the host system and guest systems (virtual machines).</p>
<p>Based on Virtio, there are implementations like <code>virtio-net</code> (virtual network device) and <code>virtio-blk</code> (virtual block device). As their names suggest, these implementations mimic the behavior of network and block devices, allowing guest operating systems to perform I/O operations as if they were using real network and block devices.</p>
<p>Virtio is compatible with major virtualization technologies such as KVM and is supported by a wide range of guest operating systems, including Linux, Windows, and FreeBSD. As a result, it has become an industry-standard specification widely adopted in virtualization environments.</p>
<h3 id="why-is-virtio-necessary"><a class="header" href="#why-is-virtio-necessary">Why is Virtio Necessary?</a></h3>
<p>When it comes to generating I/O within a virtual machine (VM), how should the hypervisor handle it? First and foremost, the hypervisor needs to make the VM recognize the device at VM startup, which requires emulating various PCI devices. Additionally, when I/O is generated for those devices, the hypervisor must mimic the behavior of those devices. A well-known and widely used software for this kind of hardware emulation is <a href="https://www.qemu.org/">QEMU</a>.</p>
<p>The advantage of fully emulating real hardware using software is that you can use device drivers designed for physical hardware that come with the guest OS. However, this approach incurs significant overhead because it involves a VMExit each time an I/O request occurs within the VM. The hypervisor must perform emulation and then return control to the VM.</p>
<p>One proposed and standardized framework to reduce the overhead of virtualization in device I/O is <code>Virtio</code>. Virtio establishes a queue structure called <code>Virtqueue</code> in shared memory between the hypervisor and VM. This mechanism minimizes the number of mode transitions caused by VMExit. However, <code>Virtio</code> requires device drivers that is implemented for it, depending on the kernel build configuration. Many modern OS distributions come with Virtio device drivers installed by default.</p>
<h3 id="components-of-virtio"><a class="header" href="#components-of-virtio">Components of Virtio</a></h3>
<p>Virtio mainly consists of the following components:</p>
<ul>
<li>Virtqueue: A queue built in shared memory between the host and guest for performing data input and output.</li>
<li>Virtio driver: The guest-side driver for Virtio-based devices.</li>
<li>Virtio device: The host-side emulation of devices.</li>
</ul>
<p><img src="../03_figs/virtio-overview.svg" alt="Virtio Overview" /></p>
<p>As depicted in the diagram, I/O requests initiated by the guest pass through Virtqueue to the host and responses are also mediated through Virtqueue back to the guest. Detailed behaviors and implementations will be discussed in the next section.</p>
<p>Additionally, when exposing Virtio devices to guests, it's possible to choose specific transport methods. The two common methods are &quot;Virtio Over PCI Bus&quot; which uses PCI (Peripheral Component Interconnect), and &quot;Virtio Over MMIO Bus&quot; which uses MMIO (Memory Mapped I/O). Guests have corresponding drivers such as <code>virtio-pci</code> and <code>virtio-mmio</code> for specific transports, along with Virtio drivers (<code>virtio-net</code>, <code>virtio-blk</code>) for particular device types.</p>
<p>In ToyVMM, we'll initially adopt <code>virtio-mmio</code> as the transport and proceed to implement Network devices for <code>virtio-net</code> and Block devices for <code>virtio-blk</code>.</p>
<h3 id="references-3"><a class="header" href="#references-3">References</a></h3>
<ul>
<li><a href="https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=virtio">OASIS</a></li>
<li><a href="https://www.cs.cmu.edu/%7E412/lectures/Virtio_2015-10-14.pdf">Virtio: An I/O virtualization framework for Linux</a></li>
<li><a href="https://ozlabs.org/%7Erusty/virtio-spec/virtio-paper.pdf">virtio: Towards a De-Facto Standard For Virtual I/O Devices</a></li>
<li><a href="https://blogs.oracle.com/linux/post/introduction-to-virtio">Introduction to VirtIO</a></li>
<li><a href="https://docs.kernel.org/driver-api/virtio/virtio.html">Virtio on Linux</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="implementing-virtio-in-toyvmm"><a class="header" href="#implementing-virtio-in-toyvmm">Implementing Virtio in ToyVMM</a></h1>
<p>In this section, we will delve into the implementation of Virtio in ToyVMM. There are three main topics covered in this discussion:</p>
<ol>
<li>Implementation of Virtqueue</li>
<li>Implementation of lightweight notifications between the guest and host using irqfd and ioeventfd</li>
<li>Implementation of the MMIO Transport</li>
</ol>
<p>As mentioned in the <a href="./03-1_virtio.html">previous section</a>, ToyVMM initially utilizes MMIO as the transport method for Virtio. Before diving into the detailed explanation, let's start by illustrating an overview of the Virtio implementation in this context.</p>
<div align="center">
<img src="../03_figs/virtio_implementation.svg" width="100%">
</div>
<p>By referring to this diagram as needed, we can better understand the explanations and code that follow.</p>
<h3 id="implementation-approach"><a class="header" href="#implementation-approach">Implementation Approach</a></h3>
<p>In the implementation, the VirtioDevice itself is implemented as an abstract concept (<code>Trait</code>), and concrete devices like <code>Net</code> and <code>Block</code> are created to fulfill this trait. Similarly, since there are options for transport methods like <code>PCI</code> and <code>MMIO</code> (with MMIO being used here), we treat transport as an abstract concept and implement it according to the specific implementation, which in this case is <code>MMIO</code>.</p>
<div align="center">
<img src="../03_figs/virtio_related_structs.svg" width="50%">
</div>
<p>Finally, we need to implement Virtqueues. While the number and usage of Virtqueues can vary depending on the implemented Virtio device, the structure of the Virtqueue remains consistent. We'll provide more details on this later.</p>
<h3 id="virtqueue-implementation"><a class="header" href="#virtqueue-implementation">Virtqueue Implementation</a></h3>
<h4 id="virtqueue-deep-dive"><a class="header" href="#virtqueue-deep-dive">Virtqueue Deep-Dive</a></h4>
<p>Before delving into the implementation of Virtqueue, let's gain a more detailed understanding of the typical Virtqueue structure. A Virtqueue is composed of three main elements: the <code>Descriptor Table</code>, the <code>Available Ring</code>, and the <code>Used Ring</code>. Here's what each of them does:</p>
<ul>
<li><code>Descriptor Table</code> : A table that holds entries (<code>Descriptor</code>) that store information such as addr and size of data to be shared between Host and Guest.</li>
<li><code>Available Ring</code> : Structure that manages <code>Descriptor</code> that stores information that the Guest wants to notify to the Host.</li>
<li><code>Used Ring</code> : Structure that manages <code>Descriptor</code> that stores information that the Host wants to notify to the Guest.</li>
</ul>
<div align="center">
<img src="../03_figs/virtqueue.svg" width="80%">
</div>
<p>We'll explore each of these elements in detail while understanding how they cooperate. First, the <code>Descriptor Table</code> contains data structures like <code>Descriptor</code> (as indicated in the diagram) gathered together.</p>
<blockquote>
<pre><code class="language-C">struct virtq_desc { 
        /* Address (guest-physical). */ 
        le64 addr; 
        /* Length. */ 
        le32 len; 
 
/* This marks a buffer as continuing via the next field. */ 
#define VIRTQ_DESC_F_NEXT   1 
/* This marks a buffer as device write-only (otherwise device read-only). */ 
#define VIRTQ_DESC_F_WRITE     2 
/* This means the buffer contains a list of buffer descriptors. */ 
#define VIRTQ_DESC_F_INDIRECT   4 
        /* The flags as indicated above. */ 
        le16 flags; 
        /* Next field if flags &amp; NEXT */ 
        le16 next; 
};
</code></pre>
<p>Source: <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-430005">2.7.5 The Virtqueue Descriptor Table</a></p>
</blockquote>
<p>A <code>Descriptor</code> represents the data to be transferred and the location of the next data in the chain.</p>
<ul>
<li><code>addr</code> is the actual address of the data (guest's physical address), and the length of the data can be obtained from <code>len</code>.</li>
<li><code>flags</code> provide information about whether there is a next descriptor, whether it's write-only, and other flags.</li>
<li><code>next</code> indicates the number of the next descriptor, allowing Descriptor Table to be processed sequentially.</li>
</ul>
<p>Usually, one Descriptor is used to send one piece of data. It's important to note that even if you allocate contiguous memory in virtual address space, if the physical addresses are not contiguous, each Descriptor will be needed for each physical page, resulting in multiple Descriptors being sent sequentially.</p>
<p>Next is the <code>Available Ring</code>. The <code>Available Ring</code> is structured as follows:</p>
<blockquote>
<pre><code class="language-C">struct virtq_avail { 
#define VIRTQ_AVAIL_F_NO_INTERRUPT      1 
        le16 flags; 
        le16 idx; 
        le16 ring[ /* Queue Size */ ]; 
        le16 used_event; /* Only if VIRTIO_F_EVENT_IDX */ 
}
</code></pre>
<p>Source: <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-490006">2.7.6 The Virtqueue Available Ring</a></p>
</blockquote>
<p>The <code>Available Ring</code> is used to specify the Descriptors that need to be notified from the guest to the host.</p>
<ul>
<li><code>flags</code> are used for temporary interrupt suppression and other purposes.</li>
<li><code>idx</code> points to the index of the newest entry in the <code>ring</code>.</li>
<li><code>ring</code> is the actual ring body, holding Descriptor numbers.</li>
<li><code>used_event</code> is also used for interrupt suppression but is only necessary if <code>VIRTIO_F_EVENT_IDX</code> is enabled.</li>
</ul>
<p>The guest writes the location of the actual data to the Descriptor and the index information to the <code>Available Ring</code> (specifically in the <code>ring</code> field). It's important to note that the host needs to remember the index of the last processed <code>ring</code>. The guest can only provide information about the current state of the ring and the latest index (<code>idx</code> field). Therefore, the host compares the last processed entry number with the latest index information (<code>idx</code>) and checks for any differences (indicating new entries). If there are differences, it means there are new entries to process. The host then refers to the ring and retrieves the Descriptor index based on the index difference, obtains the data from the Descriptor, and processes it accordingly, depending on the specific device's implementation.</p>
<p>Finally, there's the <code>Used Ring</code>, which is the reverse of the <code>Available Ring</code>, meaning it's used to specify Descriptors that need to be notified from the host to the guest.</p>
<blockquote>
<pre><code class="language-C">struct virtq_used { 
#define VIRTQ_USED_F_NO_NOTIFY  1 
        le16 flags; 
        le16 idx; 
        struct virtq_used_elem ring[ /* Queue Size */]; 
        le16 avail_event; /* Only if VIRTIO_F_EVENT_IDX */ 
}; 
 
/* le32 is used here for ids for padding reasons. */ 
struct virtq_used_elem { 
        /* Index of start of used descriptor chain. */ 
        le32 id; 
        /* 
         * The number of bytes written into the device writable portion of 
         * the buffer described by the descriptor chain. 
         */ 
        le32 len; 
};
</code></pre>
<p>Source: <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-540008">2.7.8 The Virtqueue Used Ring</a></p>
</blockquote>
<ul>
<li><code>flags</code> are used for temporary interrupt suppression and other purposes.</li>
<li><code>idx</code> points to the index of the newest entry in the <code>ring</code>.</li>
<li><code>ring</code> is the actual ring body, holding Descriptor numbers.</li>
<li><code>used_event</code> is also used for interrupt suppression but is only necessary if <code>VIRTIO_F_EVENT_IDX</code> is enabled.</li>
</ul>
<p>When returning notifications from the host to the guest, the descriptor is used to inform the guest of the location of the data to be returned, corresponding to the reply data. The index of the descriptor is stored in the <code>ring</code> of the <code>Used Ring</code> and the <code>idx</code> value is updated to point to the newest index in the <code>ring</code> before returning control to the guest.</p>
<p>However, unlike the <code>Available Ring</code> the elements of the <code>ring</code> are accompanied by a structure (<code>virtq_used_elem</code>).</p>
<ul>
<li><code>id</code> is the head entry of the descriptor chain (the same as <code>virtq_avail.idx</code>).</li>
<li><code>len</code> stores information such as the total amount of I/O performed on the descriptor chain referred to by <code>id</code> on the host side.</li>
</ul>
<p>The following diagram summarizes what has been explained so far.</p>
<div align="center">
<img src="../03_figs/virtqueue_desc_avail_used_flow.svg" width=100%>
</div>
<p>This concludes the necessary knowledge for implementing Virtqueue.</p>
<h1 id="virtqueue-implementation-on-toyvmm"><a class="header" href="#virtqueue-implementation-on-toyvmm">Virtqueue implementation on ToyVMM</a></h1>
<p>In ToyVMM, the implementation of Virtqueues is located in <code>queue.rs</code>.</p>
<p>The concrete addresses of the <code>Descriptor Table</code>, <code>Available Ring</code>, and <code>Used Ring</code> in guest memory are configured through interactions with the guest-side Device Driver during the guest VM startup. While we'll delve into this exchange as we peek into actual I/O requests from the guest, for now, let's focus on this fact.</p>
<p>ToyVMM needs to perform address accesses based on the specific starting addresses and Virtio specifications. In essence, it operates on a per-descriptor basis (where each descriptor points to the address of the actual data). During data processing, it updates the <code>Available Ring</code> and <code>Used Ring</code>.</p>
<p>Now, let's explore the code. The <code>Queue</code> structure in ToyVMM represents a Virtqueue and is defined as follows:</p>
<pre><code class="language-Rust">#[derive(Clone)]
/// A virtio queue's parameters
pub struct Queue {
    /// The maximal size in elements offered by the device
    max_size: u16,

    /// The queue size in elements the driver selected
    pub size: u16,

    /// Indicates if the queue is finished with configuration
    pub ready: bool,

    /// Guest physical address of descriptor table
    pub desc_table: GuestAddress,

    /// Guest physical address of the available ring
    pub avail_ring: GuestAddress,

    /// Guest physical address of the used ring
    pub used_ring: GuestAddress,

    next_avail: Wrapping&lt;u16&gt;,
    next_used: Wrapping&lt;u16&gt;,
}
</code></pre>
<p>In this structure, you can see the definitions for the <code>Descriptor Table</code>, <code>Available Ring</code>, and <code>Used Ring</code>, which represent the specific addresses in guest memory. These addresses are initialized during interactions with the guest's Device Driver, as mentioned earlier. From ToyVMM's perspective, these are merely physical memory addresses belonging to the guest, and ToyVMM accesses them based on Virtio specifications.</p>
<p>Now, let's delve into address access using the code.</p>
<p>ToyVMM abstracts the sequence of operations to get <code>Descriptor</code> from the state of <code>Available Ring</code> is hiddden as Virtqueue iteration, and in actual device implementations that utilize Virtqueues, you will find code structured like this:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// queue: 'Queue' struct
// desc_chain: 'DescriptorChain' struct
for desc_chain in queue.iter(mem) {
    // 'desc_chain' contains the 'addr,' 'len,' 'flags,' and 'next' values of the descriptor
    // Behind the iteration, data related to 'queue.avail_ring' is adjusted.
}
<span class="boring">}
</span></code></pre></pre>
<p>Behind the scenes of this iteration, let's explain what's happening. First, the <code>iter</code> function is implemented in the <code>Queue</code> structure, and it creates an <code>AvailIter</code> structure. To create this <code>AvailIter</code>, it fetches the latest <code>idx</code> in the <code>Available Ring</code> from the <code>GuestMemory</code> and the <code>avail_ring</code>'s starting address.</p>
<pre><code class="language-Rust">/// A consuming iterator over all available descriptor chain heads offered by the driver
pub fn iter&lt;'a, 'b&gt;(&amp;'b mut self, mem: &amp;'a GuestMemoryMmap) -&gt; AvailIter&lt;'a, 'b&gt; {
    ... // validation codes
    let queue_size = self.actual_size();
    let avail_ring = self.avail_ring;

    // Access the 'idx' fields of available ring
    // skip 2 bytes (= u16 / 'flags' member) from avail_ring address
    // and get 2 bytes (= u16 / 'idx' member representing the newest index of avail_ring) from that address.
    let index_addr = mem.checked_offset(avail_ring, 2).unwrap();
    let last_index: u16 = mem.read_obj(index_addr).unwrap();

    AvailIter {
        mem,
        desc_table: self.desc_table,
        avail_ring: self.avail_ring,
        next_index: self.next_avail,
        last_index: Wrapping(last_index),
        queue_size,
        next_avail: &amp;mut self.next_avail,
    }
}
</code></pre>
<p>As you can see, the <code>iter</code> function returns an <code>AvailIter</code>. Inside the <code>next</code> function of <code>AvailIter</code>, if <code>self.next_index</code> equals <code>self.last_index</code>, it returns <code>None</code>, indicating the end of iteration. The <code>next_index</code> tracks the processed index values.</p>
<p>Inside the <code>next</code> function, the element pointed to by <code>self.next_index</code> in the <code>Available Ring</code> (which corresponds to a descriptor index) is retrieved. The <code>DescriptorChain::checked_new</code> function is called using this retrieved value, and the result value is returned as the element during iteration.</p>
<p>The <code>checked_new</code> function calculates the address of the element pointed to by the index value and accesses it, extracting information like the <code>addr</code>, <code>len</code>, <code>flags</code>, and <code>next</code> of the descriptor. Finally, it constructs a <code>DescriptorChain</code> structure with this information.</p>
<pre><code class="language-Rust">fn checked_new(
    mem: &amp;GuestMemoryMmap,
    desc_table: GuestAddress,
    queue_size: u16,
    index: u16,
) -&gt; Option&lt;DescriptorChain&gt; {
    if index &gt;= queue_size {
        return None;
    }

    // The size of each element of the descriptor table is 16 bytes
    // - le64 addr  = 8 bytes
    // - le32 len   = 4 bytes
    // - le16 flags = 2 bytes
    // - le16 next  = 2 bytes
    // So, the calculation of the offset of the address
    // indicated by desc_index is 'index * 16'
    let desc_head = match mem.checked_offset(desc_table, (index as usize) * 16) {
        Some(a) =&gt; a,
        None =&gt; return None,
    };
    // These reads can't fail unless Guest memory is hopelessly broken
    let addr = GuestAddress(mem.read_obj(desc_head).unwrap());
    mem.checked_offset(desc_head, 16)?;
    let len = mem.read_obj(desc_head.unchecked_add(8)).unwrap();
    let flags: u16 = mem.read_obj(desc_head.unchecked_add(12)).unwrap();
    let next: u16 = mem.read_obj(desc_head.unchecked_add(14)).unwrap();
    let chain = DescriptorChain {
        mem,
        desc_table,
        queue_size,
        ttl: queue_size,
        index,
        addr,
        len,
        flags,
        next,
    };
    if chain.is_valid() {
        Some(chain)
    } else {
        None
    }
}
</code></pre>
<p>Since the <code>next</code> function returns a <code>DescriptorChain</code>, you access the descriptor's information when processing within the loop by accessing the relevant members of the <code>DescriptorChain</code> structure.</p>
<p>Although I have not mentioned it much so far, <code>Used Ring</code> also needs to be updated on the host side.
However, this is not a difficult process and can be implemented by defining the following functions and calling them as necessary.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Puts an available descriptor head into the used ring for use by the guest
pub fn add_used(&amp;mut self, mem: &amp;GuestMemoryMmap, desc_index: u16, len: u32) {
    if desc_index &gt;= self.actual_size() {
        // TODO error
        return;
    }
    let used_ring = self.used_ring;
    let next_used = (self.next_used.0 % self.actual_size()) as u64;

    // virtq_used structure has 4 byte entry before `ring` fields, so skip 4 byte.
    // And each ring entry has 8 bytes, so skip 8 * index.
    let used_elem = used_ring.unchecked_add(4 + next_used * 8);
    // write the descriptor index to virtq_used_elem.id
    mem.write_obj(desc_index, used_elem).unwrap();
    // write the data length to the virtq_used_elem.len
    mem.write_obj(len, used_elem.unchecked_add(4)).unwrap();

    // increment the used index that is the last processed in host side.
    self.next_used += Wrapping(1);

    // This fence ensures all descriptor writes are visible before the index update is.
    fence(Ordering::Release);
    mem.write_obj(self.next_used.0, used_ring.unchecked_add(2))
        .unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>Please remember this underlying mechanism as it forms the basis for the actual I/O implementation in the virtio-net and virtio-blk devices, which we will explain in the following sections.</p>
<h3 id="implementation-of-lightweight-communication-between-guest-and-host-using-irqfd-and-ioeventfd"><a class="header" href="#implementation-of-lightweight-communication-between-guest-and-host-using-irqfd-and-ioeventfd">Implementation of Lightweight Communication between Guest and Host using irqfd and ioeventfd</a></h3>
<p>So far, we've discussed the implementation of Virtqueues, but now let's delve into another crucial aspect related to Virtqueues: the &quot;notification&quot; mechanism required for communication between the host and guest when using Virtqueues. In Virtio, after filling Virtqueues with data, a mechanism for notifying the host from the guest or the guest from the host becomes necessary. Understanding how this notification is realized is essential.</p>
<p>In essence, notifications between the guest and host are achieved using the mechanisms <code>ioeventfd</code> and <code>irqfd</code>. Both of these mechanisms are provided through the <code>KVM API</code>.</p>
<p>First, for notifications from the guest to the host, we use <code>ioeventfd</code>. <code>ioeventfd</code> transforms memory writes caused by PIO/MMIO operations in the guest VM into eventfd notifications. The <code>KVM_IOEVENTFD</code> is used as part of the KVM API, where you provide the eventfd for notifications and the address for MMIO. Writes to this MMIO address are converted into notifications to the specified eventfd. As a result, software on the host side (in this case, ToyVMM) can receive notifications from the guest via eventfd. This mechanism enhances event notification efficiency, making it a more lightweight implementation compared to traditional polling or interrupt handler-based methods.</p>
<div align="center">
<img src="../03_figs/ioeventfd.svg" width="50%">
</div>
<p>Next, for notifications from the host to the guest, we use the <code>irqfd</code> mechanism. Although we've used <code>irqfd</code> in previous implementations, we employ <code>KVM_IRQFD</code> here. By passing the eventfd to be used for notifications and the IRQ number corresponding to the desired guest IRQ when using <code>KVM_IRQFD</code>, writes to the eventfd on the ToyVMM side are converted into hardware interrupts for the specified guest IRQ.</p>
<div align="center">
<img src="../03_figs/ioeventfd.svg" width="50%">
</div>
<p>Using the notification features based on the KVM API mentioned above, we achieve communication between the guest and host. Specific usage details will be discussed in the following section, &quot;Implementation of MMIO Transport.&quot;</p>
<h3 id="implementation-of-mmio-transport"><a class="header" href="#implementation-of-mmio-transport">Implementation of MMIO Transport</a></h3>
<p>Now, let's delve into the implementation of MMIO Transport.</p>
<p><a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-1650002">Virtio Over MMIO</a> provides the official specification for MMIO Transport, and you may want to refer to it as needed.</p>
<p>MMIO Transport is a method that can be easily used in virtual environments without PCI support, and it appears that Firecracker primarily supports MMIO Transport. MMIO Transport operates by performing device operations through Read/Write to specific memory regions.</p>
<p>MMIO Transport does not utilize a generic Device discovery mechanism like PCI. Therefore, Device discovery in MMIO involves providing information about the memory-mapped device's location and interrupt position to the guest OS, as described in <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-1660001">MMIO Device Discovery</a>. While the official documentation suggests documenting this in the Device Tree, an alternative method is to embed it in the kernel's command-line arguments during startup, as documented <a href="https://docs.kernel.org/admin-guide/kernel-parameters">here</a>. This latter method is used in this context because ToyVMM can dynamically adjust these command-line arguments at guest VM startup.</p>
<p>With this method, you can provide information to the guest VM to perform device discovery. The following format is used to describe MMIO device discovery:</p>
<pre><code class="language-bash">(format)
virtio_mmio.device=&lt;size&gt;@&lt;baseaddr&gt;:&lt;irq&gt;

(example)
virtio_mmio.device=4K@0xd0000000:5
</code></pre>
<p>In this case, the guest VM uses the address <code>0xd0000000</code> as the starting point and performs Read/Write at predetermined offsets (register positions) to initialize and configure the device. The details are described in <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-1670002">MMIO Device Register Layout</a>.</p>
<p>From ToyVMM's perspective, it's crucial to ensure that processing according to the specifications is carried out for each Register when Read/Write operations occur. This is the core of the MMIO Transport implementation. Typically, IO to the MMIO region is processed as <code>KVM_EXIT_MMIO</code>, and handling this correctly allows initialization and configuration of the device through this flow.</p>
<p>On the other hand, notifications for I/O via Virtqueue, which we've discussed so far, are managed using ioeventfd and irqfd. In MMIO Transport, writing to the address offset <code>0x050</code> from the base address corresponds to the process of notifying the device that &quot;data to be processed is present in the buffer.&quot; In other words, by associating this address with Eventfd using <code>KVM_IOEVENTFD</code> and then writing code to handle the desired Virtio Device's processing through this Eventfd, Notify events (writes to MMIO) generated by the guest can be directly notified as interrupts to the Eventfd.<br />
Additionally, since IRQ information is provided to the guest via the command line, the guest sets up to launch the corresponding device handler when an interrupt occurs at the specified IRQ. Conversely, when you want to trigger an interrupt in the Virtio device presented to the Guest VM (when you want to delegate processing to the Guest VM), you can do so by writing to this IRQ. Essentially, by creating Eventfd and registering it with IRQ using <code>KVM_IRQFD</code>, you can trigger interrupts by writing to this Eventfd from the ToyVMM side.</p>
<p>The figure below summarizes the above discussion, and ToyVMM implements this scheme:</p>
<div align="center">
<img src="../03_figs/mmio_transport.svg" width="80%">
</div>
<h3 id="mmio-transport---implementation-corresponding-to-mmio-device-register-layout"><a class="header" href="#mmio-transport---implementation-corresponding-to-mmio-device-register-layout">MMIO Transport - Implementation Corresponding to MMIO Device Register Layout</a></h3>
<p>The implementation of MMIO Transport can be found in the <code>mmio.rs</code> file. The <code>MmioTransport</code> structure, like the <code>I/O Bus</code> we discussed in the <a href="./02-5_serial_console_implementation.html">Serial Console implementation</a>, implements the <code>BusDevice</code> trait and is registered within the <code>Bus</code> structure. It allows handling MMIO I/O in response to <code>KVM_EXIT_MMIO</code>, similar to how traditional <code>VcpuExit::IoIn</code> and <code>VcpuExit::IoOut</code> are processed.</p>
<p>Therefore, the <code>MmioTransport</code> implements the <code>read</code> and <code>write</code> functions required to satisfy the <code>BusDevice</code>. These functions contain specific logic for handling register accesses, which are essentially the device emulation processes. Naturally, this implementation follows the specifications of the <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-1670002">MMIO Device Register Layout</a>. Here's a portion of the <code>read</code> function as an example:</p>
<pre><code class="language-Rust">impl BusDevice for MmioTransport {
    // OASIS: MMIO Device Register Layout
    #[allow(clippy::bool_to_int_with_if)]
    fn read(&amp;mut self, offset: u64, data: &amp;mut [u8]) {
        match offset {
            0x00..=0xff if data.len() == 4 =&gt; {
                let v = match offset {
                    0x0 =&gt; MMIO_MAGIC_VALUE,
                    0x04 =&gt; MMIO_VERSION,
                    0x08 =&gt; self.device.device_type(),
                    0x0c =&gt; VENDOR_ID,
                    0x10 =&gt; {
                        self.device.features(self.features_select)
                            | if self.features_select == 1 { 0x1 } else { 0x0 }
                    }
                    0x34 =&gt; self.with_queue(0, |q| q.get_max_size() as u32),
                    0x44 =&gt; self.with_queue(0, |q| q.ready as u32),
                    0x60 =&gt; self.interrupt_status.load(Ordering::SeqCst) as u32,
                    0x70 =&gt; self.driver_status,
                    0xfc =&gt; self.config_generation,
                    _ =&gt; {
                        println!(&quot;unknown virtio mmio register read: 0x{:x}&quot;, offset);
                        return;
                    }
                };
                LittleEndian::write_u32(data, v);
            }
            0x100..=0xfff =&gt; self.device.read_config(offset - 0x100, data),
            _ =&gt; {
                // WARN!
                println!(
                    &quot;invalid virtio mmio read: 0x{:x}:0x{:x}&quot;,
                    offset,
                    data.len()
                );
            }
        }
    }
</code></pre>
<p>A detailed explanation of the <code>read</code> and <code>write</code> functions would be quite extensive, so I'll skip it here. However, as you can see, the implementation is straightforward, and you can easily understand it by referring to the specification while examining the source code.</p>
<p>The processing in this part is essential for handling initialization and configuration of Virtio devices during the initialization sequence called by the Device Driver from the Guest VM during startup. By adding debugging code here, you can observe the device initialization sequence initiated by the guest.</p>
<h4 id="observing-mmio-device-initialization-during-guest-vm-startup-sequence"><a class="header" href="#observing-mmio-device-initialization-during-guest-vm-startup-sequence">Observing MMIO Device Initialization during Guest VM Startup Sequence</a></h4>
<p>The Guest OS includes the Virtio device driver (on the guest side), which is expected to perform Virtio device initialization according to the specification. In this MMIO-based implementation, during startup, the guest VM is supposed to perform R/W operations on the MMIO range of the Virtio device based on the information of the MMIO range specified in the kernel command-line. As Hypervisor, it's necessary to trap this and handle it appropriately since it corresponds to the code section where VMExit occurs during the guest VM's boot. Debugging code can be easily incorporated for observation.</p>
<p>Before we examine the specific processing flow, let's organize the initialization process according to the specification. In the following discussion, we will use the initialization of a Virtio network device (<code>virtio-net</code>) as an example. Device initialization specification is divided into three parts: Initialization in MMIO Transport (<a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-1700003">MMIO-specific Initialization And Device Operation</a>), General Initialization And Device Operation (<a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-1060003">General Initialization And Device Operation</a>), and Device-specific Initialization. Combining these, the flow is generally as follows:</p>
<ol>
<li>Read the Magic Number. Read Device ID, Device Type, Vendor ID, and other information.</li>
<li>Reset the device.</li>
<li>Set the ACKNOWLEDGE status bit.</li>
<li>Read the Device feature bits and set the device with feature bits that the OS and driver can interpret.</li>
<li>Set the FEATURES_OK status bit.</li>
<li>Perform device-specific settings (detecting and configuring Virtqueues, writing configuration).</li>
<li>Set the DRIVER_OK status bit, and at this point, the device is in a live state.</li>
</ol>
<p>Now, keeping this in mind, let's examine the actual processing during the guest VM's startup. Below is an example where I have added debugging code, and the output generated by the debugging code is annotated with comments for explanation.</p>
<pre><code class="language-bash"># Read the magic number from offset 0x00
# Since it's Little Endian, the original values are 116, 114, 105, 118
# 116(10) = 74(16)
# 114(10) = 72(16)
# 105(10) = 69(16)
# 118(10) = 76(16)
# Therefore, it's 0x74726976 (magic number)
MmioRead: addr = 0xd0000000, data = [118, 105, 114, 116]
# Read device id (0x02) from offset 0x04
MmioRead: addr = 0xd0000004, data = [2, 0, 0, 0]
# Read device type (net = 0x01) from offset 0x08
MmioRead: addr = 0xd0000008, data = [1, 0, 0, 0]
# Read vendor id (virtio vendor id = 0x00) from offset 0x0c
MmioRead: addr = 0xd000000c, data = [0, 0, 0, 0]

# This part is Device Initialization Phase (3.1.1 Driver Requirements: Device Initialization)
# Write 0 to offset 0x70 (= Status) to reset the device status
MmioWrite: addr = 0xd0000070, data = [0, 0, 0, 0]
# Read from offset 0x70, and now the device is reset
MmioRead: addr = 0xd0000070, data = [0, 0, 0, 0]
# Write 0x01 to offset 0x70 (= Status) to set the ACKNOWLEDGE bit
MmioWrite: addr = 0xd0000070, data = [1, 0, 0, 0]
# Read from offset 0x70, perhaps for confirmation?
MmioRead: addr = 0xd0000070, data = [1, 0, 0, 0]
# Add 0x02 = Device(2) to offset 0x70 (= Status), so 0x70 is 0x03
MmioWrite: addr = 0xd0000070, data = [3, 0, 0, 0]

# Processing for Device/Driver Feature bits.
# The device provides its own feature set (feature bits),
# and the driver reads it and instructs the device which feature subset to accept.
# 
# First, the Virtio device driver in the Guest OS reads the feature bits
# Write 0x01 to offset 0x14 (= DeviceFeatureSel) to select the next operation
MmioWrite: addr = 0xd0000014, data = [1, 0, 0, 0]
# Read from offset 0x10 (= DeviceFeatures).
# It reads DeviceFeatures bit, and it returns (DeviceFeatureSel * 32) + 31 bits.
# Now DeviceFeatureSel=1, so it returns the DeviceFeatures bits of 64~32 bits.
# For virtio-net, DeviceFeatureSel=0x0000_0001_0000_4c83 (64-bit),
# so it returns 0x0000_0001 in Little Endian.
MmioRead: addr = 0xd0000010, data = [1, 0, 0, 0]
# Write 0x00 to offset 0x14 (= DeviceFeatureSel) for the next operation
MmioWrite: addr = 0xd0000014, data = [0, 0, 0, 0]
# Read from offset 0x10 (= DeviceFeatures).
# Now DeviceFeatureSel=0, so it returns the lower 32 bits of DeviceFeatures.
# For virtio-net, DeviceFeatureSel=0x0000_0001_0000_4c83 (64-bit),
# so it returns 0x0000_4c83 in Little Endian.
# Now, Confirmation of Values of 0x0000_4c83
# Reversed Little Endian: 0,0,76,131
# 76(10) = 4c
# 131(10) = 83
# 0x00004c83 -&gt; Ignoring the bit set by VIRTIO_F_VERSION_1 (0x100000000) in avail_features (0x100004c83)
# In other words,
# * virtio_net_sys::VIRTIO_NET_F_GUEST_CSUM
# * virtio_net_sys::VIRTIO_NET_F_CSUM
# * virtio_net_sys::VIRTIO_NET_F_GUEST_TSO4
# * virtio_net_sys::VIRTIO_NET_F_GUEST_UFO
# * virtio_net_sys::VIRTIO_NET_F_HOST_TSO4
# * virtio_net_sys::VIRTIO_NET_F_HOST_UFO
# The feature bits of this information are returned.
MmioRead: addr = 0xd0000010, data = [131, 76, 0, 0]
# The reading of feature bits is done here, and from here, it instructs the device about the feature subset to accept.
# The process is similar to reading, where you write 0x00/0x01 to DriverFeatureSel bit
# and then write the feature bits you want to set to DriverFeature.
# First, write 0x01 to offset 0x24 (DriverFeatureSel/activate guest feature) to set 'acked_features' to 0x01
MmioWrite: addr = 0xd0000024, data = [1, 0, 0, 0]
# Write 0x01 (= 0x0000_0001, one of the values read earlier) to offset 0x20 (DriverFeatures).
# Since DriverFeatureSel is set to 0x01, a 32-bit shift occurs, and 0x0000_0001_0000_0000 is actually set.
MmioWrite: addr = 0xd0000020, data = [1, 0, 0, 0]
# Write 0x00 to offset 0x24 (DriverFeatureSel/activate guest feature) to set 'acked_features' to 0x00
MmioWrite: addr = 0xd0000024, data = [0, 0, 0, 0]
# Write 0x0000_4c83 (the other value read earlier) to offset 0x20 (DriverFeatures).
MmioWrite: addr = 0xd0000020, data = [131, 76, 0, 0]
# The processing of Feature bits is completed here.

# Read offset 0x70(= Status) -&gt; Since 0x03 was specified most recently, returning 0x03 is good.
MmioRead: addr = 0xd0000070, data = [3, 0, 0, 0]
# Write the value (3 + 8 = 11) obtained by 'adding' 0x08 = FEATURES_OK(8) to offset 0x70(= Status)
MmioWrite: addr = 0xd0000070, data = [11, 0, 0, 0]
# Read from offset 0x70(= Status). Naturally, 11 is returned.
MmioRead: addr = 0xd0000070, data = [11, 0, 0, 0]

# Device-specific setup starts from here (4.2.3.2 Virtqueue Configuration)
# Write 0x00 to offset 0x30 (= QueueSel) to select self.queue_select
MmioWrite: addr = 0xd0000030, data = [0, 0, 0, 0]
# Read from offset 0x44 (= QueueReady), and it's not ready yet, so it returns 0x0 as expected
MmioRead: addr = 0xd0000044, data = [0, 0, 0, 0]
# Read from offset 0x34 (= QueueNumMax) to check the queue size
MmioRead: addr = 0xd0000034, data = [0, 1, 0, 0]
# Write the previously read QueueNum to offset 0x38 (= QueueNum)
MmioWrite: addr = 0xd0000038, data = [0, 1, 0, 0]

# Virtual queue's 'descriptor' area 64-bit long physical address
# Write the location of the descriptor area of the selected queue (0)
# to offset 0x80 (= QueueDescLow = lo(q.desc_table) / lower 32 bits of the address)
MmioWrite: addr = 0xd0000080, data = [0, 64, 209, 122]
# Same as above, but set the remaining part of 0x84 (QueueDescHigh = hi(q.desc_table) / higher 32 bits of the address)
MmioWrite: addr = 0xd0000084, data = [0, 0, 0, 0]
# Combining the two, it's 0x0000_0000_7ad1_4000 (q.desc_table) as the base address

# Virtual queue's 'driver' area 64-bit log physical address
# Write the location of the driver area (avail_ring) of the selected queue (0)
# to offset 0x90 (= QueueDeviceLow = lo(q.avail_ring) / lower 32 bits of the address)
MmioWrite: addr = 0xd0000090, data = [0, 80, 209, 122]
# Same as above, but set the remaining part of 0x94 (QueueDeviceHigh = hi(q.avail_ring) / higher 32 bits of the address)
MmioWrite: addr = 0xd0000094, data = [0, 0, 0, 0]
# Combining the two, it's 0x0000_0000_7ad1_5000 (q.avail_ring)
# Address range of q.desc_table: q.avail_ring - q.desc_table = 0x1000 = 512(10)

# Virtual queue's 'device' area 64-bit long physical address
# Write the location of the device area (used_ring) of the selected queue (0) to offset 0xa0 (= QueueDeviceLow = lo(q.used_ring) / lower 32bits of the address)
MmioWrite: addr = 0xd00000a0, data = [0, 96, 209, 122]
# Same as above, but set the remaining part of 0xa4 (QueueDeviceHigh = hi(q.used_ring) / higher 32 bits of the address)
MmioWrite: addr = 0xd00000a4, data = [0, 0, 0, 0]
# Combining the two, it's 0x0000_0000_7ad1_6000 (q.used_ring)
# Address range of q.avail_ring: q.used_ring - q.avail_ring = 0x1000 = 512(10)

# Write 0x1 to offset 0x44 (QueueReady = q.ready) to make it Ready
MmioWrite: addr = 0xd0000044, data = [1, 0, 0, 0]

# The same process is performed for the other queue (1)
MmioWrite: addr = 0xd0000030, data = [1, 0, 0, 0]
MmioRead: addr = 0xd0000044, data = [0, 0, 0, 0]
MmioRead: addr = 0xd0000034, data = [0, 1, 0, 0]
MmioWrite: addr = 0xd0000038, data = [0, 1, 0, 0]
MmioWrite: addr = 0xd0000080, data = [0, 128, 196, 122]
MmioWrite: addr = 0xd0000084, data = [0, 0, 0, 0] # q.desc_table = 0x0000_0000_7ad1_8000
MmioWrite: addr = 0xd0000090, data = [0, 144, 196, 122]
MmioWrite: addr = 0xd0000094, data = [0, 0, 0, 0] # q.avail_ring = 0x0000_0000_7ad1_9000
MmioWrite: addr = 0xd00000a0, data = [0, 160, 196, 122]
MmioWrite: addr = 0xd00000a4, data = [0, 0, 0, 0] # q.used_ring = 0x0000_0000_7ad1_a000
MmioWrite: addr = 0xd0000044, data = [1, 0, 0, 0]
# Device-specific setup (setup of two queues for virtio-net) is completed here

# Read from offset 0x70 (= Status) and return 0x11, which was written recently
MmioRead: addr = 0xd0000070, data = [11, 0, 0, 0]
# Write 0x04 (DRIVER_OK(4)) to offset 0x70 (= Status) to 'add' it to the current value (11 + 4 = 15)
MmioWrite: addr = 0xd0000070, data = [15, 0, 0, 0]
# Read from offset 0x70 (= Status), and naturally, it returns 15
MmioRead: addr = 0xd0000070, data = [15, 0, 0, 0]
# Device Initialization Phase (3.1.1 Driver Requirements: Device Initialization) is completed here
</code></pre>
<p>When interpreted carefully, it becomes evident that the behavior aligns with the specifications. For reading and writing device-specific configurations, It execute the appropriate function from the <code>VirtioDevice</code> associated with the <code>MmioTransport</code> initialization. In other words, the <code>VirtioDevice</code> Trait requires implementations to provide the necessary information for such operations.</p>
<p>Additionally, during the initialization process, there are multiple MMIO writes to offset=0x70. These correspond to updating the status as the initialization sequence progresses. ToyVMM confirms the completion of these status updates (<code>ACKNOWLEDGE</code> -&gt; <code>DRIVER</code> -&gt; <code>FEATURES_OK</code> -&gt; <code>DRIVER_OK</code> transition). After the <code>DRIVER_OK</code> status update, ToyVMM calls the <code>activate</code> function to perform device-specific activation procedures (e.g., setting up epoll and its handlers). The specifics of this activation process are delegated to individual device implementations.</p>
<h3 id="summary"><a class="header" href="#summary">Summary</a></h3>
<p>In this section, we provided a detailed explanation of the <code>Virtio</code> mechanisms within ToyVMM. In the following sections, we will introduce concrete implementations of actual devices that were not covered in this section, specifically Network Devices and Block Devices. We will also verify the execution of specific I/O operations using the code implemented according to the Virtio principles.</p>
<h3 id="reference-1"><a class="header" href="#reference-1">Reference</a></h3>
<ul>
<li><a href="https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=virtio">OASIS</a></li>
<li><a href="https://syuu1228.github.io/howto_implement_hypervisor/">Creating a Hypervisor</a></li>
<li><a href="https://docs.kernel.org/virt/kvm/api.html">The Definitive KVM (Kernel-based Virtual Machine) API Documentation</a></li>
<li><a href="https://github.com/qemu/qemu/">QEMU</a></li>
<li><a href="https://blogs.oracle.com/linux/post/introduction-to-virtio">Introduction to VirtIO</a></li>
<li><a href="https://www.redhat.com/ja/blog/virtqueues-and-virtio-ring-how-data-travels">Virtqueues and Virtio Ring: How the Data Travels</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="implement-virtio-net-device"><a class="header" href="#implement-virtio-net-device">Implement virtio-net device</a></h1>
<p>In this section, we will proceed with the implementation of a Network Device as a specific Virtio Device. While the specification can be found in the official OASIS documentation <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-2170001">Network Device</a>, please note that this implementation may not align perfectly with the specification. If you haven't read the previous sections, be sure to review them before continuing with this section.</p>
<h3 id="virtio-net-mechanism"><a class="header" href="#virtio-net-mechanism">virtio-net Mechanism</a></h3>
<p>In <code>virtio-net</code>, three types of Virtqueues are typically used: Transmit Queue, Receive Queue, and Control Queue.
The Transmit Queue is used for data transmission from the guest to the host, the Receive Queue for data transmission from the host to the guest. The Control Queue is used for guest-to-host operations related to NIC settings, such as setting promiscuous mode, enabling/disabling broadcast reception, and multicast reception.
For the sake of brevity, we are omitting the implementation of the Control Queue in this section. It is worth noting that the specification allows scaling the number of Virtqueues, but for simplicity, we are not implementing that.</p>
<p>In the following sections, we will provide detailed implementation-based explanations of the network device.</p>
<h3 id="network-device-implementation-details"><a class="header" href="#network-device-implementation-details">Network Device Implementation Details</a></h3>
<p>The implementation of <code>virtio-net</code> can be found in <code>net.rs</code>.
We will break down and explain the initialization phase and the post-initialization phase.</p>
<p>The following diagram primarily focuses on the initialization process of the Network Device:</p>
<div align="center">
<img src="../03_figs/net-device_init_activate.svg", width="80%">
</div>
<p>The <code>Net</code> struct implements the <code>VirtioDevice</code> Trait and is associated with the <code>MmioTransport</code>. As mentioned earlier, device-specific operations during MMIO Transport initialization depend on the implementation of this <code>Net</code> struct.</p>
<p>For example, during initialization, a query about the <code>Device Type</code> occurs. According to the specification, for a <code>Net</code> device, this should return <code>0x01</code>, and the <code>Net</code> struct implements it as follows:</p>
<pre><code class="language-Rust">impl VirtioDevice for Net {
    fn device_type(&amp;self) -&gt; u32 {
        // types::NETWORK_CARD:u32 = 0x01
        types::NETWORK_CARD
    }
    ...
}
</code></pre>
<p>Similarly, queries about the <code>Device Feature</code> should be implemented to return device-specific values. Additionally, during initialization, the guest OS initializes the <code>Descriptor Table</code>, <code>Available Ring</code>, and <code>Used Ring</code> of the Virtqueues, and the addresses for each of these are notified. This allows the addresses to be stored for each queue so they can be referenced during actual processing.
Once the initialization steps are completed and the status is updated to a specific value, ToyVMM executes the <code>activate</code> function implemented in the device. In the case of the <code>Net</code> device, within this <code>activate</code> function, various file descriptors are registered with <code>epoll</code>, and the setup of handlers (e.g., <code>NetEpollHandler</code>) triggered by <code>epoll</code> is performed. The <code>Net</code> device emulates I/O by creating a Tap device on the host side and writing data received from the guest via Virtqueue to the Tap device for transmission (<code>Tx</code>), and writing incoming data from the Tap device to Virtqueue to notify the guest (<code>Rx</code>). Four file descriptors are registered with <code>epoll</code>: the <code>fd</code> of the <code>tap</code> device, an <code>eventfd</code> for notification of the Tx Virtqueue, an <code>eventfd</code> for notification of the Rx Virtqueue, and an <code>eventfd</code> for halting in unexpected situations.</p>
<p>Next, we will provide a detailed diagram of the Network Device in its activated state:</p>
<div align="center">
<img src="../03_figs/net-device_activated.svg", width="100%">
</div>
<p>When one of the registered file descriptors in <code>epoll</code> triggers an event, it dispatches the <code>NetEpollHandler</code> for event processing. <code>NetEpollHandler</code> varies its actions based on the event triggered. In any case, within the <code>NetEpollHandler</code>, it references the Virtqueue and performs I/O emulation.</p>
<p>One important point to note is that the initialization process of the device, based on <code>KVM_EXIT_MMIO</code>, is a processing call within the thread handling vCPU. In ToyVMM, this is done in a separate thread from the main thread. However, the thread responsible for executing I/O is also separate from the vCPU processing thread (currently handled in the main thread). To facilitate communication between these threads, channels are used to send the initialized <code>NetEpollHandler</code>. This allows I/O to be processed while the guest VM is running and CPU emulation is conducted in a separate thread.</p>
<p>As mentioned earlier, communication between the host and guest is primarily triggered by events related to Virtqueue Eventfds and Tap device file descriptors. In the following sections, we will provide more detailed explanations of how processing occurs in both the Tx and Rx cases.</p>
<h4 id="tx-guest---host"><a class="header" href="#tx-guest---host">Tx (Guest -&gt; Host)</a></h4>
<p>Let's start by examining the implementation of communication in the Guest -&gt; Host direction (Tx) and provide a detailed explanation. Once again, for Tx, the <code>Descriptor Table</code>, <code>Available Ring</code>, and <code>Used Ring</code> function as follows:</p>
<ul>
<li><code>Descriptor Table</code>: It contains descriptors that point to the data the Guest is trying to transmit.</li>
<li><code>Available Ring</code>: It stores the index of the descriptor pointing to the transmit data. The Host reads this index and processes Tx emuration.</li>
<li><code>Used Ring</code>: It stores the index of descriptors that have been processed on the Host side. The Guest reads this index to collect processed descriptors.</li>
</ul>
<p>Tx initiates when the guest (guest device driver) prepares a packet, and control is transferred to ToyVMM when a Write operation occurs on <code>QueueNotify</code>.</p>
<p>Specifically, in the guest, the following steps are expected:</p>
<ol>
<li>The guest sets the data address and length in the first Descriptor's <code>addr</code> and <code>len</code> fields.</li>
<li>The guest stores the index of the <code>Descriptor</code> pointing to the transmit data in the <code>Available Ring</code> entry, pointed to by the <code>Available Ring</code> index.</li>
<li>The guest increments the <code>Available Ring</code> index.</li>
<li>To notify the host of unprocessed data, the guest writes to the MMIO <code>QueueNotify</code>.</li>
</ol>
<p>Now, let's shift our focus to the host side, which is handled by ToyVMM. The EventFd triggered by the write to MMIO's <code>QueueNotify</code> is picked up by epoll monitoring. It triggers the NetEpollHandle's handler processing, specifically, the execution of the <code>TX_QUEUE_EVENT</code> corresponding operation.</p>
<div align="center">
<img src="../03_figs/net-device_tx_1.svg", width="100%">
</div>
<p>The implementation calls the <code>process_tx</code> function.<br />
In <code>process_tx</code>, the processing proceeds as follows:</p>
<ol>
<li>Initialization of necessary variables, including:
<ul>
<li><code>frame[0u8; 65562]</code>: A buffer to copy the data prepared by the guest.</li>
<li><code>used_desc_heads[0u16; 256]</code>: Data for storing the index of processed Descriptors and for updating the Used Ring at the end.</li>
<li><code>used_count</code>: A counter to keep track of how much data has been read from the guest.</li>
</ul>
</li>
<li>Iteration over the TX Virtqueue until it stops, repeating steps 3 to 5.</li>
<li>Reading the data information (located at <code>addr</code>) pointed to by the Descriptor and loading it into the buffer. If the <code>next</code> field points to another Descriptor, it is followed, and the data is read out.</li>
<li>Writing the read data to the Tap device.</li>
<li>Storing the index of processed Descriptors (the Descriptor pointed to by the Available Ring) in <code>used_desc_heads</code>.</li>
<li>Updating the <code>Used Ring</code> with the information of processed Descriptors' indexes and the total amount of data stored.</li>
<li>Writing to the <code>eventfd</code> associated with the irq to trigger an interrupt and delegate processing to the guest.</li>
</ol>
<div align="center">
<img src="../03_figs/net-device_tx_2.svg", width="100%">
</div>
<p>On the guest side, the following steps are expected:</p>
<ol>
<li>Check the index of the <code>Used Ring</code>, and if there is a difference between the index of processed entries and the previously recorded index, check and process the Descriptor indexes to fill this gap.</li>
<li>The Descriptors pointed to by these Descriptor indexes have been processed on the host side, so they are returned to the chain of free Descriptors, and the recorded Descriptor numbers are updated.</li>
<li>Repeat steps 1 and 2 until there is no difference between the index of the <code>Used Ring</code> and the recorded index position.</li>
</ol>
<p>This completes the Tx processing.</p>
<h4 id="rx-host---guest"><a class="header" href="#rx-host---guest">Rx (Host -&gt; Guest)</a></h4>
<p>Next, let's explain the communication from the host to the guest (Rx) while referring to the implementation.
In the case of Rx, the <code>Descriptor Table</code>, <code>Available Ring</code>, and <code>Used Ring</code> function as follows:</p>
<ul>
<li><code>Descriptor Table</code>: It contains descriptors that point to received data, allowing the Guest to access the received data from the Tap.</li>
<li><code>Available Ring</code>: It is used for the transfer of completed empty descriptors from the Guest's side.</li>
<li><code>Used Ring</code>: It stores the index of descriptors pointing to received data, which the Guest reads to process the necessary descriptors.</li>
</ul>
<p>Comparing Rx to Tx, you can see that the roles of the <code>Available Ring</code> and <code>Used Ring</code> are reversed.</p>
<p>Unlike Tx, Rx requires handling two types of event triggers: incoming packets from the Tap device and completion notifications from the guest for the Rx Virtqueue. Handling Rx is more complex compared to Tx due to the need to manage these two types of event triggers.</p>
<p>First, let's discuss the basic Rx processing flow, followed by considerations for cooperative behavior.</p>
<h5 id="basic-rx-processing-flow"><a class="header" href="#basic-rx-processing-flow">Basic Rx Processing Flow</a></h5>
<p>The host receives data from the Tap device and needs to notify the guest by filling the Rx Virtqueue with data. To do this, some basic setup is required for the Rx Virtqueue, such as knowing where to place the data. It's important to remember that, from the perspective of ToyVMM, each element of the Virtqueue consists only of guest memory addresses, and necessary operations are performed based on Virtqueue memory access.</p>
<p>Returning to the guest, the following steps are expected:</p>
<ol>
<li>After initializing Descriptor chains and other settings, the guest assigns the index of the head of the free Descriptor chain to the empty entry pointed to by the <code>Available Ring</code> index.</li>
<li>The guest increments the <code>Available Ring</code> index.</li>
<li>To notify the host, the guest writes to MMIO <code>QueueNotify</code>.</li>
</ol>
<p>On the host side, when Rx Virtqueue notification is received from the guest, it interprets this as the <strong>Rx data space is ready for address access.</strong> </p>
<div align="center">
<img src="../03_figs/net-device_rx_1.svg", width="100%">
</div>
<p>Suppose the Tap device receives a packet at this point. By detecting the trigger of the Tap's file descriptor, the <code>NetEpollHandler</code> is dispatched, and it performs event processing for <code>RX_TAP_EVENT</code>. This processing mainly involves calling the <code>process_rx</code> function. However, there are certain conditions under which this may not happen, which we will discuss later.</p>
<p><code>process_rx</code> proceeds as follows:</p>
<ol>
<li><code>process_rx</code> processes as many frames as possible received from the Tap by looping until no data can be read.</li>
<li>If a successful read occurs from the Tap, the size of the read data is stored in <code>self.rx_count</code>, and the <code>rx_single_frame</code> function, which processes a single frame, is called.</li>
<li>In <code>rx_single_frame</code>, the first entry from the Available Ring is retrieved, and the beginning of the free Descriptor chain that this entry points to is extracted.</li>
<li>The received single frame's data is stored in the Descriptor, calculating the size along the way. If the received frame cannot fit into a single Descriptor, the <code>next</code> field of the Descriptor is followed to continue storing data.</li>
<li>The <code>Used Ring</code> of the Rx Virtqueue is updated with information about the index of the Descriptor containing Rx data and the total amount of data stored.</li>
<li>An interrupt is triggered by writing to the <code>eventfd</code> associated with the irq to delegate processing to the guest.</li>
</ol>
<p>The following diagram illustrates the process of writing the received data into the Descriptor chain using the Available Ring:</p>
<div align="center">
<img src="../03_figs/net-device_rx_2.svg", width="100%">
</div>
<p>Once the data from the Tap device has been written, the <code>Used Ring</code> is updated, and an interrupt is sent to the guest.</p>
<div align="center">
<img src="../03_figs/net-device_rx_3.svg", width="100%">
</div>
<p>On the guest side, the guest checks the <code>Used Ring</code> index, references the Descriptor pointed to by new entries, retrieves and processes Rx data, and performs any necessary operations. It then updates the Available Ring, signaling to the host that it is ready to accept new data.</p>
<h5 id="when-tap-trigger-occurs-without-rx-virtqueue-preparation"><a class="header" href="#when-tap-trigger-occurs-without-rx-virtqueue-preparation">When Tap Trigger Occurs Without Rx Virtqueue Preparation</a></h5>
<p>It is expected that there may be cases where Tap receives a packet when Rx Virtqueue is not ready. In such cases, even if data is extracted from Tap, it is impossible to obtain information about where to store it, preventing further processing.</p>
<p>To address this, a mechanism to delay Tap device processing until Rx Virtqueue is prepared is required. In the ToyVMM code, this is controlled using a flag called <code>deferred_rx</code>.</p>
<p>When this flag is set, ToyVMM's Rx-related processing follows the following strategy:</p>
<ul>
<li>When <code>RX_QUEUE_EVENT</code> is triggered, indicating that the Rx Virtqueue is ready to receive data from the guest, data is immediately retrieved from the Tap device, and processing continues. If processing is completed at this point, the flag is cleared.</li>
<li>When <code>TAP_RX_EVENT</code> is triggered, processing is temporarily paused to check the status of the Rx Virtqueue. If processing can proceed, it continues, and if processing is completed, the flag is cleared. If processing cannot proceed or the amount of data in the Virtqueue is smaller than the received data, the flag is not cleared, and it waits for the Rx Virtqueue to be ready again.</li>
</ul>
<h5 id="when-tap-reception-exceeds-the-prepared-rx-virtqueue"><a class="header" href="#when-tap-reception-exceeds-the-prepared-rx-virtqueue">When Tap Reception Exceeds the Prepared Rx Virtqueue</a></h5>
<p>Another case to consider is when the data received by Tap exceeds the capacity of the prepared Virtqueue, as briefly mentioned above. In this case, the strategy is essentially the same, and the processing is temporarily interrupted until the next Virtqueue is prepared, controlled by the <code>deferred_rx</code> flag. When the Virtqueue is ready, processing resumes.</p>
<h3 id="verification-of-virtio-net-operation"><a class="header" href="#verification-of-virtio-net-operation">Verification of virtio-net Operation</a></h3>
<p>Let's test whether communication between the host and guest is possible using the implemented <code>Virtio</code> mechanism and the Network Device. Below is the result of executing the <code>ip addr</code> command inside the guest. <code>eth0</code> is recognized as a virtual NIC.</p>
<pre><code>localhost:~# ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 02:32:22:01:57:33 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::32:22ff:fe01:5733/64 scope link
       valid_lft forever preferred_lft forever
</code></pre>
<p>Let's also check on the host side. In ToyVMM, a Tap device is created on the host side. So assign an IP address (<code>192.168.0.10/24</code>).</p>
<pre><code class="language-bash">140: vmtap0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UNKNOWN group default qlen 1000
    link/ether c6:69:6d:65:05:cf brd ff:ff:ff:ff:ff:ff
    inet 192.168.0.10/24 brd 192.168.0.255 scope global vmtap0
       valid_lft forever preferred_lft forever
</code></pre>
<p>Additionally, assign an IP address to the guest side. Here, an address within the same subnet range as the host is assigned.</p>
<pre><code>localhost:~# ip addr add 192.168.0.11/24 dev eth0
</code></pre>
<p>Now that everything is set up, let's ping the IP address of the host's Tap interface from within the guest. You should receive responses as follows:</p>
<pre><code>localhost:~# ping -c 5 192.168.0.10
PING 192.168.0.10 (192.168.0.10): 56 data bytes
64 bytes from 192.168.0.10: seq=0 ttl=64 time=0.394 ms
64 bytes from 192.168.0.10: seq=1 ttl=64 time=0.335 ms
64 bytes from 192.168.0.10: seq=2 ttl=64 time=0.334 ms
64 bytes from 192.168.0.10: seq=3 ttl=64 time=0.321 ms
64 bytes from 192.168.0.10: seq=4 ttl=64 time=0.330 ms

--- 192.168.0.10 ping statistics ---
5 packets transmitted, 5 packets received, 0% packet loss
round-trip min/avg/max = 0.321/0.342/0.394 ms
</code></pre>
<p>Conversely, if you ping the IP address of the <code>virtio-net</code> interface in the guest from the host, you should also receive responses:</p>
<pre><code class="language-bash">[mmichish@mmichish ~]$ ping -c 5 192.168.0.11
PING 192.168.0.11 (192.168.0.11) 56(84) bytes of data.
64 bytes from 192.168.0.11: icmp_seq=1 ttl=64 time=0.410 ms
64 bytes from 192.168.0.11: icmp_seq=2 ttl=64 time=0.366 ms
64 bytes from 192.168.0.11: icmp_seq=3 ttl=64 time=0.385 ms
64 bytes from 192.168.0.11: icmp_seq=4 ttl=64 time=0.356 ms
64 bytes from 192.168.0.11: icmp_seq=5 ttl=64 time=0.376 ms

--- 192.168.0.11 ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 4114ms
rtt min/avg/max/mdev = 0.356/0.378/0.410/0.028 ms
</code></pre>
<p>Although this is a simple confirmation using ICMP, it confirms that communication is functioning properly!</p>
<h3 id="reference-2"><a class="header" href="#reference-2">Reference</a></h3>
<ul>
<li><a href="https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=virtio">OASIS</a></li>
<li><a href="https://syuu1228.github.io/howto_implement_hypervisor/">Creating a Hypervisor</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="implement-virtio-blk-device"><a class="header" href="#implement-virtio-blk-device">Implement virtio-blk device</a></h1>
<p>In this section, we will implement the Block device used by the guest's <code>virtio-blk</code>. The specification is similar to Virtio and is officially published by OASIS in the <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-2170002">Block Device</a> section. However, please note that this implementation may not be fully compliant with this specification.</p>
<p>Before proceeding with this section, make sure you have read the previous sections as the concepts introduced earlier will be used without further explanation here. Additionally, please read the <a href="./03-3_virtio-net.html">Implement virtio-net device</a> from the previous section as this section may omit details that overlap with the <code>virtio-net</code> implementation.</p>
<h3 id="mechanism-of-virtio-blk"><a class="header" href="#mechanism-of-virtio-blk">Mechanism of virtio-blk</a></h3>
<p>In <code>virtio-blk</code>, a single Virtqueue is used to represent DISK Read/Write from the guest. Unlike <code>virtio-net</code>, there are no external factors (such as receiving data from Tap), and it is purely driven by I/O requests from the guest. Therefore, it operates with a minimum of one Virtqueue. Although the specification allows for scaling the number of Virtqueues, we have not implemented it for simplicity.</p>
<p>In the following sections, we will explain the implementation details based on code examples.</p>
<h3 id="implementation-details-of-virtio-blk"><a class="header" href="#implementation-details-of-virtio-blk">Implementation Details of virtio-blk</a></h3>
<p>The implementation of <code>virtio-blk</code> can be found in <code>block.rs</code>. The roles and relationships of various structures are shown in the following diagram:</p>
<p><img src="../03_figs/blk-device_activated.svg" alt="Block Device Initialization" /></p>
<p>As mentioned earlier, the concrete implementation depends on the specific device. However, it is abstracted by the <code>VirtioDevice</code> trait, so everything else, apart from the details of various device implementations, works the same as shown for <code>virtio-net</code>. Therefore, this diagram mostly resembles the internal details of the Block Device, with minor differences.</p>
<p>During initialization, queries such as <code>Device Type</code> and <code>Features</code> are responded to by the specific implementation of the <code>Block</code> device. Similar to the <code>Net</code> device, the addresses of the Virtqueue on the Guest's address space are set up and provided. Once the initialization steps are completed, the <code>activate</code> function is executed.</p>
<p>For the <code>Block</code> device, like the <code>Net</code> device, various file descriptors are registered with <code>epoll</code> during initialization. Handlers (<code>BlockEpollHandler</code>) are set up to be executed when <code>epoll</code> triggers, just like in the case of the <code>Net</code> device. In the <code>Block</code> device, to emulate I/O, a host-side file (to be operated as a <code>BlockDevice</code>) is opened, and read/write requests from the guest are performed on it. The file descriptors registered with <code>epoll</code> include an <code>eventfd</code> for the <code>Virtqueue</code> and another <code>eventfd</code> for stopping the system in case of unexpected situations, making a total of two file descriptors.
In comparison to the <code>Net</code> device, you can see that the Tap device has been replaced by a file, and the number of eventfds has changed. However, apart from these changes, there are no significant differences in the behavior.</p>
<p>For the <code>Block</code> device, a single Virtqueue is associated with the firing of an eventfd. Therefore, we will focus on this process in the following sections.</p>
<h4 id="io-requests-in-virtio-blk"><a class="header" href="#io-requests-in-virtio-blk">I/O Requests in virtio-blk</a></h4>
<p>Before delving into the implementation details, let's explain the I/O requests in <code>virtio-blk</code>.</p>
<p>As mentioned earlier, <code>virtio-blk</code> handles I/O requests from the guest through a single Virtqueue. However, guest-originated I/O requests can be broadly categorized into two types: <code>Read</code> and <code>Write</code>, and the processing required for each of them is significantly different. The host must determine how to recognize these requests and emulate the I/O correctly.</p>
<p>To explain this, we need to understand how the <code>Descriptor Table</code> is used in <code>virtio-blk</code>. The data sent by the guest to Virtqueue follows the structure below:</p>
<blockquote>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct virtio_blk_req {
        le32 type;
        le32 reserved;
        le64 sector;
        u8 data[];
        u8 status;
};
<span class="boring">}
</span></code></pre></pre>
<p>Source: <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-2850006">Block Device: Device Operation</a></p>
</blockquote>
<p>In practice, this is created as <strong>three entries</strong> in the <code>Descriptor Table</code>, with each entry being linked by the <code>next</code> field.</p>
<ul>
<li>The first <code>Descriptor</code> entry points to the addresses containing the <code>type</code>, <code>reserved</code>, and <code>sector</code> data.</li>
<li>The second <code>Descriptor</code> entry points to the beginning of the data area where data is written.</li>
<li>The third <code>Descriptor</code> entry points to the address where the <code>status</code> will be written by Host.</li>
</ul>
<div align="center">
<img src="../03_figs/virtio-blk_virtqueue.svg", width="50%">
</div>
<p>The <code>type</code> field indicates the type of I/O (e.g., <code>read</code>, <code>write</code>, or other I/O requests). By examining this value, the host can determine how to behave differently.</p>
<p>In the case of a <code>read</code>, the second <code>Descriptor</code> entry points to the area where the host should store the data it reads from the Disk. The host can determine the sector to read from based on the <code>sector</code> value and read the necessary amount of data (<code>desc.len</code> of the second <code>Descriptor</code>).</p>
<p>In the case of a <code>write</code>, the second <code>Descriptor</code> entry contains the data that should be written to the Disk. The host reads the data and writes it to the sector specified by the <code>sector</code> value.</p>
<p>The third <code>Descriptor</code> entry is used to write status information, indicating whether the I/O was successful or failed.</p>
<p>In summary, the type of Disk I/O and the necessary data or buffers are provided through Virtqueue. It is the responsibility of the host to interpret this according to the specification, emulate the I/O correctly, and provide the appropriate status.</p>
<h4 id="implementation-of-disk-io-in-toyvmm"><a class="header" href="#implementation-of-disk-io-in-toyvmm">Implementation of Disk I/O in ToyVMM</a></h4>
<p>Let's explain the guest-originated Disk I/O requests in the context of the implementation. Everything else is essentially the same as the <code>Tx</code> case of the <code>Net</code> Device, so let's start with the point where the processing is delegated to the host through <code>QueueNotify</code>.</p>
<p>Writing to MMIO's <code>QueueNotify</code> triggers an EventFd, which is picked up by <code>epoll</code> monitoring. Specifically, the handler for <code>QUEUE_AVAIL_EVENT</code> is executed. In practice, the <code>process_queue</code> function is called, and if its return value is <code>true</code>, the <code>signal_used_queue</code> function is called.
The <code>signal_used_queue</code> function simply sends an interrupt to the guest, so the important part to examine is the <code>process_queue</code> function.</p>
<p>In the <code>process_queue</code> function, the following steps are performed:</p>
<ol>
<li>Initialize necessary variables:
<ul>
<li><code>used_desc_heads[(u16, u32), 256]</code>: Stores the index and data length of processed <code>Descriptors</code>. This is used to populate the <code>used_ring</code> at the end of <code>process_queue</code>.</li>
<li><code>used_count</code>: Keeps track of how many I/O requests from the guest have been processed.</li>
</ul>
</li>
<li>Iterate through Virtqueue until it stops, repeating steps 2 to 4.</li>
<li>Retrieve the <code>Descriptor</code> pointed to by the <code>Available Ring</code>, parse it according to the <code>virtio-blk</code> specification, and create a <code>Request</code> structure. The <code>Request</code> structure contains parsed information such as request type, sector information, data address, data length, and status address.</li>
<li>Call the <code>execute</code> function, which performs the I/O request based on the content of the <code>Request</code> structure. For successful I/O, it returns the length of data read (for Read) or 0 (for Write and other types). This value is used to write to the <code>used_ring</code>.</li>
<li>Write the status (success or failure of I/O) to the status address and write necessary information to the <code>used_ring</code>.</li>
<li>If one or more requests have been processed, return <code>true</code> as the function's return value.</li>
</ol>
<p>The following diagrams illustrate the process when the guest-originated I/O request is a Read:</p>
<div align="center">
<img src="../03_figs/blk-device_read.svg", width="100%">
</div>
<p>And here's the process when the guest-originated I/O request is a Write:</p>
<div align="center">
<img src="../03_figs/blk-device_write.svg", width="100%">
</div>
<h3 id="verification-of-virtio-blk-operation"><a class="header" href="#verification-of-virtio-blk-operation">Verification of virtio-blk Operation</a></h3>
<p>Now, let's perform a practical verification to demonstrate the functionality. Instead of using <code>initrd.img</code>, we will use an Ubuntu rootfs image similar to Firecracker, allowing us to boot the Ubuntu OS directly. With the implementation of the <code>virtio-blk</code> BlockDevice, we can recognize the Ubuntu rootfs image as <code>/dev/vda</code> in the VM. To boot from this Ubuntu image, we need to specify <code>root=/dev/vda</code> in the VM's kernel cmdline.</p>
<pre><code># Run ToyVMM with kernel and rootfs (no initrd.img)
$ sudo -E cargo run -- boot_kernel -k vmlinux.bin -r ubuntu-18.04.ext4
...

# You can verify that the launched VM is ubuntu-based.
root@7e47bb8f2f0a:~# uname -r
4.14.174
root@7e47bb8f2f0a:~# cat /etc/os-release
NAME=&quot;Ubuntu&quot;
VERSION=&quot;18.04.1 LTS (Bionic Beaver)&quot;
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=&quot;Ubuntu 18.04.1 LTS&quot;
VERSION_ID=&quot;18.04&quot;
HOME_URL=&quot;https://www.ubuntu.com/&quot;
SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;
BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;
PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic

# And you can also find that this VM mount /dev/vda as rootfs.

root@7e47bb8f2f0a:~# lsblk
NAME MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
vda  254:0    0  384M  0 disk /

root@7e47bb8f2f0a:~# ls -lat /
total 36
drwxr-xr-x 12 root root   360 Aug 14 13:47 run
drwxr-xr-x 11 root root  2460 Aug 14 13:46 dev
dr-xr-xr-x 12 root root     0 Aug 14 13:46 sys
drwxrwxrwt  7 root root  1024 Aug 14 13:46 tmp
dr-xr-xr-x 57 root root     0 Aug 14 13:46 proc
drwxr-xr-x  2 root root  3072 Jul 20  2021 sbin
drwxr-xr-x  2 root root  1024 Dec 16  2020 home
drwxr-xr-x 48 root root  4096 Dec 16  2020 etc
drwxr-xr-x  2 root root  1024 Dec 16  2020 lib64
drwxr-xr-x  2 root root  5120 May 28  2020 bin
drwxr-xr-x 20 root root  1024 May 13  2020 .
drwxr-xr-x 20 root root  1024 May 13  2020 ..
drwxr-xr-x  2 root root  1024 May 13  2020 mnt
drwx------  4 root root  1024 Apr  7  2020 root
drwxr-xr-x  2 root root  1024 Apr  3  2019 srv
drwxr-xr-x  6 root root  1024 Apr  3  2019 var
drwxr-xr-x 10 root root  1024 Apr  3  2019 usr
drwxr-xr-x  9 root root  1024 Apr  3  2019 lib
drwx------  2 root root 12288 Apr  3  2019 lost+found
drwxr-xr-x  2 root root  1024 Aug 21  2018 opt
</code></pre>
<p>As mentioned above, it can be seen that the VM is running the Ubuntu-based OS passed as /dev/vda, and after logging in, it is confirmed that it is an Ubuntu-based OS, and the rootfs is correctly mounted as intended. Furthermore, unlike the previous initrd.img, which had volatile rootfs, in this case, the rootfs persisted as a DISK is used for booting the VM, allowing files created within the VM to be retained across VM reboots.</p>
<pre><code># Create a sample file (hello.txt) in the first VM boot and reboot.

root@7e47bb8f2f0a:~# echo &quot;HELLO UBUNTU&quot; &gt; ./hello.txt
root@7e47bb8f2f0a:~# cat hello.txt
HELLO UBUNTU
root@7e47bb8f2f0a:~# reboot -f
Rebooting.

# After the second boot, you can also find 'hello.txt'.  

Ubuntu 18.04.1 LTS 7e47bb8f2f0a ttyS0

7e47bb8f2f0a login: root
Password:
Last login: Mon Aug 14 13:57:27 UTC 2023 on ttyS0
Welcome to Ubuntu 18.04.1 LTS (GNU/Linux 4.14.174 x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

This system has been minimized by removing packages and content that are
not required on a system that users do not log into.

To restore this content, you can run the 'unminimize' command.
root@7e47bb8f2f0a:~# cat hello.txt
HELLO UBUNTU
</code></pre>
<p>With the implementation of both <code>virtio-net</code> and <code>virtio-blk</code> devices, you have successfully created a minimal VM with the necessary functionality.</p>
<h3 id="reference-3"><a class="header" href="#reference-3">Reference</a></h3>
<ul>
<li><a href="https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=virtio">OASIS</a></li>
<li><a href="https://syuu1228.github.io/howto_implement_hypervisor/">Creating a Hypervisor</a></li>
<li><a href="https://blog.bobuhiro11.net/2022/04-12-gokvm6.html">Self-Made VMM with virtio-blk Support</a></li>
<li><a href="https://wiki.osdev.org/Virtio#Block_Device_Packets">OSDev.org - Virtio#Block_Device_Packets</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
                
    </body>
</html>

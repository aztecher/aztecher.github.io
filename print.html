<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>toyvmm book</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="quickstart.html"><strong aria-hidden="true">2.</strong> QuickStart</a></li><li class="chapter-item expanded "><a href="01_running_tiny_code_in_vm.html"><strong aria-hidden="true">3.</strong> Running Tiny Code in VM</a></li><li class="chapter-item expanded "><a href="02_load_linux_kernel.html"><strong aria-hidden="true">4.</strong> Load Linux Kernel</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="02-1_overview_of_booting_linux.html"><strong aria-hidden="true">4.1.</strong> 02-1. Overview of Booting Linux</a></li><li class="chapter-item expanded "><a href="02-2_elf_binary_format_and_vmlinux_structure.html"><strong aria-hidden="true">4.2.</strong> 02-2. ELF binary format and vmlinux structure</a></li><li class="chapter-item expanded "><a href="02-3_loading_initrd.html"><strong aria-hidden="true">4.3.</strong> 02-3. Loading initrd</a></li><li class="chapter-item expanded "><a href="02-4_setup_registers_of_vcpu.html"><strong aria-hidden="true">4.4.</strong> 02-4. Setup registers of vcpu</a></li><li class="chapter-item expanded "><a href="02-5_serial_console_implementation.html"><strong aria-hidden="true">4.5.</strong> 02-5. Serial Console implementation</a></li><li class="chapter-item expanded "><a href="02-6_toyvmm_implementation.html"><strong aria-hidden="true">4.6.</strong> 02-6. ToyVMM implementation</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">toyvmm book</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<h2 id="what-is-toyvmm"><a class="header" href="#what-is-toyvmm">What is ToyVMM?</a></h2>
<p>ToyVMM is a project being developed for the purpose of learning virtualization technology.
ToyVMM aims to accomplish the following</p>
<p>Code-based understanding of KVM-based virtualization technologies
Learn about the modern virtualization technology stack by using libraries managed by rust-vmm
The rust-vmm libraries are also used as a base for well-known OSS such as firecracker and provides the functionality needed to create custom VMMs.</p>
<h2 id="disclaimer"><a class="header" href="#disclaimer">Disclaimer</a></h2>
<p>While every effort has been made to provide correct information in this publication, the authors do not necessarily guarantee that all information is accurate.
Therefore, the authors cannot be held responsible for the results of development, prototyping, or operation based on this information.
If you find any errors in the contents of this document, please correct or report them as PR or Issue.</p>
<h2 id="whats-next"><a class="header" href="#whats-next">What's Next?</a></h2>
<p>If you would like to try ToyVMM first, please refer to <a href="./quickstart.html">QuickStart</a>.
To learn more about KVM-based virtualization through ToyVMM, please refer to <a href="./01_running_tiny_code_in_vm.html">01. Running Tiny Code in VM</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quickstart"><a class="header" href="#quickstart">QuickStart</a></h1>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>Since this project is based on KVM, it's desiable to have KVM setup in the development environment.
In addition, Docker installation is required since the code testing and execution is basically intended to be performed inside a Docker container.</p>
<h2 id="run-toyvmm"><a class="header" href="#run-toyvmm">Run ToyVMM!</a></h2>
<p>Running <code>make run</code> executes cargo run on the development environment, and running <code>make run_container</code> executes it inside the container. Currently running code equivalent to the example of LWN article 「<a href="https://lwn.net/Articles/658511/">Using the KVM API</a>」and similar to <a href="https://docs.rs/kvm-ioctls/latest/kvm_ioctls/#example---running-a-vm-on-x86_64">kvm_ioctls' example</a></p>
<pre><code class="language-bash">$ make run
sudo -E cargo run
   Compiling bitflags v1.3.2
   Compiling libc v0.2.121
   Compiling vmm-sys-util v0.9.0
   Compiling vm-memory v0.7.0
   Compiling kvm-bindings v0.5.0
   Compiling kvm-ioctls v0.11.0
   Compiling toyvmm v0.1.0 (/home/mmichish/Documents/rust/toyvmm)
    Finished dev [unoptimized + debuginfo] target(s) in 5.43s
     Running `target/debug/toyvmm`
Recieved I/O out exit. Address: 0x3f8, Data(hex): 0x34
Recieved I/O out exit. Address: 0x3f8, Data(hex): 0xa
sudo rm -rf target
</code></pre>
<h2 id="whats-next-1"><a class="header" href="#whats-next-1">What's next?</a></h2>
<p>Check <a href="./01_running_tiny_code_in_vm.html">01. Running Tiny Code in VM</a> for a detailed explanation of the ToyVMM implementation!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="01-running-tiny-code-in-vm"><a class="header" href="#01-running-tiny-code-in-vm">01. Running Tiny Code in VM</a></h1>
<p>Tiny code execution is now based on <a href="./quickstart.html">QuickStart</a> content, so please check it first.</p>
<h3 id="deepdive-toyvmm-instruction-and-how-to-run-tiny-code-in-vm"><a class="header" href="#deepdive-toyvmm-instruction-and-how-to-run-tiny-code-in-vm">DeepDive ToyVMM instruction and how to run tiny code in VM</a></h3>
<p>This <code>main</code> function is a program that starts a VM using the KVM mechanism and executes the following small code inside the VM</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>code = &amp;[
	0xba, 0xf8, 0x03, /* mov $0x3f8, %dx */
	0x00, 0xd8,       /* add %bl, %al */
	0x04, b'0',       /* add $'0', %al */
	0xee,             /* out %al, (%dx) */
	0xb0, '\n',       /* mov $'\n', %al */
	0xee,             /* out %al, (%dx) */
	0xf4,             /* hlt */
];
<span class="boring">}
</span></code></pre></pre>
<p>This code perform several register operations, but the initial state of the CPU regisers for this VM is set as follows.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    regs.rip = 0x1000;
    regs.rax = 2;
    regs.rbx = 2;
    regs.rflags = 0x2;
    vcpu.set_sregs(&amp;sregs).unwrap();
    vcpu.set_regs(&amp;regs).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>This will output the result of calculations (2 + 2) inside the VM from the IO Port, followed by a newline code as well.<br />
As you can see the result of running ToyVMM, hex value 0x34 (= '4') and 0xa (= New Line) are catched from I/O port</p>
<h3 id="hows-work-above-code-with-rust-vmm-libraries"><a class="header" href="#hows-work-above-code-with-rust-vmm-libraries">How's work above code with rust-vmm libraries</a></h3>
<p>Now, the following crate provided by rust-vmm is used to run these codes.</p>
<pre><code class="language-bash"># Please see Cargo.toml
kvm-bindings
kvm-ioctls
vmm-sys-util
vm-memory
</code></pre>
<p>I omit to describe about <a href="https://github.com/rust-vmm/vmm-sys-util">vmm-sys-util</a> because it is only used to create temporary files at this point, so there is nothing special to mention about it.</p>
<p>I will go through the code in order and describe how each crate is related to that.<br />
In this explanation, we will focus primary on the perspective of <strong>what ioctl is performed as a result of a function call</strong> (This is because the interface to manipulate KVM from the user space relies on the iocl system call)<br />
Also, please note that explanations of unimportant variables may be omitted.<br />
It should be noted that what is described here is not only the ToyVMM implementation, but also the firecracker implementation in a similaer form.</p>
<p>First, we need to open <code>/dev/kvm</code> and acquire the file descriptor. This can be done by <code>Kvm::new()</code> of <a href="https://github.com/rust-vmm/kvm-ioctls"><code>kvm_ioctls</code></a> crate. Following this process, the <a href="https://github.com/rust-vmm/kvm-ioctls/blob/d12f5776be0937a14da1ad8f9736653e8a2ad5ba/src/ioctls/system.rs#L69-L78"><code>Kvm::open_with_cloexec</code></a> function issues an <code>open</code> system call as follows, returns a file descriptor as <code>Kvm</code> structure</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let ret = unsafe { open(&quot;/dev/kvm\0&quot;.as_ptr() as *const c_char, open_flags) };
<span class="boring">}
</span></code></pre></pre>
<p>The result obtained from above is used to call the method <code>create_vm</code>, which results in the following <code>ioctl</code> being issued</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>vmfd = ioctl(kvmfd, KVM_CREATE_VM, 0)

where
  vmfd: from /dev/kvm
<span class="boring">}
</span></code></pre></pre>
<p>Please keep in mind that the file descriptor returned from above function will be used later when preparing the CPU.<br />
Anyway, we finish to crete a VM but it has no memory, cpu.</p>
<p>Now, the next step is to prepare memory!
In <code>kvm_ioctls</code>'s example, memory is prepared as follows</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// First, setup Guest Memory using mmap
let load_addr: *mut u8 = unsafe {
    libc::mmap(
        null_mut(),
        mem_size, // 0x4000
        libc::PROT_READ | libc::PROT_WRITE,
        libc::MAP_ANONYMOUS | libc::MAP_SHARED | libc::MAP_NORESERVE,
        -1,
        0,
    ) as *mut u8
};

// Second, setup kvm_userspace_memory_region sructure using above memory
// kvm_userspace_memory_region is defined in kvm_bindings crate
let mem_region = kvm_userspace_memory_region {
    slot,
    guest_phys_addr: guest_addr,  // 0x1000
    memory_size: mem_size as u64, // 0x4000
    userspace_addr: load_addr as u64,
    flags: KVM_MEM_LOG_DIRTY_PAGES,
};
unsafe { vm.set_user_memory_region(mem_region).unwrap() };

// retrieve slice from pointer and length (slice::form_raw_parts_mut)
//   &gt; https://doc.rust-lang.org/beta/std/slice/fn.from_raw_parts_mut.html
// and write asm_code into this slice (&amp;[u8], &amp;mut [u8], Vec&lt;u8&gt; impmenent the Write trait!)
//   &gt; https://doc.rust-lang.org/std/primitive.slice.html#impl-Write
unsafe {
    let mut slice = slice::from_raw_parts_mut(load_addr, mem_size);
    slice.write(&amp;asm_code).unwrap();
}
<span class="boring">}
</span></code></pre></pre>
<p>Check <code>set_user_memory_region</code>. This function will issue the following ioctl as a result, attach the memory to VM</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ioctl(vmfd, KVM_SET_USER_MEMORY_REGION, &amp;mem_region)
<span class="boring">}
</span></code></pre></pre>
<p>ToyVMM, on the other hand, provides a utility functions for memory preparation.<br />
This difference is due to the fact that ToyVMM's implementation is similaer to firecracker's, but they are essentially doing the same thing.</p>
<p>Let's look at the whole implementation first</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// The following `create_region` functions operate based on file descriptor, so first, create a temporary file and write asm_code to it.
let mut file = TempFile::new().unwrap().into_file();
assert_eq!(unsafe { libc::ftruncate(file.as_raw_fd(), 4096 * 10) }, 0);
let code: &amp;[u8] = &amp;[
    0xba, 0xf8, 0x03, /* mov $0x3f8, %dx */
    0x00, 0xd8,       /* add %bl, %al */
    0x04, b'0',       /* add $'0', %al */
    0xee,             /* out %al, %dx */
    0xb0, b'\n',      /* mov $'\n', %al */
    0xee,             /* out %al, %dx */
    0xf4,             /* hlt */
];
file.write_all(code).expect(&quot;Failed to write code to tempfile&quot;);

// create_region funcion create GuestRegion (The details are described in the following)
let mut mmap_regions = Vec::with_capacity(1);
let region = create_region(
    Some(FileOffset::new(file, 0)),
    0x1000,
    libc::PROT_READ | libc::PROT_WRITE,
    libc::MAP_NORESERVE | libc::MAP_PRIVATE,
    false,
).unwrap();

// Vec named 'mmap_regions' contains the entry of GuestRegionMmap
mmap_regions.push(GuestRegionMmap::new(region, GuestAddress(0x1000)).unwrap());

// guest_memory represents as the vec of GuestRegion
let guest_memory = GuestMemoryMmap::from_regions(mmap_regions).unwrap();
let track_dirty_page = false;

// setup Guest Memory
vm.memory_init(&amp;guest_memory, kvm.get_nr_memslots(), track_dirty_page).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>The <code>create_vm</code> consequently performs a mmap in the following way and returns a part of the structure (GuestMmapRegion) representing the GuestMemory</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn create_region(
    maybe_file_offset: Option&lt;FileOffset&gt;,
    size: usize,
    prot: i32,
    flags: i32,
    track_dirty_pages: bool,
) -&gt; Result&lt;GuestMmapRegion, MmapRegionError&gt; {

...

let region_addr = unsafe {
    libc::mmap(
        region_start_addr as *mut libc::c_void,
        size,
        prot,
        flags | libc::MAP_FIXED,
        fd,
        offset as libc::off_t,
    )
};
let bitmap = match track_dirty_pages {
    true =&gt; Some(AtomicBitmap::with_len(size)),
    false =&gt; None,
};
unsafe {
    MmapRegionBuilder::new_with_bitmap(size, bitmap)
        .with_raw_mmap_pointer(region_addr as *mut u8)
        .with_mmap_prot(prot)
        .with_mmap_flags(flags)
        .build()
}
<span class="boring">}
</span></code></pre></pre>
<p>Let's check the structure about Memory here.
In <code>src/kvm/memory.rs</code>, the following Memory structure is defined based on <a href="https://github.com/rust-vmm/vm-memory">vm-memory</a> crate</p>
<pre><code>pub type GuestMemoryMmap = vm_memory::GuestMemoryMmap&lt;Option&lt;AtomicBitmap&gt;&gt;;
pub type GuestRegionMmap = vm_memory::GuestRegionMmap&lt;Option&lt;AtomicBitmap&gt;&gt;;
pub type GuestMmapRegion = vm_memory::MmapRegion&lt;Option&lt;AtomicBitmap&gt;&gt;;
</code></pre>
<p>The <code>MmapRegionBuilder</code> is also defined in the <code>vm-memory</code> crate, and this <code>build</code> method creates the <code>MmapRegion</code>.</p>
<p>This time, since we have performed the mmap myself in advance and passed that address to <code>with_raw_mmap_pointer</code>, <a href="https://github.com/rust-vmm/vm-memory/blob/f6ef1b619b126324830c87a3554b7082a0490ae0/src/mmap_unix.rs#L145-L147">use that area to initialize</a>. Otherwise, <a href="https://github.com/rust-vmm/vm-memory/blob/f6ef1b619b126324830c87a3554b7082a0490ae0/src/mmap_unix.rs#L164-L173">mmap is performed in the <code>build</code> method</a>. In any case, this <code>build</code> method will get the <code>MmapRegion</code> structure, but defines a synonym as described above, which is returned as the <code>GuestMmapRegion</code>. By calling the <code>create_region</code> function once, you can allocate and obtain one region of GuestMemory based on the information(<code>size</code>, <code>flags</code>, ...etc) specified in the argument.</p>
<p>The region allocated here is only mmapped from the virtual address space of the VMM process, and no further information is available. To use this area as Guest Memory, a <code>GuestRegionMmap</code> structure is created from this area. This is simple, specify the corresponding <code>GuestAddress</code> for this region and initialize <code>GuestRegionMmap</code> with a tuple of mmapped area and GuestAddress. In following code, the initialized <code>GuestRegionMmap</code> is pushed to Vec for subsequent processing.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>map_regions.push(GuestRegionMmap::new(region, GuestAddress(0x1000)).unwrap());
<span class="boring">}
</span></code></pre></pre>
<p>Now, the <code>mmap_regions: Vec&lt;GuestRegionMmap&gt;</code> created as above represents the entire memory of the Guest VM, and each region that makes up the guest memory holds information on the area allocated by the VMM for the region and the top address of the Guest side.
The <code>GuestMemoryMmap</code> structure representing the Guest Memory is initialized from this Vec information and set to VM by the <code>memory_init</code> method.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let guest_memory = GuestMemoryMmap::from_regions(mmap_regions).unwrap();
vm.memory_init(&amp;guest_memory, kvm.get_nr_memslots(), track_dirty_page).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>Next, let's check the operation of this <code>memory_init</code>. This calls <code>set_kvm_memory_regions</code> and the actual process is described there.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn set_kvm_memory_regions(
    &amp;self,
    guest_mem: &amp;GuestMemoryMmap,
    track_dirty_pages: bool,
    ) -&gt; Result&lt;()&gt; {
    let mut flags = 0u32;
    if track_dirty_pages {
        flags |= KVM_MEM_LOG_DIRTY_PAGES;
    }
    guest_mem
        .iter()
        .enumerate()
        .try_for_each(|(index, region)| {
            let memory_region = kvm_userspace_memory_region {
                slot: index as u32,
                guest_phys_addr: region.start_addr().raw_value() as u64,
                memory_size: region.len() as u64,
                userspace_addr: guest_mem.get_host_address(region.start_addr()).unwrap() as u64,
                flags,
            };
            unsafe { self.fd.set_user_memory_region(memory_region) }
        })
    .map_err(Error::SetUserMemoryRegion)?;
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>Here we can see that <code>set_user_memory_region</code> is called using the necessary information while iterating the region.
In other words, it is processing the same as the example code except that there may be more than one region.</p>
<p>Now that we've gone through the explanation of memory preparation, let's take a look at the <code>vm-memory</code> crate!
The information presented here is only the minimum required, so please refer to <a href="https://github.com/rust-vmm/vm-memory/blob/main/DESIGN.md">Design</a> or other sources for more details.
This will also be related to the above iteration, where we were able to call methods such as <code>sart_addr()</code> and <code>len()</code> to construct the necessary information for <code>set_user_memory_region</code>.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>GuestAddress (struct) : Represent Guest Physicall Address (GPA)
FileOffset(struct) : Represents the start point within a 'File' that backs a 'GuestMemoryRegion'

GuestMemoryRegion(trait) : Represents a continuous region of guest physical memory / trait
GuestMemory(trait) : Represents a container for a immutable collection of GuestMemoryRegion object / trait

MmapRegion(struct) : Helper structure for working with mmaped memory regions
GuestRegionMmap(struct &amp; implement GuestMemoryRegion trait) : Represents a continuous region of the guest's physical memory that is backed by a mapping in the virtual address space of the calling process
GuestMemoryMmap(struct &amp; implement GuestMemory trait) : Represents the entire physical memory of the guest by tracking all its memory regions
<span class="boring">}
</span></code></pre></pre>
<p><a href="https://github.com/rust-vmm/vm-memory/blob/f6ef1b619b126324830c87a3554b7082a0490ae0/src/mmap.rs#L436">Since <code>GuestRegionMmap</code> implements the <code>GuestMemoryRegion</code> trait</a>, there are implementations of functions such as <code>start_addr()</code> and <code>len()</code>, which were used in the above interation.
The following figure briefly summarizes the relationship between these structures</p>
<img src="./01_figs/vm-memory_overview.svg" width="100%">
<p>As you can see, what is being done is essentially the same.</p>
<p>The final step is prepareing vCPU (vCPU is a CPU to be attached to a virtual machine).<br />
Currently, a VM has been created and memory containing instructions has been inserted, but these is no CPU, so the instructions can't be executed. Therefore, let's create a vCPU, associate it with the VM, and execute the instruction by running the vCPU!</p>
<p>Using the file descriptor obtained during VM creaion (<code>vmfd</code>), the resulting <code>ioctl</code> will be issued as follows.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>vcpufd = ioctl(vmfd, KVM_CREATE_VCPU, 0)
<span class="boring">}
</span></code></pre></pre>
<p>The <code>create_vm</code> method that was just issued to obtain the <code>vmfd</code> is designed to return a <code>kvm_ioctls::VmFd</code> strucure as a result, and by execuing the <code>create_vcpu</code> method, which is a method of this structure, the above ioctl is consequently issued and returns the result as a <code>kvm_ioctls::VcpuFd</code> structure.</p>
<p><code>VcpuFd</code> provides utilities for getting and setting various CPU states.<br />
For example, if you want o get/set a register set from the vCPU, you would normally issue the following <code>ioctl</code></p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ioctl(vcpufd, KVM_GET_SREGS, &amp;sregs);
ioctl(vcpufd, KVM_SET_SREGS, &amp;sregs);
<span class="boring">}
</span></code></pre></pre>
<p>For these, the following methods are available in <code>kvm_ioctls::VcpuFd</code></p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>get_sregs(&amp;self) -&gt; Result&lt;kvm_sregs&gt;
set_sregs(&amp;self, sregs: &amp;kvm_sregs) -&gt; Result&lt;()&gt;
<span class="boring">}
</span></code></pre></pre>
<p><code>VcpuFd</code> also provids a method called <code>run</code>, which issues the following insructions to actually run the vCPU.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ioctl(vcpufd, KVM_RUN, NULL)
<span class="boring">}
</span></code></pre></pre>
<p>and then, we can aquire return values that has the type <code>Result&lt;VcpuExit&gt;</code> resulting this method.</p>
<p>When running vCPU, exit occurs for various reasons. This is an instruction that the CPU cannot handle, and the OS usually tries to deal with it by invoking the corresponding handler.<br />
If this type of exit comes back from the VM's vCPU, as in the case, it will be necessary to write the appropriate code to handle the situation.<br />
<code>VcpuExit</code> is defined in <code>kvm_ioctls::VcpuExit</code> as enum.<br />
When Exit are occurred on several reasons in running vCPU, the exit reasons that are defined in kvm.h in linux kernel are wrapped to <code>VcpuExit</code>.<br />
Therefore, it is sufficient to write a process that pattern matches this result and appropriately handles the error to be handled.</p>
<p>Now, there is a instruction that execute outputting values through I/O port and this will occur the <code>KVM_EXIT_IO_OUT</code>.<br />
<code>VcpuExit</code> wrap this exit reason as <code>IoOut</code>.</p>
<p>Originally (in C programm as example), we require to calculate appropriate offset to get output data from I/O port, but now, this process are implemented in <code>run</code> method and returned as VcpuExit that contains necessary values.<br />
So, we don't have to write these unsafe code (pointer offset calculation) and handle these exit as you will.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>loop {
    match vcpu.run().expect(&quot;vcpu run failed&quot;) {
        kvm_ioctls::VcpuExit::IoOut(addr, data) =&gt; {
            println!(
                &quot;Recieved I/O out exit. \
                Address: {:#x}, Data(hex): {:#x}&quot;,
                addr, data[0],
            );
        },
        kvm_ioctls::VcpuExit::Hlt =&gt; {
            break;
        }
        exit =&gt; panic!(&quot;unexpected exit reason: {:?}&quot;, exit),
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>In above, only handle <code>KVM_EXIT_IO_OUT</code> and <code>KVM_EXIT_HLT</code>, and the others will be processed as panic. (Although all exits should be handled, I want to focus on the description of KVM API example and keep it simply)</p>
<p>Since we are here, let's take a look at the processing of the <code>run</code> method in some detail.<br />
Let's check the processing of <code>KVM_EXIT_IO_OUT</code>.</p>
<p>If you look at the <a href="https://lwn.net/Articles/658511/">LWN article</a>, you will see that it calculates the offset and outputs the necessary information in the following way.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>case KVM_EXIT_IO:
    if (run-&gt;io.direction == KVM_EXIT_IO_OUT &amp;&amp;
	    run-&gt;io.size == 1 &amp;&amp;
	    run-&gt;io.port == 0x3f8 &amp;&amp;
	    run-&gt;io.count == 1)
	putchar(*(((char *)run) + run-&gt;io.data_offset));
    else
	errx(1, &quot;unhandled KVM_EXIT_IO&quot;);
    break;
<span class="boring">}
</span></code></pre></pre>
<p>On the other hand, <code>run</code> method implemented in <code>kvm_ioctl::VcpuFd</code> is like bellow</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>...
let run = self.kvm_run_ptr.as_mut_ref();
match run.exit_reason {
    ...
    KVM_EXIT_IO =&gt; {
        let run_start = run as *mut kvm_run as *mut u8;
        // Safe because the exit_reason (which comes from the kernel) told us which
        // union field to use.
        let io = unsafe { run.__bindgen_anon_1.io };
        let port = io.port;
        let data_size = io.count as usize * io.size as usize;
        // The data_offset is defined by the kernel to be some number of bytes into the
        // kvm_run stucture, which we have fully mmap'd.
        let data_ptr = unsafe { run_start.offset(io.data_offset as isize) };
        // The slice's lifetime is limited to the lifetime of this vCPU, which is equal
        // to the mmap of the `kvm_run` struct that this is slicing from.
        let data_slice = unsafe {
            std::slice::from_raw_parts_mut::&lt;u8&gt;(data_ptr as *mut u8, data_size)
        };
        match u32::from(io.direction) {
            KVM_EXIT_IO_IN =&gt; Ok(VcpuExit::IoIn(port, data_slice)),
            KVM_EXIT_IO_OUT =&gt; Ok(VcpuExit::IoOut(port, data_slice)),
            _ =&gt; Err(errno::Error::new(EINVAL)),
        }
    }
		...
<span class="boring">}
</span></code></pre></pre>
<p>Let me explain a little. The <code>kvm_run</code> is provided by the <a href="https://github.com/rust-vmm/kvm-bindings"><code>kvm-bindings</code></a> crate, which is a structure automatically generated from a header file using <a href="https://github.com/rust-lang/rust-bindgen"><code>bindgen</code></a>, so it is a structure like the linux kernel's <code>kvm_run</code> converted directory to Rust.<br />
First, <code>kvm_run</code> is obtained in the form of a pointer, a method of obtaining a pointer often used in Rust.<br />
This correspoinds to the first address of the <code>kvm_run</code> structure which is bound to <code>run_start</code> variable.<br />
And the information corresponding to <code>run-&gt;io(.member)</code> can be obtained from <code>run.__bindgen_anon_1.io</code>, although it is a bit tricky. The field named <code>__bindgen_anon_1</code> is the effect of automatic generation by <code>bindgen</code>.<br />
The data we want is at the first address of <code>kvm_run</code> plus <code>io.data_offset</code>. This process is performed in <code>run_start.offset(io.data_offset as isize)</code>. And the data size can be calculated from <code>io-&gt;size</code> and <code>io-&gt;count</code> (in the LWN example, it is 1byte, so it's taken directory from the offset by putchar). This part is calculated and stored in the value <code>data_size</code>, and <code>std::slice::from_raw_parts_mut</code> actually retrieves the data using this size.<br />
Finally, checking <code>io.direction</code>, we change the wrap type for <code>KVM_EXIT_IO_IN</code> or <code>KVM_EXIT_IO_OUT</code> respectively, and return the descired information such as <code>port</code> and <code>data_slice</code> together.</p>
<p>As can be seen from the above, what is being done is clear.<br />
However, it still contains many unsafe operations because it involves pointer manipuration.<br />
We can see that by using these libraries, we are able to implement VMM on a stable implementation.</p>
<p>Well, it's ben a long time comming, but let's take a look back at the rust-vmm crates we're using again.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>kvm-bindings : Library that includes structures automatically generated from kvm.h by bindgen.
kvm-ioctls : Library that hides ioctl and unsafe processes related to kvm operations and provides user-friendly sructures, functions and methods.  
vm-memory : Library that provides structures and operations to the Memory
<span class="boring">}
</span></code></pre></pre>
<p>This knowledge will come up again and again in future discussion and is basic and important.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="load-linux-kernel"><a class="header" href="#load-linux-kernel">Load Linux Kernel</a></h1>
<p><strong>chapter2 is currently available only in Japanese, but will soon be translated into English ;)</strong></p>
<p>このセクションではVMMのファーストステップとしてGuest VMを起動するための実装について触れることとする。<br />
VMMとしては必要最低限の機能である一方、Linux Kernelの起動にあたってさまざまな知識を要求される内容でもある。</p>
<p>このセクションではGuest VMを起動するための最低限の事項について説明し、ToyVMMでどのように実装しているかについても触れていく
そのため、いくつかの細かいチャプターに分割しトピックごとに説明をしていくことにしよう</p>
<p>トピックとしては次のようになっている。</p>
<ul>
<li><a href="./02-1_overview_of_booting_linux.html">02-1. Overview of Booting Linux</a></li>
<li><a href="./02-2_elf_binary_format_and_vmlinux_structure.html">02-2. ELF binary format and vmlinux structure</a></li>
<li><a href="./02-3_loading_initrd.html">02-3. Loading initrd</a></li>
<li><a href="./02-4_setup_registers_of_vcpu.html">02-4. Setup registers of vcpu</a></li>
<li><a href="./02-5_serial_console_implementation.html">02-5. Serial Console implementation</a></li>
<li><a href="./02-6_toyvmm_implementation.html">02-6. ToyVMM implementation</a></li>
</ul>
<p>また、本資料は以下のコミットナンバーをベースとしている</p>
<ul>
<li>ToyVMM : <code>27fdf196dfb31938f24785ca64e7233a6dc8fceb</code></li>
<li>Firecracker : <code>4bf121fc032cc2d94a20a3625f2af3918545154a</code></li>
</ul>
<p>本資料をToyVMMのコードを参照しながら確認する場合は参考にされたい。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview-of-booting-linux"><a class="header" href="#overview-of-booting-linux">Overview of Booting Linux</a></h1>
<h3 id="一般的なブートの仕組み"><a class="header" href="#一般的なブートの仕組み">一般的なブートの仕組み</a></h3>
<p>Linuxでは大まかに以下のようにプログラムが順番に動作していくことでOSが起動していく</p>
<ol>
<li>BIOS</li>
<li>ブートローダ (GRUB)</li>
<li>Linuxカーネル（vmlinuz）</li>
<li>init</li>
</ol>
<p>BIOSはマザーボード上のROMにプログラムが格納されている。<br />
我々が電源を投入すると、CPUはこの領域がマップされているアドレスから処理を実行するようになっている。<br />
BIOSはハードウェアの検出、初期化を実行し、その後OSのブートドライブ（HHD/SSD、USBフラッシュメモリなど）を探索する。<br />
この時、ブートドライブはMBR、もしくはGPTの形式でフォーマットされている必要があり、これらのフォーマットとBIOSの関係はそれぞれ以下のように対応する</p>
<table><thead><tr><th>BIOS \ DISK Format</th><th>MBR</th><th>GPT</th></tr></thead><tbody>
<tr><td>Legacy BIOS</td><td>◯</td><td>-</td></tr>
<tr><td>UEFI</td><td>◯ *</td><td>◯</td></tr>
</tbody></table>
<p>* UEFIはLegacy Boot Modeのサポートがあるため、MBRをサポートしている</p>
<p>以降ではMBRを利用する場合のOS探索について説明する<br />
詳しい説明に入る前に、MBRの構造について以下の図を参照しつつ簡単に整理しておく。
以降で説明するMBRの構造はHDD／SSDやUSBフラッシュメモリなどの場合を想定し記載しており、後述するPartition Entryの存在を暗黙に仮定しているので注意されたい。
なお、本資料では<a href="https://en.wikipedia.org/wiki/Master_boot_record">Wikipedia</a>で記載されている名称を引用しているので注意されたい。</p>
<p>MBRはブートドライブの先頭セクタに512byte書き込まれており、大きく分けて3つの領域が存在している。</p>
<ol>
<li>Bootstrap code are (446 byte)</li>
<li>Partition Entry (64 byte = 16 byte * 4)</li>
<li>Boot Signature (2 byte)</li>
</ol>
<p>MBRについてここでは詳細に説明はしないが、Boot code areaにはOSをブートする機械語のプログラム（Boot Loader）が、Partition Entryにはそのディスクの論理パーティション情報が格納されている。<br />
（余談だが、Boot code areaは446byteしかないため、Boot Loaderを直接実装するのではなく、Boot Loaderは別の場所に格納しておき、そのブートローダをメモリに読み込むために最小限のプログラムを配置することもあるようだ）<br />
ここで重要なのは3つ目の「Boot Signature」であり、ここに格納されている2byteの値は、当該ドライブがブートドライブかどうかを担保するために利用される。<br />
具体的には、BIOSがOSのブートドライブを探索する時、先頭1セクタ（512byte）を読み込み、最後の2byte（Boot Signature）がブートドライブであることを示すシグネチャ（<code>0x55 0xaa</code>）であることを確認する。
このシグネチャが亜確認できた場合、当該ディスクをブートディスクと判定し、先頭1セクタ(512byte)をメインメモリの0x7c00から0x7fffに読み込んで、0x7c00からプログラムを実行していく。</p>
<p>さて、これまでの議論の簡単な裏付けとして、手元のマシンでBoot Signatureを確認してみる。<br />
仮想マシンなので、ブートディスクは<code>vda</code>と表示されている。通常のマシンなら<code>sda</code>などだろう。
この<code>vda</code>から先頭1セクタ分の内容をファイルに書き出し、<code>hexdump</code>で510byteオフセットした位置から2byte確認してみると、確かに<code>0x55</code> <code>0xaa</code>の値が確認できる。</p>
<pre><code class="language-bash">$ lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0     11:0    1    2M  0 rom
vda    252:0    0  300G  0 disk
├─vda1 252:1    0    1M  0 part
└─vda2 252:2    0  300G  0 part /

$ sudo dd if=/dev/vda of=mbr bs=512 count=1
1+0 records in
1+0 records out
512 bytes (512 B) copied, 0.000214802 s, 2.4 MB/s

$ hexdump -s 510 -C mbr
000001fe  55 aa                                             |U.|
00000200
</code></pre>
<p>話を戻すと、BIOSによってMBRの情報を元にブートディスク上に格納されていたブートローダがメモリ上に展開され実行されていくことになる。<br />
ブートローダはカーネルとinitramfsをDISKからメモリに読み込み、カーネル起動する役目を持ったプログラムであり、近年では一般的にGRUBが利用されることが多い。<br />
ブートローダの詳細の処理内容についてもここでは省略とする。<br />
重要な点としては、ブートローダはDISK上に格納されたカーネルなどを読み込む必要があるという点である。
これを達成する素朴な方法は我々がDISK上のカーネルファイルの位置をブートローダに対して教えることであろう。<br />
しかしgrub.cfgの内容を見てみると、カーネルやinitrdの位置をファイルパスの形でしか指定していないことを確認できるだろう。<br />
これはブートローダがファイルシステムを解釈する能力を有している必要があることを意味する。<br />
実際に、Boot Loaderいくつかのファイルシステムを解釈でき、ファイルシステム上のディレクトリパス情報からカーネルを探し出すことができる。
ただし、当然ながらBoot Loaderは特定のファイルシステムのみのサポートに留まるため、それ以外のフォーマットのものを解釈することはできないので注意されたい。
ブートローダによってgrub.cfgで指定されたカーネルとRAMディスクをメモリ上にロードし、カーネルの先頭アドレスにジャンプすることで、処理をカーネルへと引き渡し自身の処理を終える</p>
<p>カーネルの処理の話に入る前に、カーネルファイルについて少し整理しておく。
カーネルファイルは一般に<code>vmlinuz*</code>という名前がついているファイルである
我々にとって馴染みのあるカーネルファイルは<code>/boot/vmlinuz-*.img</code>と思われるが、このファイルは<code>bzImage</code>形式のファイルである。これは<code>file</code>コマンドで簡単に確認することができる。<br />
この<code>bzImage</code>はカーネル本体を含む圧縮バイナリファイルの他に、低レベルの初期化を行うためのファイルなどいくつかのファイルが含まれる形式になっている。
この<code>bzImage</code>を適切に解凍することでカーネルの実行バイナリを手に入れることもできる。
本資料では<code>bzImage</code>形式のカーネルを<code>vmlnuz</code>、実行バイナリ形式のカーネルを<code>vmlinux.bin</code>と表記する。</p>
<p>さてブートローダから<code>vmlinuz</code>に処理が引き渡されると<code>vmlinuz</code>は低レベルの初期化処理を実施後、カーネル本体を解凍、メモリにロードし、カーネルのエントリールーチンに処理を移す。
カーネルは全ての初期化処理を終えると、<code>tmpfs</code>ファイルシステムを作成し、ブートローダがRAM上に配置した<code>initramfs</code>をそこに展開し、ディレクトリルートにある<code>init</code>スクリプトを起動する。
この<code>init</code>スクリプトはDISK上に格納されている本命のファイルシステムをマウントするために必要な準備を整え、本命のファイルシステムやその他に重要なファイルシステムをマウントする。この時<code>initramfs</code>にはいくつかのデバイスドライバなども含まれているため、多様なフォーマットのルートファイルシステムをマウントすることが可能である。
さらにこれが完了すると、ルートを本命のルートファイルシステムに切り替え、そこに格納されている<code>/sbin/init</code> バイナリを起動する。</p>
<p><code>/sbin/init</code>はシステムで最初に起動されるプロセス（PID=1が付与されるプロセス）であり、他のプロセスを起動させる役割を持っている全てのプロセスの親となるものである。
initにはさまざまな実装（<code>SysVinit</code>, <code>Upstart</code>）があるが、最近のCentOSやUbuntuなどで利用されているのは<code>Systemd</code>である。
initの最終的な責務は、システムの更なる準備とブートプロセスが終わった時点で必要なサービスが実行されておりユーザがログイン可能な状態まで持っていくことである。</p>
<p>以上が、非常に大雑把ではあるが電源投入からOSが起動するまでの流れである。</p>
<h3 id="initrdとinitramfs"><a class="header" href="#initrdとinitramfs">initrdとinitramfs</a></h3>
<p>上記に記載したLinux起動処理の中に、メモリ上に展開するファイルシステムである<code>initramfs</code>を紹介したが、我々がよく目にするのは<code>/boot/initrd.img</code>であろうと思う。ここでは<code>initrd</code>と<code>initramfs</code>との違いについて説明する
<code>initrd</code>は「initial RAM <strong>disk</strong>」、<code>initramfs</code>「initial RAM <strong>File System</strong>」であり両者は別物であるが、提供したい機能は同じで「本命のルートファイルシステムのマウントに必要なコマンド、ライブラリ、モジュール」を提供し、本命のルートファイルシステム上に存在する<code>/sbin/init</code>スクリプトを起動することである。<br />
もともと本来起動したいシステムは何かしらの記憶装置に書き込まれているが、これを読み込むには適切なデバイスドライバの存在と、これをマウントするファイルシステムが存在していないといけないという問題がある。<br />
<code>initrd</code>/<code>initramfs</code>は両方ともこの問題を解決する。</p>
<p><code>initrd</code>と<code>initramfs</code>は上記の機能を提供するための<strong>方式</strong>が異なっており、名前の通りであるが<code>initrd</code>はブロックデバイス、<code>initramfs</code>は（<code>tmpfs</code>をもとにした）RAM filesystemの方式になっている。
従来は<code>initrd</code>を利用していたが、Kernel 2.6以降で<code>initramfs</code>が利用できるようになっており、現在はこちらの方式を利用することの方が一般的と思われる。
<code>initrd</code>から<code>initramfs</code>に移りわってきたのにはもちろん、<code>initrd</code>には問題があり、<code>initramfs</code>はそれの解決が測られたからである。
<code>initrd</code>には概ね以下のような問題が存在していた</p>
<ol>
<li>RAM diskはRAM上に擬似的なブロックデバイスを作成し、これをあたかも二次記憶のように取り扱う仕組みであるため、通常のブロックデバイスと同様にメモリキャッシュ機構が働いてしまうために不必要にキャッシュメモリを消費する。さらにはページングのような機構が働いてしまうことで一層メモリを逼迫してしまう。</li>
<li>RAM diskはそのデータをフォーマットし解釈するためのext2のようなファイルシステムドライバーが必要である。</li>
<li>RAM diskのブロックデバイスは固定サイズになるため、あまりに小さいと必要なスクリプトを全て収めることができず、大きすぎると無駄にメモリを利用する</li>
</ol>
<p>これを解決するために考案され、現在のデフォルトになっているのが<code>initramfs</code>である。<br />
<code>initramfs</code>はサイズを柔軟に設定できる軽量なメモリ内ファイルシステムである<code>tmpfs</code>をベースとして作られたfilesystemである。<br />
当然これはブロックデバイスではないので、キャッシュやページングでメモリを汚すこともなく、ブロックデバイスに対するファイルシステムドライバも不要で、さらに固定長という問題もうまく解決している。</p>
<p><code>initrd</code>/<code>initramfs</code>いずれの方式にせよ、その中に格納されているツールを利用して本命のルートファイルシステムをマウントしそちらにルートを切り替えた上で、そのファイルシステム上に存在しているスタートアップスクリプトである<code>/sbin/init</code>を起動する。</p>
<h4 id="initramfsの中身を確認する"><a class="header" href="#initramfsの中身を確認する">initramfsの中身を確認する</a></h4>
<p><code>initramfs</code>の内容を展開し中身を確認してみる。Ubuntu 20.04.2 LTSの<code>initrd</code>を展開してみる。<br />
（注意: <code>initrd</code>という命名のファイルだが、このファイルはれっきとした<code>initramfs</code>である）。<br />
<code>initramfs</code>はいくつかのファイルをCPIOの形式にしたものが連結されているため、そのまま<code>cpio</code>コマンドで解凍しても以下のように冒頭のファイル（AuthenticAMD.bin）のみしか出てこない</p>
<pre><code class="language-bash">$ mkdir initrd-work &amp;&amp; cd initrd-work
$ sudo cp /boot/initrd.img ./
$ cat initrd.img| cpio -idvm
.
kernel
kernel/x86
kernel/x86/microcode
kernel/x86/microcode/AuthenticAMD.bin
62 blocks
</code></pre>
<p><code>dd</code>/<code>cpio</code>の組み合わせで全てのファイルが展開できるが、<code>unmkinitramfs</code>という便利なコマンドがあるので今回はこちらを利用する</p>
<pre><code class="language-bash">$ mkdir extract
$ unmkinitramfs initrd.img extract
$ ls extract
early  early2  main
</code></pre>
<p>解凍した結果、<code>early</code>, <code>early2</code>, <code>main</code>というディレクトリが作成されていることがわかる
例えばこの<code>early</code>は先ほどCPIOで解凍した際に出てきたファイルが確認できる
重要なのは、<code>main</code>の配下で、その中のコンテンツとしてファイルシステムルートの内容が格納されている</p>
<pre><code class="language-bash">$ ls extract/early/kernel/x86/microcode
AuthenticAMD.bin
$ ls extract/early2/kernel/x86/microcode
GenuineIntel.bin
$ ls extract/main
bin  conf  cryptroot  etc  init  lib  lib32  lib64  libx32  run  sbin  scripts  usr  var
</code></pre>
<p>ここで解凍した内容に対してchrootすると、Linux起動時のRAM filesystemの内容を擬似的に操作でき、どのような操作ができるか把握することができる。</p>
<pre><code>$ sudo chroot extract/main /bin/sh

BusyBox v1.30.1 (Ubuntu 1:1.30.1-4ubuntu6.3) built-in shell (ash)
Enter 'help' for a list of built-in commands.

# ls
scripts    init       run        etc        var        usr        conf
lib64      bin        lib        libx32     lib32      sbin       cryptroot
# pwd
/
# which mount
/usr/bin/mount
# exit
</code></pre>
<p>上記に示す通り、ルートに<code>init</code>というスクリプトファイルが入っており、これが<code>initramfs</code>を展開したのちに起動されるスクリプトである
このスクリプトを全て解説することはしないが、<code>init</code>スクリプトの中で<code>/proc/cmdline</code>の中身を読んでおり、ここから本来のroot filesystemが格納しているディスク情報（<code>root=/dev/sda1</code>のような記載）を拾い、マウント処理を実施しているようであった。
一方、この辺りが空の場合、Ubuntu 20.04LTSのinitrdから抜き出したこの<code>init</code>ファイルではエラーになるようだった。</p>
<p>今回のToyVMMでは以降説明する<code>firecracker-initrd</code>をベースとした<code>initramfs</code>を利用しているためこの辺りの挙動は少し異なる。</p>
<h4 id="firecracker-initrdについて"><a class="header" href="#firecracker-initrdについて">firecracker-initrdについて</a></h4>
<p>ToyVMMでは、<a href="https://github.com/marcov/firecracker-initrd">firecracker-initrd</a>を利用させてもらっている。
firecracker-initrdはAlpineをベースとしてinitrd.img（<code>initramfs</code>）を作成してくれる。
上記でみたUbuntuのinitrdとは異なり、microcodeなど追加のCPIOファイルは含まれないため、単純に解凍するだけでroot filesystemが確認できる</p>
<pre><code>$ cat initrd.img | cpio -idv
$ ls
bin  dev  etc  home  init  initrd.img  lib  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
</code></pre>
<p>Alpine Linuxは通常起動時にRAM上にファイルシステムが展開された上でOSが起動する。その後ニーズに応じて<code>setup-alpine</code>でDISKにOSを焼いたりするかなど決定する。
今回はこのAlpine Linuxのinitを使用しているため、この<code>initramfs</code>を利用して起動したVMは、デフォルトでは本命のルートファイルシステムをマウントせず、単純にRAM上にファイルシステムを展開しAlpine Linuxが起動することになる。<br />
これは、従来通りのOSのようにboot領域を二次記憶に置いた上で<code>/proc/cmdline</code>でinitスクリプトに伝えるという流れとは異なるものであるということを理解しておきたい。</p>
<h2 id="boot-sequence-of-linux-kernel-in-toyvmm"><a class="header" href="#boot-sequence-of-linux-kernel-in-toyvmm">Boot sequence of linux kernel in ToyVMM</a></h2>
<p>ここでこれまで議論してきた内容とToyVMMでのLinuxブートについての比較をしてみる</p>
<table><thead><tr><th>Boot process (on Linux)</th><th>ToyVMM</th></tr></thead><tbody>
<tr><td>BIOS</td><td>Not implemented yet</td></tr>
<tr><td>Boot Loader</td><td><strong>Require: vmlinux/initrd.img loading, basic setup required</strong></td></tr>
<tr><td>Linux Kernel</td><td>Processed by <code>vmlinux.bin</code></td></tr>
<tr><td>init</td><td>Processed by <code>init</code> scripts (from firecracker-initrd's <code>initrd.img</code>)</td></tr>
</tbody></table>
<p>現在のToyVMMの実装では<code>bzImage</code>の読み込みについてはサポートしておらず、ELFバイナリである<code>vmlinux.bin</code>を利用することとする。
現時点の実装ではBIOS関係については実装を省略している。<br />
BootLoaderが行う処理のうち、<code>vmlinux.bin</code>や<code>initrd.img</code>をメモリにロードするなどの処理を実装する必要がある。
Linux Kernel自体は<code>vmlinux.bin</code>が、<code>init</code>の処理は<code>initrd.img</code>内部の<code>init</code>スクリプトが担当するため、上記の処理を実装することで既存のLinux Kernelを起動すること自体は可能である。
より詳細の実装については<a href="./02-6_minimal_vmm_implementation.html">02-6_minimal_vmm_implementation</a>で説明する。</p>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><a href="https://www.hazymoon.jp/OpenBSD/arch/i386/stand/mbr/mbr_structure.html">MBR(Master Boot Records)の構造</a></li>
<li><a href="https://linux.die.net/man/4/initrd">Initrd(4) - Linux man page</a></li>
<li><a href="https://gihyo.jp/admin/serial/01/ubuntu-recipe/0384">Initramfsのしくみ</a></li>
<li><a href="https://wiki.gentoo.org/wiki/Initramfs/Guide/ja">Initramfs/ガイド</a></li>
<li><a href="https://0xax.gitbooks.io/linux-insides/content/Booting/">Kernel Boot Process</a></li>
<li><a href="https://www.baeldung.com/linux/initrd-vs-initramfs">What's the Difference Between initrd and initramfs</a></li>
<li><a href="https://wiki.bit-hive.com/linuxkernelmemo/pg/bzImage">bzImage</a></li>
<li><a href="http://www.seinan-gu.ac.jp/%7Eshito/old_pages/hacking/shell/sh/boot_shutdown.html">Initデーモンを理解する</a></li>
<li><a href="https://keichi.dev/post/linux-boot/">Linuxがブートするまで</a></li>
<li><a href="http://archive.linux.or.jp/JF/JFdocs/kernel-docs-2.6/filesystems/ramfs-rootfs-initramfs.txt.html">filesystems/ramfs-rootfs-initramfs.txt</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="elf-binary-format-and-vmlinux-structure"><a class="header" href="#elf-binary-format-and-vmlinux-structure">ELF binary format and vmlinux structure</a></h1>
<p>本稿執筆時、ToyVMMでVMを起動する際に利用するカーネルはELF形式の<code>vmlinux.bin</code>を前提としている。<br />
そのため、VMMの内部ではELF形式を解釈し、適切にカーネルをVM用に用意したメモリ領域にロードする必要がある。 
この処理は <a href="https://github.com/rust-vmm/linux-loader"><code>rust-vmm/linux-loader</code></a> crateで実装されており、ToyVMMではこのcrateを利用するため実装としては隠蔽されてしまうが、このcrateの中でどのように処理されているかを知ることは重要だと判断したため、本章を設けELFバイナリのロードに関する解説を記載することとした。</p>
<h2 id="elf-binary-format"><a class="header" href="#elf-binary-format">ELF Binary Format</a></h2>
<p>ELFのファイルフォーマットは以下のようになっている</p>
<img src="./02_figs/elf_format.svg" width="100%">
<p>上記の通り、ELFファイルフォーマットは基本的に<code>ELF Header</code>、<code>Program Header Table</code>、<code>Segument(Sections)</code>、<code>Section Header Table</code>からなる。<br />
ELFファイルはシステムローダが利用する場合は<code>Program Header Table</code>に記述された<code>Segment</code>の集合として取り扱われ、コンパイラ・アセンブラ・リンカは<code>Section Header Table</code>に記述された<code>Section</code>の集合として扱われる。</p>
<p><code>ELF Header</code>はこのELFファイルの全体的な情報を保持している。<br />
<code>Program Header Table</code>の各エントリである<code>Program Header</code>は、それぞれが対応する<code>Segument</code>についてのHeader情報を保持している。つまり、<code>Program Header</code>の数だけ、<code>Segment</code>が存在していることになる。<br />
また、この<code>Segument</code>はさらに複数の<code>Seciton</code>という単位に分割でき、この<code>Section</code>単位でヘッダ情報を保持しているのが<code>Section Header Table</code>である。</p>
<p><code>ELF Header</code>は常にファイルオフセットの先頭から始まっており、ELFデータを読み込むために必要となる情報を保持している。
以下に<code>ELF Header</code>の内容を一部抜粋する。全体の構成を知りたい場合は<a href="https://linuxjm.osdn.jp/html/LDP_man-pages/man5/elf.5.html">Man page of ELF</a>を参考にされたい</p>
<table><thead><tr><th>Attribute</th><th>Meaning</th></tr></thead><tbody>
<tr><td><code>e_entry</code></td><td>このELFプロセスを開始する際のエントリポイントとなる仮想アドレス</td></tr>
<tr><td><code>e_phoff</code></td><td><code>Program Header Table</code>が存在する場所のファイルオフセット値</td></tr>
<tr><td><code>e_shoff</code></td><td><code>Section Header Table</code>が存在する場所のファイルオフセット値</td></tr>
<tr><td><code>e_phentsize</code></td><td><code>Program Header Table</code>にある1エントリのサイズ</td></tr>
<tr><td><code>e_phnum</code></td><td><code>Program Header Table</code>中のエントリの個数</td></tr>
<tr><td><code>e_shentsize</code></td><td><code>Section Header Table</code>にある1エントリのサイズ</td></tr>
<tr><td><code>e_shnum</code></td><td><code>Section Header Table</code>中のエントリの個数</td></tr>
</tbody></table>
<p>上記で抜粋した内容から、<code>Program Header</code>や<code>Section Header</code>の各エントリの情報を取り出すことが可能であると分かるであろう。</p>
<p>ここで、<code>Program Header</code>の内容を一部抜粋する。</p>
<table><thead><tr><th>Attribute</th><th>Meaning</th></tr></thead><tbody>
<tr><td><code>p_type</code></td><td>この<code>Program Header</code>が指す<code>Segment</code>の種類を表現しており、解釈の方法についてのヒントを与える</td></tr>
<tr><td><code>p_offset</code></td><td>この<code>Program Header</code>が指す<code>Segment</code>のファイルオフセット値</td></tr>
<tr><td><code>p_paddr</code></td><td>物理アドレスが意味を持つシステムでは、この値は<code>Program Header</code>が指す<code>Segment</code>の物理アドレスを指す</td></tr>
<tr><td><code>p_filesz</code></td><td>この<code>Program Header</code>が指す<code>Segment</code>のファイルイメージのバイト数</td></tr>
<tr><td><code>p_memsz</code></td><td>この<code>Program Header</code>が指す<code>Segment</code>のメモリイメージのバイト数</td></tr>
<tr><td><code>p_flags</code></td><td>この<code>Program Header</code>が指す<code>Segment</code>の情報を示すフラグで、実行可能、書き込み可能、読み取り可能を表現している</td></tr>
</tbody></table>
<p>上述の通り、<code>Program Header</code>の中身を解釈することで、当該セグメントの位置やサイズ、どの様に解釈すべきかの情報を手に入れることができる。
今回の内容はこの<code>Program Header</code>の構造まで把握できていれば十分であるため、<code>Section Header</code>やそのほかの詳細については省略する。<br />
興味がある方は、<a href="https://linuxjm.osdn.jp/html/LDP_man-pages/man5/elf.5.html">Man page of ELF</a>等を参考に確認されたい。</p>
<p>さて、後述するが今回取り扱う<code>vmlinux.bin</code>は<code>Program Header</code>の数が5個で、内4つの<code>p_type</code>の値が<code>PT_LOAD</code>、最後の一つだけ<code>PT_NOTE</code>になっているという大変簡単な構造になっている。
ここで、<code>PT_LOAD</code>、<code>PT_NOTE</code>についてのみ、<a href="https://linuxjm.osdn.jp/html/LDP_man-pages/man5/elf.5.html">Man page of ELF</a>からその詳細内容を部分的に抜粋する。一部情報を削っているため、必要に応じて参考資料を確認されたい。</p>
<table><thead><tr><th><code>p_type</code></th><th>Meaning</th></tr></thead><tbody>
<tr><td><code>PT_LOAD</code></td><td>この要素は<code>p_filesz</code>と<code>p_memsz</code>で記述される読み込み可能な<code>Segment</code>である。</td></tr>
<tr><td><code>PT_NOTE</code></td><td>この要素はロケーションとサイズのための補助情報が書き込まれている</td></tr>
</tbody></table>
<p><code>PT_LOAD</code>では、ファイルのバイト列はメモリセグメントの先頭に対応づけされているため、<code>p_offset</code>を利用して得られる、セグメントのメモリアドレスからサイズ分（基本的には<code>p_memsz</code>を利用する）をCOPYすることでセグメントの内容を読み込むことができる。</p>
<p>以上で必要最低限なELFの知識を身につけることができたので、次は実際に<code>vmlinux.bin</code>をダンプしてみて中身を確認してみる。</p>
<h2 id="vmlinxの解析"><a class="header" href="#vmlinxの解析">vmlinxの解析</a></h2>
<p>それではここで<code>vmlinux</code>の内容を少し解析してみよう。<br />
この解析内容の一部は今後重要な要素になってくるため是非把握してもらいたい。<br />
<code>readelf</code>コマンドはELFフォーマットのファイルを理解しやすい形でダンプしてくれる非常に心強いツールである。
ここではvmlinuxのELF Header(<code>-h</code>)、Program Header（<code>-l</code>）をそれぞれ表示してみる</p>
<pre><code class="language-bash">$ readelf -h -l vmlinux.bin
ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF64
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              EXEC (Executable file)
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x1000000
  Start of program headers:          64 (bytes into file)
  Start of section headers:          21439000 (bytes into file)
  Flags:                             0x0
  Size of this header:               64 (bytes)
  Size of program headers:           56 (bytes)
  Number of program headers:         5
  Size of section headers:           64 (bytes)
  Number of section headers:         36
  Section header string table index: 35

Program Headers:
  Type           Offset             VirtAddr           PhysAddr
                 FileSiz            MemSiz              Flags  Align
  LOAD           0x0000000000200000 0xffffffff81000000 0x0000000001000000
                 0x0000000000b72000 0x0000000000b72000  R E    0x200000
  LOAD           0x0000000000e00000 0xffffffff81c00000 0x0000000001c00000
                 0x00000000000b0000 0x00000000000b0000  RW     0x200000
  LOAD           0x0000000001000000 0x0000000000000000 0x0000000001cb0000
                 0x000000000001f658 0x000000000001f658  RW     0x200000
  LOAD           0x00000000010d0000 0xffffffff81cd0000 0x0000000001cd0000
                 0x0000000000133000 0x0000000000413000  RWE    0x200000
  NOTE           0x0000000000a031d4 0xffffffff818031d4 0x00000000018031d4
                 0x0000000000000024 0x0000000000000024         0x4

 Section to Segment mapping:
  Segment Sections...
   00     .text .notes __ex_table .rodata .pci_fixup __ksymtab __ksymtab_gpl __kcrctab __kcrctab_gpl __ksymtab_strings __param __modver
   01     .data __bug_table .vvar
   02     .data..percpu
   03     .init.text .altinstr_aux .init.data .x86_cpu_dev.init .parainstructions .altinstructions .altinstr_replacement .iommu_table .apicdrivers .exit.text .smp_locks .data_nosave .bss .brk
   04     .notes
</code></pre>
<p>ELF Headerをみてみると、Entry point address (<code>e_entry</code>)の値としてProgram Headerの最初のセグメントの物理アドレスの値である(<code>0x0100_0000</code>)が格納されていることが分かる。この値は<code>rust-vmm/linux-loader</code>の実装としてkernelをロードした際の返り値として返却される値であり、かつvCPUの<code>eip</code>（命令アドレスレジスタ）に設定する値でもあるため重要である。<br />
また、ELF HeaderのNumber of program headers(<code>e_phnum</code>)の値である<code>5</code>と同じ数のProgram Headerが確認でき、Program Headerを出力をみると先頭4つはTypeが<code>LOAD</code>、最後は<code>NOTE</code>となっていることが確認できる。<br />
また、1つ目、および4つ目の<code>LOAD</code>セグメントはFlagを確認すると<code>E(xecutable)</code>がマークされており、この辺りに実行可能コードが存在していることも分かる。
特に1つめのエントリは実際にカーネルの実行バイナリのエントリポイントに該当する内容が配置されていることが期待される。<br />
今回はこれ以上の深追いは控えておくが、興味がある人はELFのSpecificationをもとにさらに解析をしてみるのも面白いかもしれない。</p>
<h2 id="toyvmmでの実装"><a class="header" href="#toyvmmでの実装">ToyVMMでの実装</a></h2>
<p>ToyVMMでは、<code>src/builder.rs</code>の中の<code>load_kernel</code>関数の中でvmlinuxの読み込みを実施している。<br />
この関数には、カーネルファイルへのパス情報などが含まれている<code>boot_config</code>とVM向けに確保したメモリ(<code>guest_memory</code>)を渡している。
<code>load_kernel</code>が実施していることは単純で、<code>boot_config</code>からカーネルファイルへのパスを取得し、<code>linux-loader</code>の<code>Elf</code>という構造体を<code>Loader</code>という名前で取り扱い、この構造体に実装されているELF形式のLinuxのローディング処理を適切な引数を伴って実行しているだけである。</p>
<pre><code>use linux_loader::elf::Elf as Loader;

let entry_addr = Loader::load::&lt;File, memory::GuestMemoryMmap&gt;(
    guest_memory,
    None,
    &amp;mut kernel_file,
    Some(GuestAddress(arch::x86_64::get_kernel_start())),
).map_err(StartVmError::KernelLoader)?;
</code></pre>
<p>さて、ここから<code>linux-loader</code>の実装について深掘りしてみよう。
<code>linux-loader</code>では、<code>KernelLoader</code> traitが定義されており、その定義は以下のようになっている</p>
<pre><code>/// Trait that specifies kernel image loading support.
pub trait KernelLoader {
    /// How to load a specific kernel image format into the guest memory.
    ///
    /// # Arguments
    ///
    /// * `guest_mem`: [`GuestMemory`] to load the kernel in.
    /// * `kernel_offset`: Usage varies between implementations.
    /// * `kernel_image`: Kernel image to be loaded.
    /// * `highmem_start_address`: Address where high memory starts.
    ///
    /// [`GuestMemory`]: https://docs.rs/vm-memory/latest/vm_memory/guest_memory/trait.GuestMemory    .html
    fn load&lt;F, M: GuestMemory&gt;(
        guest_mem: &amp;M,
        kernel_offset: Option&lt;GuestAddress&gt;,
        kernel_image: &amp;mut F,
        highmem_start_address: Option&lt;GuestAddress&gt;,
    ) -&gt; Result&lt;KernelLoaderResult&gt;
    where
        F: Read + Seek;
}
</code></pre>
<p>コメントから推測できるように、このtraitが実装しているべき<code>load</code>関数は、特定のカーネルイメージフォーマットをGuestMemoryに読み込むような実装になっていることを要求している。
linux-loaderではx86_64向けの実装として、ELF形式の他にbzImage形式のカーネルの読み込みについても実装が存在しているようであるが、ひとまず今回はELF向けの実装を利用する。</p>
<p>さて、先のToyVMM側のコードで利用していた<code>Elf</code>構造体（<code>Loader</code>と名前を変えてimportした構造体）はこの<code>KernelLoader</code> traitを実装しており、その<code>load</code>関数がELFファイルをロードする実装になっていることが期待できる。<br />
そのため、このload関数を見てみると以下のような処理になっていることがわかる。処理内容がすこし長いためコードの転載は控える。</p>
<ol>
<li>ELFファイルの先頭から、ELFヘッダー分のデータを抜き出す</li>
<li><code>loader_result</code>という変数名の<code>KernelLoaderResult</code>構造体のインスタンスを作成し、<code>kernel_load</code>メンバにELFヘッダの<code>e_entry</code>の値を格納しておく。この値はシステムが最初に制御を渡すアドレス、つまりプロセスを開始する仮想アドレスに該当する。</li>
<li>ELFファイルを先頭からプログラムヘッダテーブルが存在するアドレスまで（<code>e_phoff</code>分）シークし、プログラムヘッダテーブル数分（<code>e_phnum</code>分）ループしながら、ELFファイルに含まれているプログラムヘッダを全て抜き出す。</li>
<li>上記のプログラムヘッダをループしつつ以下の内容を行う
<ul>
<li>ELFファイルの先頭から今確認しているプログラムヘッダに対応するセグメントまで（<code>p_offset</code>分）シーク</li>
<li>Guestのメモリに対して、<code>mem_offset</code>から算出したmemory regionのアドレス位置を先頭に、<code>kernel_image</code>（<code>p_offset</code>分シーク済みなので、プログラムヘッダに対応するセグメントのデータの先頭）から、セグメントのサイズ分(<code>p_filesz</code>分)だけを書き込む</li>
<li><code>kernel_end</code>（GuestMemory上での読み込んだセグメントの末尾のアドレス）の値を更新し、<code>loader_result.kernel_end</code>（2回目以降のループでは前回の値が記録されている）と比較して大きい方の値を<code>loader_result.kernel_end</code>に格納しておく</li>
</ul>
</li>
<li>全てのプログラムヘッダをループ後、返り値として最終的な<code>loader_result</code>を返却する。</li>
</ol>
<p>これはまさに上記でみたELFフォーマットを解釈し読み込むコードになっていることがわかる。<br />
また当該関数呼び出しの結果返却される<code>KernelLoaderResult</code>の値には、最終的なGuestMemory上でのカーネルの開始位置、終了位置の情報が含まれており、特にこの開始位置の情報は<a href="./02-4_setup_registers_of_vcpu.html">Setup registers of vCPU</a>で利用する値になるため重要である。</p>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<ul>
<li><a href="https://valinux.hatenablog.com/entry/20200910">vmlinux</a></li>
<li><a href="https://www.hazymoon.jp/OpenBSD/annex/elf.html">ELF Formatについて</a></li>
<li><a href="https://linuxhint.com/understanding_elf_file_format/">Understanding the ELF File Format</a></li>
<li><a href="https://qiita.com/niwaka_dev/items/b915d1ffc7a677c74959">ELF形式のヘッダ部分を解析する単純なプログラムを作ってみた</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="loading-initrd"><a class="header" href="#loading-initrd">Loading initrd</a></h1>
<p>本稿では、VMを起動するにあたり<code>initrd</code>(<code>initramfs</code>)のロードやこれにまつわる設定について記載する。<br />
以降の記載では、<code>initrd</code>と書いたときも暗黙に<code>initramfs</code>を指しているとする。<br />
initramfs自体の説明は<a href="./02-1_overview_of_booting_linux.html">Overview of booting linux</a>で既におこなっているのでそちらを確認されたい</p>
<h2 id="loading-initrd-and-setup-some-parameters-of-kernel-header"><a class="header" href="#loading-initrd-and-setup-some-parameters-of-kernel-header">Loading initrd and setup some parameters of kernel header</a></h2>
<p><code>initrd</code>をロードする関数は<code>load_initrd</code>に実装している。
引数としてはGuest用に確保したメモリと、<code>initrd</code>のファイルをOpenした<code>File</code>構造体(Read, Seekを実装している)の可変参照を渡している</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn load_initrd&lt;F&gt;(
    vm_memory: &amp;memory::GuestMemoryMmap,
    image: &amp;mut F,
) -&gt; std::result::Result&lt;InitrdConfig, StartVmError&gt;
where F: Read + Seek {
    let size: usize;
    // Get image size
    match image.seek(SeekFrom::End(0)) {
        Err(e) =&gt; return Err(StartVmError::InitrdRead(e)),
        Ok(0) =&gt; {
            return Err(StartVmError::InitrdRead(io::Error::new(
                io::ErrorKind::InvalidData,
                &quot;Initrd image seek returned a size of zero&quot;,
            )))
        }
        Ok(s) =&gt; size = s as usize,
    };
    // Go back to the image start
    image.seek(SeekFrom::Start(0)).map_err(StartVmError::InitrdRead)?;
    // Get the target address
    let address = arch::initrd_load_addr(vm_memory, size)
        .map_err(|_| StartVmError::InitrdLoad)?;

    // Load the image into memory
    //   - read_from is defined as trait methods of Bytes&lt;A&gt;
    //     and GuestMemoryMmap implements this trait.
    vm_memory
        .read_from(GuestAddress(address), image, size)
        .map_err(|_| StartVmError::InitrdLoad)?;

    Ok(InitrdConfig{
        address: GuestAddress(address),
        size,
    })
}
<span class="boring">}
</span></code></pre></pre>
<p>上記の処理でおこなっていること関数名の通りGuest用メモリへの<code>initrd</code>のロードであるが、内容としては以下の通り単純である</p>
<ol>
<li>initrdのサイズの取得する（SeekFrom::End(0)としてファイルの末尾にカーソルを指定することでoffset=size取得をしている）</li>
<li>1でサイズを取得するために動かしたカーソルを先頭に戻す</li>
<li>initrdをロードするべきGuestメモリのaddressを取得する</li>
<li>上記Guestメモリのaddress位置にinitrdの中身を読み込む</li>
<li><code>InitrdConfig</code>という構造体にGuestメモリのinitrd開始位置のアドレスとinitrdの値を詰めて返却する)</li>
</ol>
<p>さて、上記でGuestメモリ上に<code>initrd</code>をロードすることはできたが、実際にこの領域をカーネルがどのように把握するのかという疑問が残っている<br />
ブートローダの責務の一つにカーネルのセットアップヘッダを読み込み、いくつかのフィールドを埋めるというものがある。<br />
このセットアップヘッダの内容は<a href="https://docs.kernel.org/x86/boot.html#the-real-mode-kernel-header">Boot Protocol</a>として定義されており、上記のinitrdに関係する内容はこの値として格納されるべき値の一つになっている.</p>
<p>今回、ToyVMMではこれらの内容を主に<code>configure_system</code>関数で以下の通り設定している。<br />
以下の内容については<a href="https://docs.kernel.org/x86/boot.html#the-real-mode-kernel-header">Boot Protocol</a>を参照している。<br />
ここでは下記以外の設定項目については設定をしていないため説明を省略する。</p>
<table><thead><tr><th>Offset/Size</th><th>Name</th><th>Meaning</th><th>ToyVMM value</th></tr></thead><tbody>
<tr><td>01FE/2</td><td>boot_flag</td><td>0xAA55 magic number</td><td>0xaa55</td></tr>
<tr><td>0202/4</td><td>header</td><td>Magic signature &quot;HdrS&quot; (0x53726448)</td><td>0x5372_6448</td></tr>
<tr><td>0210/1</td><td>type_of_loader</td><td>Boot loader identifier</td><td>0xff (undefined)</td></tr>
<tr><td>0218/4</td><td>ramdisk_image</td><td>initrd load address (set by boot loader)</td><td>GUEST ADDRESS OF INITRD</td></tr>
<tr><td>021C/4</td><td>ramdisk_size</td><td>initrd size (set by boot loader)</td><td>SIZE OF INITRD</td></tr>
<tr><td>0228/4</td><td>cmd_line_ptr</td><td>32-bit pointer to the kernel command line</td><td>0x20000</td></tr>
<tr><td>0230/4</td><td>kernel_alignment</td><td>Physical addr alignment required for kernel</td><td>0x0100_0000</td></tr>
<tr><td>0238/4</td><td>cmdline_size</td><td>Maximum size of the kernel command line</td><td>SIZE OF CMDLINE STRING</td></tr>
</tbody></table>
<p>上記の内容をGuestMemoryの<code>0x7000</code>に書き込むコードになっている。<br />
この<code>0x7000</code>のアドレスは後述するvCPUのRSIの値として書き込んでおく値になる。<br />
vCPUのレジスタ設定関係については<a href="./02-4_setup_registers_of_vcpu">Setup registers of vCPU</a>に記載しているので、本稿読了後に参照されたい。</p>
<h2 id="setup-e820"><a class="header" href="#setup-e820">Setup E820</a></h2>
<p>Guest OSのE820のセットアップを行うことで、OSやBootLoaderに対して利用可能なメモリ領域の報告できるようにしたい。
kernel headerの[]に[]があるので、この値をToyVMM側で設定する。
この辺りの処理は基本的にFirecrackerの実装に合わせて実装している。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>add_e820_entry(&amp;mut params, 0, EBDA_START, E820_RAM)?;
let first_addr_past_32bits = GuestAddress(FIRST_ADDR_PAST_32BITS);
let end_32bit_gap_start = GuestAddress(MMIO_MEM_START);
let himem_start = GuestAddress(HIGH_MEMORY_START);
let last_addr = guest_mem.last_addr();
if last_addr &lt; end_32bit_gap_start {
    add_e820_entry(
        &amp;mut params,
        himem_start.raw_value() as u64,
        last_addr.unchecked_offset_from(himem_start) as u64 + 1,
        E820_RAM)?;
} else {
    add_e820_entry(
        &amp;mut params,
        himem_start.raw_value(),
        end_32bit_gap_start.unchecked_offset_from(himem_start),
        E820_RAM)?;
    if last_addr &gt; first_addr_past_32bits {
        add_e820_entry(
            &amp;mut params,
            first_addr_past_32bits.raw_value(),
            last_addr.unchecked_offset_from(first_addr_past_32bits) + 1,
            E820_RAM)?;
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>上記のコードはToyVMMで起動するGuest VMのアドレス全体の設計を見ながら理解した方が良いだろう。そのため以下に、現状の実装におけるGuestのメモリ設計を以下の通り一覧にしておく。
この内容は今後変更される可能性があるため注意されたい。</p>
<table><thead><tr><th>Guest Address</th><th>Contents</th><th>Note</th></tr></thead><tbody>
<tr><td>0x0 - 0x9FBFF</td><td>E820</td><td></td></tr>
<tr><td>0x7000 - 0x7FFF</td><td>Boot Params (Header)</td><td>ZERO_PAGE_START(=0x7000)</td></tr>
<tr><td>0x9000 - 0x9FFF</td><td>PML4</td><td>Now only 1 entry (8byte), maybe expand later</td></tr>
<tr><td>0xA000 - 0xAFFF</td><td>PDPTE</td><td>Now only 1 entry (8byte), maybe expand later</td></tr>
<tr><td>0xB000 - 0xBFFF</td><td>PDE</td><td>Now 512 entry (4096byte)</td></tr>
<tr><td>0x20000 -</td><td>CMDLINE</td><td>Size depends on cmdline parameter len</td></tr>
<tr><td>0x100000</td><td></td><td>HIGH_MEMORY_START</td></tr>
<tr><td>0x100000 - 0x7FFFFFF</td><td>E820</td><td></td></tr>
<tr><td>0x100000 - 0x20E3000</td><td>vmlinux.bin</td><td>Size depends on vmlinux.bin's size</td></tr>
<tr><td>0x6612000 - 0x7FFF834</td><td>initrd.img</td><td>Size depends on initrd.img's size</td></tr>
<tr><td>0x7FFFFFF</td><td>GuestMemory last address</td><td>based on (128 &lt;&lt; 20 = 128MB = 0x8000000) - 1</td></tr>
<tr><td>0xD0000000</td><td></td><td>MMIO_MEM_START（4GB - 768MB）</td></tr>
<tr><td>0xD0000000 - 0xFFFFFFFF</td><td></td><td>MMIO_MEM_START - FIRST_ADDR_PAST_32BIT</td></tr>
<tr><td>0x100000000</td><td></td><td>FIRST_ADDR_PAST_32BIT (4GB~)</td></tr>
</tbody></table>
<p>コードを確認すると、GuestMemoryのサイズに非依存で設計しているアドレス帯（大まかに<code>0x0 ~ HIGH_MEMORY_START</code>のレンジ）は<code>0~EBDA_START(0x9FBFF)</code>の領域を共通でE820にUsableで登録している。
その後、GuestMemoryをどの程度確保しているかに従ってE820に登録している範囲が変化する。
現在の実装では、GuestのMemoryはデフォルトで128MBのメモリを確保するように実装しているためGuest Memoryは全体で<code>0x0 ~ 0x7FF_FFFF</code>になる。今回はこのレンジに<code>vmlnux.bin</code>の内容や<code>initrd.img</code>がマップされている。
つまり<code>guest_mem.last_addr() = 0x7FF_FFFF &lt; 0xD000_0000 = end_32bit_gap_start</code>のロジックに該当するので、<code>HIGH_MEMORY_START ~ guest_mem.last_addr()</code>のレンジを追加で登録している。
今後拡張していく中で、GuestMemoryのサイズが4GB超える場合は、<code>0x10_0000 ~ 0xD000_0000</code>と<code>0x1_000_0000 ~ guest_mem.last_addr()</code>のレンジを登録することになる。</p>
<p>後ほどVM起動時のコンソール出力を確認できるようになるが、ここでは確認のために先取ってVM起動時の一部の出力を添付する。
以下のように上記で設定したE820エントリが登録できている。</p>
<pre><code class="language-bash">[    0.000000] e820: BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x0000000007ffffff] usable
</code></pre>
<h2 id="references-2"><a class="header" href="#references-2">References</a></h2>
<ul>
<li><a href="https://nishidy.hatenablog.com/entry/2016/09/08/230637">Linuxのブートシーケンスの基礎まとめ</a></li>
<li><a href="https://doc.kusakata.com/admin-guide/initrd.html">Linuxカーネルユーザ・管理者ガイド - 初期RAMdディスクを使用する</a></li>
<li><a href="https://manpages.ubuntu.com/manpages/bionic/ja/man4/initrd.4.html">initrd</a></li>
<li><a href="https://www.gcd.org/blog/2007/09/129/">initramfs(initrd)のinitをbusyboxだけで書いてみた</a></li>
<li><a href="https://blog.goo.ne.jp/pepolinux/e/4d1f4b6e0f5b5ed389fcec1f711b1408">initramfsとinitrdについて</a></li>
<li><a href="https://qiita.com/akachochin/items/d38b538fcabf9ff80531">initramfsについて</a></li>
<li><a href="http://archive.linux.or.jp/JF/JFdocs/kernel-docs-2.6/filesystems/ramfs-rootfs-initramfs.txt.html">filesystem/ramfs-rootfs-initramfs.txt</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setup-registers-of-vcpu"><a class="header" href="#setup-registers-of-vcpu">Setup registers of vCPU</a></h1>
<p>本稿では、vCPUのレジスタの設定について記載する。<br />
一口にレジスタと言ってもその種類は多岐に渡るため、それぞれどのレジスタをどう設定すると良いかを判断するのはかなり煩雑である。<br />
本稿で説明するRegisterに関わる内容はVMを起動するという側面にのみ焦点を置いた内容になっているので注意されたい。<br />
また、64-bit modeでGuest OSを起動したいので、64-bit modeに移行するためのいくつかの設定やその設定にまつわるPagingについても簡単に解説する。</p>
<h2 id="setup-vcpu-general-purpose-registers"><a class="header" href="#setup-vcpu-general-purpose-registers">Setup vCPU general purpose registers</a></h2>
<p>vCPUのgeneral purose registersは、KVMの<code>set_regs</code> APIを通してセットアップが可能である。<br />
今回は以下のようにレジスタの値を設定する。（レジスタ自体の詳細な説明は省く)</p>
<table><thead><tr><th>Register</th><th>Value</th><th>Meaning</th></tr></thead><tbody>
<tr><td>RFLAGS</td><td>2</td><td>0x02のbitは予約ビットで立てておかないといけない</td></tr>
<tr><td>RIP</td><td>KERNEL START ADDRESS (<code>0x0100_0000</code>)</td><td>ELFから取得したkernelのentry pointのアドレス</td></tr>
<tr><td>RSP</td><td>BOOT STACK POINTER (<code>0x8ff0</code>)</td><td>BOOT時に利用するStack Pointerのアドレス</td></tr>
<tr><td>RBP</td><td>BOOT STACK POINTER (<code>0x8ff0</code>)</td><td>BOOT処理実施前なのでRSPの値に合わせておく</td></tr>
<tr><td>RSI</td><td><code>boot_params</code> ADDRESS (<code>0x7000</code>)</td><td><code>boot_param</code>の情報が格納されているアドレス</td></tr>
</tbody></table>
<p>RIPはvCPU起動時の命令開始アドレスを格納する必要があり、今回はKernelのEntry Pointのアドレスを記載する。<br />
後述するが、<code>x64 Long Mode</code>を設定したCPUで実行するため、RIPのアドレスも仮想メモリアドレスとして扱われることになるが、Paging機構をIdentity Mappingで実装するため、<code>仮想メモリアドレス = 物理メモリアドレス</code>となり辻褄が合うことになる。<br />
RSP、RBPにはBootに必要なStackを格納するためのアドレスを入れておく。この辺りの値は空いている領域を使えば良い<br />
RSIには<a href="https://docs.kernel.org/x86/boot.html#id1">64-bit Boot Protocol</a>にも記載がある通り、<code>boot_params</code>構造体が格納されているアドレスを渡しておく必要がある。
ToyVMMはFirecrackerの値を模倣して作成しているため、RSP、RBP、RSIに格納するaddress値はFirecrackerのものを模倣している。</p>
<h2 id="setup-vcpu-special-registers"><a class="header" href="#setup-vcpu-special-registers">Setup vCPU special registers</a></h2>
<p>vCPUのspecial registersは、KVMの<code>set_sregs</code> APIを通してセットアップが可能である。<br />
ここでは実際にセットアップをしているレジスタにのみ焦点を当てつつ、その背景についても簡単にではあるが触れながら確認していく。<br />
ここからの説明では、これまで話題に上げてこなかった単語なども出てくることになるだろう。これらを一つ一つ説明していてはキリがないため、知らない単語に遭遇したらご自身で確認してほしい。</p>
<h4 id="idtinterrupt-descriptor-table"><a class="header" href="#idtinterrupt-descriptor-table">IDT(Interrupt Descriptor Table)</a></h4>
<p><a href="https://wiki.osdev.org/Interrupt_Descriptor_Table">IDT(Interrupt Descriptor Table)</a>とは、Protected modeとLong Modeにおける割り込み、例外に関する情報を保持するデータ構造である。<br />
もともとReal ModeではIVT（Interrupt Vector Table）というものが存在しており、これはISR(Interrupt Service Routine)がどこにあるかをCPUに対して教える役割を持っていた。<br />
要するに各割り込みや例外に対するハンドラを保持しており、それらが発生したとき、どのハンドラを起動すればいいか決定できるテーブルであった。</p>
<p>Protected modeやLong modeになるとRead Modeとは異なるアドレス表現になるため、それに対応した同様の能力をもつ機構がIDTである。<br />
IDTは最大255 Entryのテーブルであり、IDTのアドレスをIDTRレジスタに設定する必要がある。割り込みが発生した際、CPUはIDTRの値からIDTを参照し、指定された割り込みハンドラを実行する。</p>
<p><a href="https://docs.kernel.org/x86/boot.html#id1">64-bit Boot Protocol</a>での要求を確認すると、Interruptの設定はDisabledでなくてはならないという。
それに伴い、IDTに関する設定はToyVMM(Firecracker)の実装の中では省略されている、IDTについての説明もここまでにとどめておく。</p>
<h4 id="segumentation-gdtglobal-descriptor-table-ldtlocal-descriptor-table"><a class="header" href="#segumentation-gdtglobal-descriptor-table-ldtlocal-descriptor-table">Segumentation, GDT(Global Descriptor Table), LDT(Local Descriptor Table)</a></h4>
<p>GDTの話を始める前に、まずはSegumentationについて軽く導入しておく。<br />
メモリセグメンテーションはメモリ管理方式の一つであり、プログラムやデータをセグメントと呼ばれる可変なまとまりで管理する方式である。<br />
セグメントはメモリ空間上で情報の属性などによって分類されたグループであり、仮想記憶やメモリ保護機能を実現する方式の一つである。<br />
Linuxではフラットメモリを前提としたセグメンテーションとPagingを併用しているため、以降ではそれを前提として話を進める。</p>
<p><a href="https://wiki.osdev.org/Interrupt_Descriptor_Table">GDT(Global Descriptor Table)</a>は、メモリセグメントを管理するためのデータ構造である。<br />
このデータ構造はIDTのものと非常によく似通っている。
GDTはSegment Descriptorと呼ばれる複数のEntryを持つテーブルであり、GDTのアドレスをGDTRレジスタに設定する必要がある。<br />
このTableのエントリは、Segment Selectorによってアクセスされ、該当するアドレス領域はどこかという情報や、その領域ではどの様な操作が許可されているかなどの情報を得ることができる。
Segument SelectorはSegumentation RegistersやIDTの各EntryのフォーマットであるGate Descriptor、Task State Segumentなどの中に現れるものである。<br />
詳細については本稿では説明を省略しているため、気になった場合は調べてみてほしい</p>
<p><a href="https://wiki.osdev.org/Local_Descriptor_Table">LDT(Local Descriptor Table)</a>は、GDTと同様にメモリにアクセスするためのセグメントを管理するデータ構造であるが、タスクやスレッド毎にLDTを保有できるという点で違いがある。<br />
タスク毎にGDTに相当するディスクリプタを持たせることは、自身のプログラム、タスク間ではセグメントを共有しつつ、異なるタスクとはセグメントを分離することができるため、タスク間のセキュリティを高めることに寄与する。
LDTも今回の実装では関わってこない話なので、この詳細についてもここでは省略する。</p>
<h3 id="gdt-setup-for-64-bit-mode"><a class="header" href="#gdt-setup-for-64-bit-mode">GDT setup for 64-bit mode</a></h3>
<p><a href="https://docs.kernel.org/x86/boot.html#id1">64-bit Boot Protocol</a>にも記載がある通り、64-bit modeの場合はそれぞれのSegment descriptorは4G flat segmentとしてセットアップする必要があり、Code Segument、Data Segumentはそれぞれ適切な権限を付与する必要がある。
その一方<a href="https://wiki.osdev.org/Global_Descriptor_Table">Gloabl Descriptor Table</a>を確認すると、64-bit modeの場合は基本的にbase, limitが無視され、各Descriptorは全体のリニアアドレススペースをカバーするという記載があるため、Flag以外についてはどの様な値を書いていてもよさそうではある。今回は念の為、明示的にflat segumentとしてセットアップを行った。
また、<code>DS</code>、<code>ES</code>、<code>SS</code>の値はDSと同一にする必要がある旨についても記載があるため、これに習って実装する。</p>
<p>以降では、ToyVMM(Firecrackerと読み替えていただいても差し支えない）の実装を参考にこれらがどの様に設定されているかを確認してみる。
この設定は<code>configure_seguments_and_sregs</code>関数で実施されている。説明をしやすくするために、一部コメントを追記している</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn configure_segments_and_sregs(sregs: &amp;mut kvm_sregs, mem: &amp;GuestMemoryMmap) -&gt; Result&lt;(), RegError&gt; {
    let gdt_table: [u64; BOOT_GDT_MAX as usize] = [
        gdt::gdt_entry(0, 0, 0),            // NULL
        gdt::gdt_entry(0xa09b, 0, 0xfffff), // CODE
        gdt::gdt_entry(0xc093, 0, 0xfffff), // DATA
        gdt::gdt_entry(0x808b, 0, 0xfffff), // TSS
    ];
    // &gt; https://wiki.osdev.org/Global_Descriptor_Table
    //
    //              55 52     47     40 39        31               16 15                0
    // CODE: 0b0..._1010_1111_1001_1011_0000_0000_0000_0000_0000_0000_1111_1111_1111_1111
    //              &lt;-f-&gt;     &lt;-Access-&gt;&lt;---------------------------&gt; &lt;----- limit -----&gt;
    // - Flags  : 1010      =&gt; G(limit is in 4KiB), L(Long mode)
    // - Access : 1001_1011 =&gt; P(must 1), S(code/data type), E(executable), RW(readable/writable), A(CPU access allowed)
    //   - 0xa09b of A,9,B represents above values
    //
    // DATA: 0b0..._1100_1111_1001_0011_0000_0000_0000_0000_0000_0000_1111_1111_1111_1111
    // - Flags  : 1100      =&gt; G(limit is in 4KiB), DB(32-bit protected mode)
    // - Access : 1001_0011 =&gt; P(must 1), S(code/data type), RW(readable/writable), A(CPU access allowed)
    //
    // TSS
    // - Flags  : 1000      =&gt; G(limit is in 4KiB)
    // - Access : 1000_1011 =&gt; P(must 1), E(executable), RW(readable/writable), A(CPU access allowed)
    //    - TSS requires to support Intel VT
    let code_seg = gdt::kvm_segment_from_gdt(gdt_table[1], 1);
    let data_seg = gdt::kvm_segment_from_gdt(gdt_table[2], 2);
    let tss_seg = gdt::kvm_segment_from_gdt(gdt_table[3], 3);

    // Write seguments
    write_gdt_table(&amp;gdt_table[..], mem)?;
    sregs.gdt.base = BOOT_GDT_OFFSET as u64;
    sregs.gdt.limit = mem::size_of_val(&amp;gdt_table) as u16 - 1;

    write_idt_value(0, mem)?;
    sregs.idt.base = BOOT_IDT_OFFSET as u64;
    sregs.idt.limit = mem::size_of::&lt;u64&gt;() as u16 - 1;

    sregs.cs = code_seg;
    sregs.ds = data_seg;
    sregs.es = data_seg;
    sregs.fs = data_seg;
    sregs.gs = data_seg;
    sregs.ss = data_seg;
    sregs.tr = tss_seg;

    // 64-bit protected mode
    sregs.cr0 |= X86_CR0_PE;
    sregs.efer |= EFER_LME | EFER_LMA;
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>上記ではセットアップするGDTとして4 Entryを持つテーブルを作成している。
最初のEntryはGDTの要求としてNullでなければならないため、そのようなエントリを作成している。
それ以外は全体のメモリ領域に対して、CODE Segment、DATA Segment、TSS Segmentの設定を行なっていることが分かるだろう。<br />
TSSの設定はIntel VTの要求を満たすために設定されており、本資料の範疇では実質使用しない内容である。</p>
<p>さて、このGDTを作成する際に各エントリを作成する関数<code>gdt_entry</code>を呼び出しているが、この内容を以下に転載する。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn gdt_entry(flags: u16, base: u32, limit: u32) -&gt; u64 {
    ((u64::from(base) &amp; 0xff00_0000u64) &lt;&lt; (56 - 24))
        | ((u64::from(flags) &amp; 0x0000_f0ffu64) &lt;&lt; 40)
        | ((u64::from(limit) &amp; 0x000f_0000u64) &lt;&lt; (48 - 16))
        | ((u64::from(base) &amp; 0x00ff_ffffu64) &lt;&lt; 16)
        | (u64::from(limit) &amp; 0x0000_ffffu64)
}
<span class="boring">}
</span></code></pre></pre>
<p>この関数の引数として、全てのエントリがbaseに<code>0x0</code>、limitに<code>0xFFFFF</code> (<code>2^5 = 32bit = 4GB</code>)を指定しているためフラットなセグメンテーションになっている。第一引数であるflagsについてはEntry毎に設定を行なっており、これが翻ってGDTの<code>Flags</code>や<code>AccessByte</code>の値に対応するようになる。<br />
実際にそれぞれのEntryを<code>gdt_entry</code>に与えた結果返却される値と、その値を解析した内容が上記コード上のコメントになっている。
コメントを確認すると、<a href="https://docs.kernel.org/x86/boot.html#id1">64-bit Boot Protocol</a>で要求されていた通り、CODE SegumentにはExecute / Read permissionと、さらに<code>long mode (64-bit code segment)</code>のフラグが、DATA SegumentにはRead / Write permissionが付与されていることが分かる。
上記の通り作成したGDTを、<code>write_gdt_table</code>関数でGuestMemory上に書き込み、その先頭アドレスを<code>sregs.gdt.base</code>に残している。</p>
<p>後続するIDTの設定だが、上述した通りここはdisabledとなるようだ。そのためか、特に何もメモリ上に書き込んでない。ただしGuestMemory上のどの位置を利用するかについては決めてあり、そのアドレスを<code>sregs.idt.base</code>に残している。</p>
<p>引き続き、そのほかのレジスタ値を設定する。
上述した通り<code>CS</code>にはCODE segumentの情報を、<code>DS</code>, <code>ES</code>, <code>SS</code>にはData Segumentの情報を、<code>TR</code>にはTSS Segumentの情報を格納しておく。<br />
上記のコードでは<code>FS</code>, <code>GS</code>にもDATA Segumentの情報を書いているが、これらのセグメントの値はおそらく設定しなくても良い。</p>
<p>最後に、CR0やEFERレジスタの設定をしているがこの説明は後述する。</p>
<h3 id="64-bit-protected-mode"><a class="header" href="#64-bit-protected-mode">64-bit protected mode</a></h3>
<p><code>Long mode</code>とはx86_64プロセッサ用のネイティブモードであり、従来（<code>x86</code>）に比べていくつかの追加機能がサポートされているが、ここではこれらについて詳細には記載しない<br />
<code>Long mode</code>はさらに<code>64-bit mode</code>と<code>互換モード</code>の2つのサブモードから構成される。</p>
<p>64-bitモードに切り替えるには、以下の処理が必要になる</p>
<ul>
<li>CR4.PAEを設定し、物理アドレス拡張機構を有効化する</li>
<li>Page Tableの作成、CR3レジスタへトップレベルページテーブルのアドレスを読み込む</li>
<li>CR0.PGを設定し、Pagingの有効化する</li>
<li>EFER.LMEを設定し、Long Modeの有効化する</li>
</ul>
<p>レジスタ値の設定は<code>kvm_sregs</code>構造体のうち対応するものを更新し<code>set_sregs</code>で設定するだけであり、既に説明済みであるため同様に実施すれば良い。<br />
それ以外に重要な作業としてPage Tableの作成がある。
特に64-bit modeに移行するためには、4-Level Page Tableを構築する必要があるため、これに焦点をしぼって以降簡単にPagingについて説明をする。</p>
<h4 id="4-level-page-table-for-entering-64-bit-mode"><a class="header" href="#4-level-page-table-for-entering-64-bit-mode">4-Level Page Table for entering 64-bit mode</a></h4>
<p>これまで特に言及をしてこなかったが、Linux Kernelの起動に関わる処理は、利用できるメモリアドレス空間の違いによって何段階かに名称分けされている。
起動直後、物理メモリアドレスを直接触ってセットアップを進める処理は、<code>x16 Real-Mode</code>と呼ばれ、その名の通り16bitのメモリアラインメントで処理が進んでいく。<br />
一方、読者もよく知っている通り、我々の馴染みがあるOSは<code>32bit</code>であったり、<code>64bit</code>である。<br />
これらはCPUのモード切り替えと呼ばれる機能により、<code>x32 Protected Mode</code>、<code>x64 Long Mode</code>と呼ばれるモードに切り替えられるが、これらのモードに切り替えられた途端、CPUは仮想メモリアドレスしか利用できない状態になる。<br />
また、特にx64 CPUアーキテクチャでは基本的に<code>4-level page table</code>によって、64bit 仮想アドレスが物理アドレスに変換されることが期待される.
つまり、<code>x64 Long Mode</code>に切り替える前に<code>4-level page table</code>を構成してCPUに伝える必要があり、この処理はBootLoaderの機能の一部として実装される。</p>
<p>さてもう一つ重要な点としては、今<code>RIP</code>の値にはカーネルのエントリーポイントを示す<strong>物理アドレスの値</strong>が格納されているが、<code>x64 Long Mode</code>で取り扱う際にこのアドレスが<strong>仮想アドレスの値として利用される</strong>ため、別の物理アドレスに変換されてしまうとOSが起動できなくなってしまう。<br />
したがって、ここではまず仮想メモリアドレスが同じ物理メモリアドレスにマッピングされる簡単なページテーブル（これは特にIdentity Mappingと呼ばれる）を作成すること上記の問題に対応する</p>
<p><strong>Note</strong><br />
ここでBootLoaderが作成するPage Tableはx64でカーネルを実行するために一時的に必要な処理であることに注意されたい。<br />
通常我々が仮想メモリアドレスやPage Tableと聞いた時に多くの場合に思い浮かべるのは、ユーザスペースのプロセスに対してのアドレスの話であるが、このユーザプロセスに対するPagingの仕組みはカーネル内部に実装があり、カーネルの起動とともに構成されるものであるため、今回の話とは切り離して考えるべきである。<br />
つまり、このBootLoaderのpage tableの変換の仕組みがIdentity Mappingであろうがなかろうが、OS起動後の各プロセスに対するPagingの仕組みには影響がないということである。</p>
<h4 id="page-table-implementation-in-toyvmm"><a class="header" href="#page-table-implementation-in-toyvmm">Page Table implementation in ToyVMM</a></h4>
<p>ここではToyVMMの実装を具体的に見ていきながら、Page Tableの構成について理解を深める。<br />
この実装はFirecrackerの実装を模倣しているため、実質的にFirecrackerの実装と読み替えていただいて問題ない。</p>
<p>まずは、簡単に4-Level Page Tableの構造について議論しておく。基本的には以下の名称でLevel毎にTableが存在しそれぞれ名称分けされている。</p>
<ul>
<li>Level 4: Page Map Level 4 (PML4)</li>
<li>Level 3: Page Directory Pointer Table (PDPT)</li>
<li>Level 2: Page Directory Table (PDT)</li>
<li>Level 1: Page Tables (PT)</li>
</ul>
<p>また、各Tableはそれぞれ512個のEntityを格納可能であり、一つのEntityは8byte（64bit）からなるため、Table全体としては<code>512(entity) * 8(byte/entity) = 4096(byte)</code>となる。これは1つのPage（<code>4KB</code>）にちょうど収まるサイズになっている。
それぞれのLevelのEntiryは以下のような構造になっている<br />
（引用元: <a href="https://alessandropellegrini.it/didattica/2017/aosv/1.Initial-Boot-Sequence.pdf">x86 Initial Boot Sequence</a>、<a href="https://wiki.osdev.org/Paging">OSdev/Paging</a>。64bitのうちHigh bitについては今回あまり重要ではないので紙面の都合上省略している）</p>
<img src="./02_figs/cr3_and_paging.svg" width="100%">
<p>上記から、以下の内容を満たしながらセットアップすればよさそうである。</p>
<ul>
<li>CR3のなかで、PML4のアドレスとして利用されるデータは12~32+bitになるため、これを考慮してPML4のアドレスを設計する</li>
<li>PML4は有効化のために0bit目は1にセットし、12~32+bitにPDPTのアドレスを設計する</li>
<li>PDPTE page directoryのレイアウトを利用するために、PDPTEの7bit目は立てず、12~32+bitのレンジにPDのアドレスを設計する</li>
<li>PDEでは2MB pageを許可するため7bit目を立て、21~32+bitのレンジにPhysical Addressを設計する
<ul>
<li>Firecrackerでは、Level1 Page Tableを利用せず(= 4KiB pageを利用せず)、2MiB Pagingで実装しているようである。ToyVMMの実装もこれに倣う（2MiBページングは基本的に多くのCPUでサポートされている上、4KiBページングによるPage Tableの肥大化を伏せるためかと思われる）</li>
</ul>
</li>
</ul>
<p>さて、上記をもとに実際の実装部分のコードを抜粋する</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn setup_page_tables(sregs: &amp;mut kvm_sregs, mem: &amp;GuestMemoryMmap) -&gt; Result&lt;(), RegError&gt; {
    let boot_pml4_addr = GuestAddress(PML4_START);
    let boot_pdpte_addr = GuestAddress(PDPTE_START);
    let boot_pde_addr = GuestAddress(PDE_START);

    // Entry converting VA [0..512GB)
    mem.write_obj(boot_pdpte_addr.raw_value() as u64 | 0x03, boot_pml4_addr)
        .map_err(|_| RegError::WritePdpteAddress)?;
    // Entry covering VA [0..1GB)
    mem.write_obj(boot_pde_addr.raw_value() as u64 | 0x03, boot_pdpte_addr)
        .map_err(|_| RegError::WritePdpteAddress)?;
    // 512 MB entries together covering VA [0..1GB).
    // Note we are assuming CPU support 2MB pages (/proc/cpuinfo has 'pse').
    for i in 0..512 {
        mem.write_obj((i &lt;&lt; 21) + 0x83u64, boot_pde_addr.unchecked_add(i * 8))
            .map_err(|_| RegError::WritePdeAddress)?;
    }
    sregs.cr3 = boot_pml4_addr.raw_value() as u64;
    sregs.cr4 |= X86_CR4_PAE;
    sregs.cr0 |= X86_CR0_PG;
    Ok(())

}
<span class="boring">}
</span></code></pre></pre>
<p>見た通り実装はかなりシンプルである。<br />
<code>PML4_START</code>、<code>PDPTE_START</code>、<code>PDE_START</code>にはそれぞれアドレス値がハードコードされており、それぞれ<code>PML4_START=0x9000</code>、<code>PDPTE_START=0xa000</code>、<code>PDE_START=0xb000</code>となっていて、これは上記したそれぞれのアドレス設計の要求を満たしている。<br />
上記を見ると分かる通り、<code>PML4</code>及び<code>PDPT</code> Table自体は1つずつであり、Entryとしても最初のものしかセットアップしていない。これはこのページテーブルで変換されるカーネルのアドレスが、<code>0x0100_0000</code>であり、これを仮想アドレスとして扱った場合、詳しくは後述するが、<code>PML4</code>、<code>PDPT</code>は必ず最初のEntryを見ることになるためこの実装で十分である。<br />
PML4には、PDPTの先頭アドレス情報に0x03の論理和を取ったものを書き込み、PDPTにも同様にPDの先頭アドレス情報に0x03の論理和を取ったものを書き込む。
ここで0x03で論理和を取っている理由は、<code>PML4E</code>、<code>PDPTE</code>の0, 1bit目のフラグを立てるためであり、1bit目は共にR/W許可に関するフラグ、0bitは共に当該Entryの存在性に関してのフラグに該当するため今回のケースでは必須の処理である。<br />
PDは512 Entry分作成するためにループし、<strong>ループのindexの値を</strong>21bit shiftさせたものと0x83の論理和を取ったものを、PDの先頭アドレスから8byte毎(=1 Entry size毎）に書き込んでいる。<br />
ここで0x83で論理和を取っている理由は、前述しているR/W許可フラグ、存在性確認のフラグに加えて、2MBのpage frameとして扱うかどうかに関わるフラグを立てるためである。このフラグを立てることによって、21bit目からの値をアドレスとして取り扱う（図の「PDE 2MB page」のレイアウトを利用することになる）。したがって、<strong>上述したループで格納したindex値を21bitオフセット（2^21 = 2MB）させた値がそのまま変換後の物理アドレス値に対応するとになる</strong>ため、PDEとしてはindex=0のEntryは0を21bit offsetした値(= <code>0x0000_0000</code>)、index=1のEntryは1を21bit offsetした値(= <code>0x0010_0000</code>)というように変換されることになる。</p>
<p>さて、以降では上記で作成したPage Tableで、EIPに格納したkernelのアドレス（<code>0x0100_0000</code>）は正しく変換されるのか実際に計算して確かめてみよう！<br />
前述した通り、<code>x64 Long Mode</code>へ移行すると、このカーネルのアドレスは64bit仮想アドレスとして取り扱われることになる。今、ToyVMM（およびFirecracker）ではカーネルを物理アドレスの<code>0x0100_0000</code>に読み込んでおり、その値が<code>eip</code>レジスタに格納されている。
したがって、<code>0x0100_0000</code>を仮想アドレスとして扱い、上述した変換テーブルを用いてアドレス変換を行った結果、<code>0x0100_0000</code>になることを期待したい。</p>
<p>では具体的に計算してみよう。64bit仮想アドレスを4-Level Page Tableで変換する場合は以下の図の様に仮想アドレスの下位48bitを<code>9 + 9 + 9 + 9 + 12</code>bit毎に分割し、4つの9bitを先頭からそれぞれ各Page tableのEntryのindex値として利用する。この方法で特定したEntryのレイアウトを確認して、次のPage Tableの物理アドレスを確認し、同様にその物理アドレスと仮想アドレスから得たEntryのindex値を元に次のPage Tableの対象のEntryを割り出す。これを続けると最終的に目的の物理アドレスを得ることができる。Pageは少なくとも4KB毎のサイズになっているため、アドレス値としても4KB毎の値になるため、仮想アドレスの最後の12bitはそのオフセット(<code>2^12 = 4KB</code>)として利用される。</p>
<img src="./02_figs/4-level-page-table_and_address_translation.svg" width="100%">
<p>今回はPDEで2MB page frameとして取り扱うフラグを立てていることを思い出してほしい。この場合はPDEから得られる結果をそのまま物理アドレスへのマッピングとして利用する。この時使われないPTEの9bit分はオフセットとして取り扱われ、元々の12bitと合わせて合計21bit分のoffsetを加えることになる。この21bitオフセットが2MBに対応していることになる。同様にPDPTEでフラグを立てていると1GB page frameとして扱われるという仕組みになっている。</p>
<p>上記の話をもとに、<code>0x0100_0000</code>を変換してみる。この値はわかりやすさのためにbitで表現すると<code>0b0..._0000_0001_0000_0000_0000_0000_0000_0000</code>である。これを仮想アドレス変換の方式に倣いbitを分解すると、以下の通りになる。</p>
<table><thead><tr><th>Entry index for</th><th>Range of Virtual Address</th><th>Value</th></tr></thead><tbody>
<tr><td>Page Map Level4 (PML4)</td><td>47 ~ 39 bit</td><td><code>0b0_0000_0000</code></td></tr>
<tr><td>Page Directory Pointer Table (PTPT)</td><td>38 ~ 30 bit</td><td><code>0b0_0000_0000</code></td></tr>
<tr><td>Page Directory Table (PDT)</td><td>29 ~ 21 bit</td><td><code>0b0_0000_1000</code></td></tr>
<tr><td>Page Tables (PT)</td><td>20 ~ 12 bit</td><td><code>0b0_0000_0000</code></td></tr>
<tr><td>-</td><td>11 ~ 0  bit (offset)</td><td><code>0b0_0000_0000</code></td></tr>
</tbody></table>
<p>これを見ると分かる通り、<code>PML4E</code>、<code>PDPTE</code>用のindex値は<code>0</code>になるため、それぞれのTableの先頭アドレスから64bit確認することになる。
実装で確認した通り、index=0の<code>PML4E</code>には<code>PDPT</code>のアドレスが書かれており、index=0の<code>PDPTE</code>にはPDTのアドレスが書かれているため、<code>PDT</code>までは順当に辿り着く。
さて、今回PDEのIndex値は上記の仮想メモリアドレスから<code>0b0_0000_1000</code>なので<code>PDT</code>の中で8番目のEntryを確認することになるが、当該Entryの2MB Page frameの領域に書かれている値は実装から<code>0b0...0000_1000</code>であることが分かる。
したがって、この値に21bit offsetを加えた値である<code>0b1_0000_0000_0000_0000_0000_0000 = 0x100_0000</code>が変換により得られる物理アドレスであり、これは入力した仮想アドレスと一致している。
したがって、変換後もカーネルのエントリーポイントを指すことになり、64-bit long modeにシフトしてもカーネルを起動から処理が開始されることになる</p>
<img src="./02_figs/virt_phys_address_translation_example.svg" width="100%">
<p><strong>Note</strong><br />
今回作成したPage Tableを再考してみると、PML4、PDPT用のEntryは1つしか作っていないので、そもそも対象となる仮想メモリアドレス範囲はMaxでも<code>2^31 - 1</code>までの範囲になる(この領域を超える場合、PML4E、PDPTEとしてindexが0以外を指す場合が存在してしまう)
加えて、PDのEntryでは2MB page frameを有効化しているため、仮想メモリアドレスの下位21bitはOffsetとして取り扱われる。
その上で、PDEのアドレス設計をindexに対応付けているため、このPage Tableは <strong><code>2^21 ~ 2^30-1</code>の範囲でIdentity Mapping</strong> になっている。</p>
<h2 id="what-to-do-next"><a class="header" href="#what-to-do-next">What to do next?</a></h2>
<p>実はここまでの話を組み合わせるだけで、Guest VMを起動すること自体は可能である。<br />
しかし、この状態ではGuest VMは起動できてもそれを操作することはできないという何とも片手落ちな状態になってしまう。<br />
起動したGuest VMが我々の想定した通りの設定になっているかなどを確認するためにも、Guest VMを操作するようなインターフェイスを作りたいところである。<br />
次の章ではこれを達成するために<code>Serial</code>について議論し、ToyVMMの中に実装することでGuest VMを起動後にキーボード操作できるようにする！</p>
<h2 id="references-3"><a class="header" href="#references-3">References</a></h2>
<ul>
<li><a href="https://docs.kernel.org/x86/boot.html#id1">The Linux/x86 Boot Protocol - 64-bit Boot Protocol</a></li>
<li><a href="https://postd.cc/linux-bootstrap-4/">Linux Insides: カーネル起動プロセス part4</a></li>
<li><a href="https://wiki.osdev.org/Interrupt_Descriptor_Table">Global Descriptor Table (wiki)</a></li>
<li><a href="https://wiki.osdev.org/Interrupt_Descriptor_Table">Interrupt Descriptor Tabke (wiki)</a></li>
<li><a href="https://wiki.osdev.org/Segmentation">Segmentation (wiki)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Control_register#CR3">Control register (wiki)</a></li>
<li><a href="https://wiki.osdev.org/Segmentation">Long mode (wiki)</a></li>
<li><a href="https://alessandropellegrini.it/didattica/2017/aosv/1.Initial-Boot-Sequence.pdf">x86 initial boot sequence</a></li>
<li><a href="https://back.engineering/23/08/2020/">Virtual Memory - Intro to Paging Tables</a></li>
<li><a href="https://os.phil-opp.com/paging-introduction/">Writing an OS in Rust - Introduction to Paging</a></li>
<li><a href="https://www.intel.com/content/dam/support/us/en/documents/processors/pentium4/sb/25366821.pdf">Intel 64 and IA-32 Architectures Software Developer's Manual</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="serial-console-implementation"><a class="header" href="#serial-console-implementation">Serial Console implementation</a></h1>
<h2 id="about-serial-uart-and-ttys0"><a class="header" href="#about-serial-uart-and-ttys0">About Serial UART and ttyS0</a></h2>
<p>UART（Universal Asynchronous Receiver/Transmitter）はコンピュータやマイコンと周辺機器を繋ぐ非同期式シリアル通信規格である。
UARTによってシリアル・パラレル信号の相互変換を行えるため、入力されるパラレルデータをシリアルデータへ変換し通信回線越しに相手に送信することができる。
これを実装するために設計された集積回路として8250 UARTと呼ばれるデバイスが製造され、その後さまざまなファミリが登場してきた。</p>
<p>さて、今回Guest OS（Linux）を起動させようとしているわけであるが、デバッグ等の用途としてシリアルコンソールが存在すると便利なケースが多い。<br />
シリアルコンソールはGuestの全てのコンソール出力をシリアルポートに送付するため、シリアルターミナルが適切に設定されていればリモートターミナルとしてシステムの起動状況を確認したり、シリアルポート経由でシステムにログオンしたりすることができる。<br />
今回は、ToyVMM上で起動したGuest VMの状態確認やGuestの操作をするためにこの方式を利用することにする。</p>
<p>コンソールメッセージをシリアルポートに出力させるために、カーネルの起動時パラメータとして<code>console=ttyS0</code>を設定する必要がある。<br />
現在のToyVMMの実装ではこの値をデフォルト値として与えている。</p>
<p>問題はこれを受け取るシリアルターミナル側である。
シリアルポートに該当するIO Portのアドレスは決まっているため、ToyVMMのレイヤからは当該アドレス付近に対して<code>KVM_EXIT_IO</code>の命令を受けることになる。
つまりGuest OS側から発行されるシリアルコンソールへの出力情報、またそれ以外にも必要なセットアップ要求などを適切に処理する必要があり、これはUARTデバイスをエミュレートすることで成立させる必要がある。
その上で、デバイスをエミュレートした結果として、標準出力に対してコンソール出力を出力したり、逆に我々の標準入力をGuest VM側に反映させることができれば、ToyVMMからVMを起動した際に、その起動情報の確認やGuestの操作を手元のターミナルから実施することが可能になる。</p>
<p>以上をまとめると、大まかに下記のような概念図のものを作成することになる。</p>
<img src="./02_figs/overview_serial_device.svg" width="100%">
<p>以降では順を追って説明していく。</p>
<h2 id="serial-uart"><a class="header" href="#serial-uart">Serial UART</a></h2>
<p>Serial UARTについては、以下のLammet Biesの資料とWikibooksに大変詳細な情報が記載されているため基本的にはこれを確認すれば良い。</p>
<ul>
<li><a href="https://www.lammertbies.nl/comm/info/serial-uart">Serial UART information (Lammet Bies)</a></li>
<li><a href="https://en.wikibooks.org/wiki/Serial_Programming/8250_UART_Programming">Serial Programming / 8250 UART Programming (Wikibooks)</a></li>
</ul>
<p>以下の図は、<a href="https://www.lammertbies.nl/comm/info/serial-uart">Lammetの資料に記載のある図</a>を引用しつつそれぞれのRegisterの各bitに関して簡単に説明を加えた図である。本資料の執筆において個人的に作成した図であるが、読者の理解の手助けになることを期待して添付しておく。
ただし、それぞれのregisterやbitの意味については本資料では説明はしないため、上記の資料を参考に確認してもらいたい。</p>
<img src="./02_figs/serial_uart_registers.svg" width="100%">
<p>基本的には上記のregisters/bitsを操作することで必要な処理を行うのがUARTの仕組みになっている。<br />
今回はこれをSoftwareでエミュレートする必要があるが、この実装に関しては <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>を利用することで代替とする。<br />
以降でこの <a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a> の実装と上記のSpecificationとを比較しながら簡単にではあるが確認していこうと思う。</p>
<h2 id="rust-vmmvm-superioによるserial-deviceのsoftware実装"><a class="header" href="#rust-vmmvm-superioによるserial-deviceのsoftware実装">rust-vmm/vm-superioによるSerial DeviceのSoftware実装</a></h2>
<h3 id="初期値設定rwの実装"><a class="header" href="#初期値設定rwの実装">初期値設定／RWの実装</a></h3>
<p>ここからは<a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>を利用したserial deviceの実装を、上記のSpecificationと比較しながら確認していく。
是非、上記からコードを取得して自分で確認してみてほしい。
なお、以下の内容は <code>vm-superio-0.6.0</code> に準拠しているので、最新のコードでは変更されているかもしれないため留意されたい。</p>
<p>まず、いくつかの値の初期値について以下の通りに整理する。<br />
<a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>はもともとVMMでの利用を前提にしているため、いくつかのレジスタの値を初期設定していたり、書き換え想定をしていなかったりする。</p>
<table><thead><tr><th>Variable</th><th>DEFAULT VALUE</th><th>Meaning</th><th>REGISTER</th></tr></thead><tbody>
<tr><td>baud_divisor_low</td><td>0x0c</td><td>baud rate 9600 bps</td><td></td></tr>
<tr><td>baud_divisor_high</td><td>0x00</td><td>baud rate 9600 bps</td><td></td></tr>
<tr><td>interrupt_enable</td><td>0x00</td><td>No interrupts enabled</td><td>IER</td></tr>
<tr><td>interrupt_identification</td><td>0b0000_0001</td><td>No pending interrupt</td><td>IIR</td></tr>
<tr><td>line_control</td><td>0b0000_0011</td><td>8 bit word length</td><td>LCR</td></tr>
<tr><td>line_status</td><td>0b0110_0000</td><td>(1)</td><td>LSR</td></tr>
<tr><td>modem_control</td><td>0b0000_1000</td><td>(2)</td><td>MCR</td></tr>
<tr><td>modem_status</td><td>0b1011_0000</td><td>(3)</td><td>MSR</td></tr>
<tr><td>scratch</td><td>0b0000_0000</td><td></td><td>SCR</td></tr>
<tr><td>in_buffer</td><td>Vec::new()</td><td>vector values (buffer)</td><td>-</td></tr>
</tbody></table>
<ol>
<li>THR empty関係のbitを立てている。このbitを立てているといつでもデータを受信可能であることを表現していることになるが、これは仮想デバイスとしての利用が前提の設定になっている。</li>
<li>多くのUARTはAuxiliary Output 2の値を1に設定し、interruptを有効にするたデフォルトで有効にしている</li>
<li>Connectedの状態、かつハードウェアデータフローの初期化</li>
</ol>
<p>さて、次にwriteのリクエストが来た場合の処理内容について簡単に記載する。
<code>KVM_EXIT_IO</code>の結果として、IOが発生したaddressと、書き込むべきデータが渡される。
ToyVMM側ではこれらの値から適切なデバイス（今回はSerial UART device）とそのベースアドレスからのOffsetを計算し、<code>vm-superio</code>で定義されている<code>write</code>関数を呼び出す。
以下の内容は、<code>Serial::write</code>の処理を簡単に表に起こしたものである。基本的には素直にレジスタ値の書き換えになるが一部ちょっとロジックが入る。</p>
<table><thead><tr><th>Variable</th><th>OFFSET(u8)</th><th>Additional Conditions</th><th>write</th></tr></thead><tbody>
<tr><td>DLAB_LOW_OFFSET</td><td>0</td><td>is_dlab_set = true</td><td><code>self.baud_divisor_low</code>を書き換え</td></tr>
<tr><td>DLAB_HIGH_OFFSET</td><td>1</td><td>is_dlab_set = true</td><td><code>self.baud_divisor_high</code>を書き換え</td></tr>
<tr><td>DATA_OFFSET</td><td>0</td><td>- (is_dlab_set = false)</td><td>(1)</td></tr>
<tr><td>IER_OFFSET</td><td>1</td><td>- (is_dlab_set = false)</td><td>(2)</td></tr>
<tr><td>LCR_OFFSET</td><td>3</td><td>-</td><td><code>self.line_control</code>を書き換え</td></tr>
<tr><td>MCR_OFFSET</td><td>4</td><td>-</td><td><code>self.modem_control</code>を書き換え</td></tr>
<tr><td>SCR_OFFSET</td><td>7</td><td>-</td><td><code>self.scratch</code>を書き換え</td></tr>
</tbody></table>
<ol>
<li>現在のSerialの状態として、LOOP_BACK_MODE（MCR bit 4）が有効になっている場合とそうでない場合で場合分け
<ul>
<li>有効の場合、送信レジスタに書かれたものをそのまま受信レジスタに書き込まれる(loopbackする）ようにシミュレート（今回は重要ではない）</li>
<li>有効でない場合、書き込むべきデータをそのまま出力に書き出し、既存の設定状態に依存して割り込みを入れる。
<ul>
<li>上記の表をみてわかる通り、外部からのwriteによるIIRの変更はサポートしておらず、デフォルト値が<code>0b0000_0001</code>で設定されている。</li>
<li>もし、IER_OFFSETに対してIERのTHR empty bitのフラグが立っている場合は、IIRのTHR emptyに対応するフラグを立てて割り込みをトリガする。</li>
</ul>
</li>
</ul>
</li>
<li>IERのbitのうち0-3bit以外はMaskした結果（Interruptに関連するbitのみそのままにして）で <code>self.interrupt_enable</code>を書き換え</li>
</ol>
<p>次に、readのリクエストが来た場合の処理内容について簡単に記載する<br />
同様に <code>Serial::read</code>の処理を表に起こしたものが下記である。readの場合はwriteと異なり基本的には返り値としてデータを返すロジックになっている</p>
<table><thead><tr><th>Variable</th><th>OFFSET(u8)</th><th>Additional Conditions</th><th>write</th></tr></thead><tbody>
<tr><td>DLAB_LOW_OFFSET</td><td>0</td><td>is_dlab_set = true</td><td><code>self.baud_divisor_low</code>を読み込み</td></tr>
<tr><td>DLAB_HIGH_OFFSET</td><td>1</td><td>is_dlab_set = true</td><td><code>self.baud_divisor_high</code>を読み込み</td></tr>
<tr><td>DATA_OFFSET</td><td>0</td><td>- (is_dlab_set = false)</td><td>(1)</td></tr>
<tr><td>IER_OFFSET</td><td>1</td><td>- (is_dlab_set = false)</td><td><code>self.inerrupt_enable</code>を読み込み</td></tr>
<tr><td>IIR_OFFSET</td><td>2</td><td>-</td><td>(2)</td></tr>
<tr><td>LCR_OFFSET</td><td>3</td><td>-</td><td><code>self.line_control</code>を読み込み</td></tr>
<tr><td>MCR_OFFSET</td><td>4</td><td>-</td><td><code>self.modem_control</code>を読み込み</td></tr>
<tr><td>LSR_OFFSET</td><td>5</td><td>-</td><td><code>self.line_status</code>を読み込み</td></tr>
<tr><td>MSR_OFFSET</td><td>6</td><td>-</td><td>(3)</td></tr>
<tr><td>SCR_OFFSET</td><td>7</td><td>-</td><td><code>self.scratch</code>を読み込み</td></tr>
</tbody></table>
<ol>
<li>Serial構造体が持つbufferのデータを読み出したりするが、現実装ではこのbufferはloopback modeでのwriteでしかデータが積まれない実装になっているため、今回の内容では省略。OSの起動シーケンスでもこの領域に関する<code>read</code>は発行されていなかった。</li>
<li><code>self.interrupt_identification</code> | <code>0b1100_0000(FIFO enabled)</code>の結果を返却しデフォルト値に戻す</li>
<li>現在の状態がloopback modeかどうかで場合分けを行う
<ul>
<li>loopbackの場合は適切に調整する（今回は重要ではないので省略）</li>
<li>loopbackで無い場合は素直に<code>self.modem_status</code>の値を返却する</li>
</ul>
</li>
</ol>
<h2 id="toyvmmでのrust-vmmvm-superioの利用"><a class="header" href="#toyvmmでのrust-vmmvm-superioの利用">ToyVMMでのrust-vmm/vm-superioの利用</a></h2>
<p>ToyVMMでは上記の<a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>を利用し<code>KVM_EXIT_IO</code>の内容をハンドルする。
加えて考えなければならないのは以下の2点である。</p>
<ul>
<li>Guestからシリアルポートに当てたコンソール出力を標準出力に書き出すことで、起動シーケンスやGuest内部の状態を確認できるようにする。</li>
<li>標準入力の内容をGuest VMに引き渡す</li>
</ul>
<p>以降、それぞれ順番に確認していく。　</p>
<h3 id="シリアルポート当てのコンソール出力を標準出力に書き出す"><a class="header" href="#シリアルポート当てのコンソール出力を標準出力に書き出す">シリアルポート当てのコンソール出力を標準出力に書き出す</a></h3>
<p>起動シーケンスやGuest VMの内部状態を確認するために、シリアルポート宛のコンソール出力を標準出力に書き出すようにしてみよう。<br />
「シリアルポート当てのコンソール出力」はまさに、<code>KVM_EXIT_IO</code>で<code>Serial向けのIO Portアドレス</code>に対しての<code>KVM_EXIT_IO_OUT</code>のケースに該当する。
以下のコード部が該当処理になる。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>...
loop {
  match vcpu.run() {
      Ok(run) =&gt; match run {
          ...
          VcpuExit::IoOut(addr, data) =&gt; {
              io_bus.write(addr as u64, data);
          }
      ...  
      }
    }
}
...
<span class="boring">}
</span></code></pre></pre>
<p>さて、ここでは<code>KVM_EXIT_IO_OUT</code>で受け取ったアドレスと書き込むべきデータを伴って、<code>io_bus.write</code>を呼び出すのみになっている。
この<code>io_bus</code>は以下のような形で設定を行ったものである。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut io_bus = IoBus::new();
let com_evt_1_3 = EventFdTrigger::new(EventFd::new(libc::EFD_NONBLOCK).unwrap());
let stdio_serial = Arc::new(Mutex::new(SerialDevice {
    serial: serial::Serial::with_events(
        com_evt_1_3.try_clone().unwrap(),
        SerialEventsWrapper {
            buffer_read_event_fd: None,
        },
        Box::new(std::io::stdout()),
    ),
}));
io_bus.insert(stdio_serial.clone(), 0x3f8, 0x8).unwrap();
vm.fd().register_irqfd(&amp;com_evt_1_3, 4).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>上記のセットアップについては少し説明が必要なため以降に順を追って話していくが、大まかに押さえておくと以下のようなことをおこなっている。</p>
<ul>
<li>I/O Busを表現している<code>IoBus</code>構造体、割り込みを表現する<code>eventfd</code>を初期化する。</li>
<li>Serial Deviceの初期化をおこなう。その際にGuestへ割り込みを発生させるための<code>eventfd</code>と標準出力のためのFD（<code>std::io::stdout</code>）を渡している。</li>
<li>初期化した<code>IoBus</code>に上記のSerial Deviceを登録している。この時、<code>0x3f8</code>をベースアドレス、<code>0x8</code>をレンジとして登録している。
<ul>
<li>これにより、<code>0x3f8</code>を基底として<code>0x8</code>のレンジはこのSerial Deviceが利用するアドレス領域ということを表現している。</li>
</ul>
</li>
</ul>
<h4 id="io-busの取り回し"><a class="header" href="#io-busの取り回し">I/O Busの取り回し</a></h4>
<p><code>KVM_EXIT_IO</code>で渡されるアドレス値は、アドレス空間全体におけるアドレスの値になる。<br />
一方で、<a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>の<code>read/write</code>の実装は、Serial Deviceのベースアドレスからのオフセット値をとって処理を実施するような実装になっているため、このギャップを埋めるための処理が必要になる。<br />
単純にオフセットを計算するだけでも良いが、Firecrackerではその後の拡張性（Serialデバイス以外のIO Portを利用するデバイス）も考慮してか、I/O Busを表現する構造体である<code>Bus</code>という構造体が存在する。
これは<code>BusRange</code>（バスにおけるデバイスのベースアドレスと利用するアドレスレンジを表現している構造体）とともにデバイスを登録できるようなものになっている。<br />
さらに、あるアドレスへのIOが発生しときに、そのアドレスを確認し、対応するアドレスレンジに登録されているデバイスを取り出して、そのデバイスに対して、ベースアドレスからのオフセット値でIOを実行するような仕組みが提供されている。
例えば<code>write</code>関数は以下のような実装になっており、<code>get_device</code>でアドレス情報から対応する登録済みデバイスと、そのデバイスのベースアドレスからのオフセットを取得し、それを利用してデバイスに実装されている<code>write</code>関数を呼び出している。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn write(&amp;self, addr: u64, data: &amp;[u8]) -&gt; bool {
    if let Some((offset, dev)) = self.get_device(addr) { : u64 : &amp;Mutex&lt;dyn BusDevice&gt;
        // OK to unwrap as lock() failing is a serious error condition and should panic.
        dev.lock() Result&lt;MutexGuard&lt;dyn BusDevice&gt;, …&gt;
            .expect(&quot;Failed to acquire device lock&quot;) MutexGuard&lt;dyn BusDevice&gt; msg:
            .write(offset, data);
        true
    } else {
        false
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>具体的にSerialデバイスの話を例に挙げて考えてみる。
前述した通りGuest VMからのserialに対する<code>KVM_EXIT_IO_OUT</code>は<code>0x3f8</code>をベースとして8 byteのアドレスレンジで発生する。
ToyVMMのIoBusでも同様のアドレスベース、レンジ情報でSerial Deviceの登録をしているため、例えば<code>KVM_EXIT_IO_OUT</code>として<code>0x3fb</code>へ<code>0b1001_0011</code>を書き込むという命令をトラップした場合、登録したSerial Deviceに対して、ベースアドレス(<code>0x3f8</code>)からのオフセット(<code>0x3</code>)の位置、つまり<code>LCR</code>に<code>0b1001_0011</code>を書く、という命令に解釈される。</p>
<h4 id="eventfdirqfdによるguest-vmへの割り込み通知"><a class="header" href="#eventfdirqfdによるguest-vmへの割り込み通知">eventfd/irqfdによるGuest VMへの割り込み通知</a></h4>
<p>ここからは少しKVMと割り込みに関する話をしたい。
いくつかLinuxのソースコードを引用することになるが以降では<code>v4.18</code>のコードから引用する。</p>
<p>:warning: 以降の話は基本的にソースコードを元に記載しているが、詳細な状態遷移を逐一確認して記載したものではないため多少間違っている可能性があります。もし間違いを発見した場合はコメントをいただけると幸いです。</p>
<p><a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>では、Serialの初期化時に第一引数に<a href="https://docs.rs/vmm-sys-util/0.6.1/vmm_sys_util/eventfd/struct.EventFd.html"><code>EventFd</code></a>を要求する。<br />
これはLinuxにおける<a href="https://man7.org/linux/man-pages/man2/eventfd.2.html">eventfd</a>のWrapperになっているものである。
eventfdの詳細は<a href="https://man7.org/linux/man-pages/man2/eventfd.2.html">man</a>を確認してほしいが、簡単にいうとプロセス間やプロセスとカーネルの間などでのイベントの通知を実現することができる仕組みである。</p>
<p>次にirqfdである。irqfdはeventfdをベースとしたVMに対して割り込みを入れることのできるfile descriptorである。
イメージとしてはeventfdの一端をKVMが保持し、もう片方からの通知をGuest VMへの割り込みとして解釈するというものである。
このirqfdによる割り込みは、Guest VMの外の世界からGuest VMへの割り込み、つまり通常のシステムで言うところの周辺デバイスからの割り込みをエミュレートするものである。逆方向の割り込みは<code>ioeventfd</code>の仕組みを利用するがここでは一旦省略する。</p>
<p>実際にソースコードを見ながら、このirqfdがどのようにGuestへの割り込みにつながっていくかを確認してみよう。<br />
KVMに対して<code>KVM_IRQFD</code>を伴ってioctlを実施すると、渡されたデータを元に<code>kvm_irqfd</code>、<code>kvm_irqfd_assign</code>の流れでKVMの処理が実行され、この<code>kvm_irqfd_assign</code>関数で<code>kvm_kernel_irqfd</code>構造体のインスタンスが作成される。<br />
この時、ioctl時に渡した追加情報を元に設定を行うが、特に<code>kvm_kernel_irqfd</code>構造体は<code>gsi</code>というフィールドを持っており、これがioctlで渡した引数の値によって設定される。<br />
この<code>gsi</code>は、<code>irqfd</code>に対応するGuestの割り込みテーブルのインデックスに該当するものになるため、ioctlを呼ぶ際にはeventfdに加えて、Guestのどの割り込みテーブルのエントリに対して割り込みを入れるかということも指定する。
ToyVMMではこの設定を行なっているのが以下の一行である。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>vm.fd().register_irqfd(&amp;com_evt_1_3, 4).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>これは<code>kvm_ioctl::VmFd</code>構造体のメソッドとして定義されている</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn register_irqfd(&amp;self, fd: &amp;EventFd, gsi: u32) -&gt; Result&lt;()&gt; {
    let irqfd = kvm_irqfd {
        fd: fd.as_raw_fd() as u32,
        gsi,
        ..Default::default()
    };
    // Safe because we know that our file is a VM fd, we know the kernel will only read      the
    // correct amount of memory from our pointer, and we verify the return result.
    let ret = unsafe { ioctl_with_ref(self, KVM_IRQFD(), &amp;irqfd) }; : i32 fd: req: arg:
    if ret == 0 {
        Ok(())
    } else {
        Err(errno::Error::last())
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>つまり上記では、これまで話してきたSerial deviceに利用しているeventfd（<code>com_evt_1_3</code>）をGSI=4（Guest VM上のCOM1ポートへの割り込みテーブルインデックス）を伴って設定しているため、この<code>com_evt_1_3</code>に対して実行した<code>write</code>は、COM1からの割り込みとしてGuest VMに渡り（つまり、Guestから見るとCOM1の先のserial deviceから割り込みが発生したことになり）、Guest VMのCOM1の割り込みハンドラを起動することになる。</p>
<p>さて、今Guest側の割り込みテーブル（GSI: Global System Interrupt）の話が出たが、これらはいつ、どのようにセットアップされるかいついて以降で説明していくこととする。<br />
端的に言えばこれらは<code>KVM_CREATE_IRQCHIP</code>を伴ってKVMにioctlを発行することで設定される。これを実施すると割り込みコントローラである<code>PIC</code>と<code>IOAPIC</code>の２種類が作成される（内部的には<code>kvm_pic_init</code>でPICの初期化とread/write opsの登録などを行い、<code>kvm-&gt;arch.vpic</code>に設定。<code>kvm_ioapic_init</code>でIOAPICの初期化とread/write opsの登録などを行い、<code>kvm-&gt;arch.vioapic</code>に設定している）<br />
この<code>PIC</code>や<code>IOAPIC</code>などのハードウェアは高速化の目的でKVMに実装があるため、独自にエミュレートする必要がない。もちろんqemuなどに任せることができるが、ここでは利用しないため省略する。
さらにその後、<code>kvm_setup_default_irq_routing</code>関数の中でデフォルトのIRQ Routingの設定がなされている。
この処理によって、どのGSIに対する割り込みによってどのハンドラが起動するか、という部分がセットアップされる。</p>
<p>さて、もう少し<code>kvm_setup_default_irq_routing</code>の中身を見てみよう。この関数の中ではさらに<code>kvm_set_irq_routing</code>関数を呼びだしており、本質的な処理はそこに記載がある。
ここでは<code>kvm_irq_routing_table</code>を作成し、これに対してGSIからIRQへの対応を表現している<code>kvm_kernel_irq_routing_entry</code>を設定していく形になる。
この<code>kvm_kernel_irq_routing_entry</code>はデフォルトのエントリ（<code>default_routing</code>）が存在しており、これをループしながら登録していくような形の実装が存在する。
この<code>default_routing</code>は以下のような定義になっている。関係するマクロの実装も記しておく。</p>
<pre><code class="language-C">#define SELECT_PIC(irq) \
	((irq) &lt; 8 ? KVM_IRQCHIP_PIC_MASTER : KVM_IRQCHIP_PIC_SLAVE)

#define IOAPIC_ROUTING_ENTRY(irq) \
	{ .gsi = irq, .type = KVM_IRQ_ROUTING_IRQCHIP,	\
	  .u.irqchip = { .irqchip = KVM_IRQCHIP_IOAPIC, .pin = (irq) } }

#define ROUTING_ENTRY1(irq) IOAPIC_ROUTING_ENTRY(irq)

#define PIC_ROUTING_ENTRY(irq) \
	{ .gsi = irq, .type = KVM_IRQ_ROUTING_IRQCHIP,	\
	  .u.irqchip = { .irqchip = SELECT_PIC(irq), .pin = (irq) % 8 } }

#define ROUTING_ENTRY2(irq) \
	IOAPIC_ROUTING_ENTRY(irq), PIC_ROUTING_ENTRY(irq)

static const struct kvm_irq_routing_entry default_routing[] = {
	ROUTING_ENTRY2(0), ROUTING_ENTRY2(1),
	ROUTING_ENTRY2(2), ROUTING_ENTRY2(3),
	ROUTING_ENTRY2(4), ROUTING_ENTRY2(5),
	ROUTING_ENTRY2(6), ROUTING_ENTRY2(7),
	ROUTING_ENTRY2(8), ROUTING_ENTRY2(9),
	ROUTING_ENTRY2(10), ROUTING_ENTRY2(11),
	ROUTING_ENTRY2(12), ROUTING_ENTRY2(13),
	ROUTING_ENTRY2(14), ROUTING_ENTRY2(15),
	ROUTING_ENTRY1(16), ROUTING_ENTRY1(17),
	ROUTING_ENTRY1(18), ROUTING_ENTRY1(19),
	ROUTING_ENTRY1(20), ROUTING_ENTRY1(21),
	ROUTING_ENTRY1(22), ROUTING_ENTRY1(23),
};
</code></pre>
<p>見ての通り、0-15までのIRQ番号は<code>ROUTING_ENTRY2</code>に、16-23までのをIRQ番号は<code>ROUTING_ENTRY1</code>に引き渡しており、<code>ROUTING_ENTRY2</code>は<code>IOAPIC_ROUTING_ENTRY</code>と<code>PIC_ROUTING_ENTRY</code>を、<code>ROUTING_ENTRY1</code>は<code>IOAPIC_ROUTING_ENTRY</code>のみを呼び出して、必要な情報を埋めた構造体を作っている。</p>
<p>この構造体の情報を使いながら後続する<code>kvm_set_routing_entry</code>関数で以下の通りそれぞれの<code>.u.irqchip.irqchip</code>の値(<code>KVM_IRQCHIP_PIC_SLAVE</code>、<code>KVM_IRQCHIP_PIC_MASTER</code>、<code>KVM_IRQCHIP_IOAPIC</code>)ごとにコールバック（<code>kvm_set_pic_irq</code>、<code>kvm_set_ioapic_irq</code>）や必要な設定をおこなっている。このコールバックは割り込み発生時に呼ばれる関数に該当し、後ほど触れるため少し覚えておいてほしい。</p>
<pre><code class="language-C">int kvm_set_routing_entry(struct kvm *kvm,
			  struct kvm_kernel_irq_routing_entry *e,
			  const struct kvm_irq_routing_entry *ue)
{
	/* We can't check irqchip_in_kernel() here as some callers are
	 * currently inititalizing the irqchip. Other callers should therefore
	 * check kvm_arch_can_set_irq_routing() before calling this function.
	 */
	switch (ue-&gt;type) {
	case KVM_IRQ_ROUTING_IRQCHIP:
		if (irqchip_split(kvm))
			return -EINVAL;
		e-&gt;irqchip.pin = ue-&gt;u.irqchip.pin;
		switch (ue-&gt;u.irqchip.irqchip) {
		case KVM_IRQCHIP_PIC_SLAVE:
			e-&gt;irqchip.pin += PIC_NUM_PINS / 2;
			/* fall through */
		case KVM_IRQCHIP_PIC_MASTER:
			if (ue-&gt;u.irqchip.pin &gt;= PIC_NUM_PINS / 2)
				return -EINVAL;
			e-&gt;set = kvm_set_pic_irq;
			break;
		case KVM_IRQCHIP_IOAPIC:
			if (ue-&gt;u.irqchip.pin &gt;= KVM_IOAPIC_NUM_PINS)
				return -EINVAL;
			e-&gt;set = kvm_set_ioapic_irq;
			break;
		default:
			return -EINVAL;
		}
		e-&gt;irqchip.irqchip = ue-&gt;u.irqchip.irqchip;
		break;
...
</code></pre>
<p>さて、ここまで見てきたところで再度<code>irqfd</code>の話に立ち戻ろう。
先ほどは説明していなかったが、実は<code>kvm_irqfd_assign</code>関数の中では、<code>init_waitqueue_func_entry(&amp;irqfd-&gt;wait, irqfd_wakeup)</code>という処理が呼び出され、<code>&amp;irqfd-&gt;wait-&gt;func</code>に<code>irqfd_wakeup</code>を登録している。
割り込みが発生した際にこの関数が呼び出され、この中で<code>schedule_work(&amp;irqfd-&gt;inject)</code>が呼ばれる。
この<code>inject</code>フィールドも<code>kvm_irqfd_assign</code>関数の中で初期化されており、結果として<code>irqfd_inject</code>関数が呼び出されることになり、さらにこの関数の中で<code>kvm_set_irq</code>関数が呼び出される。<br />
<code>kvm_set_irq</code>の処理の中では、割り込みがきたIRQ番号を持つエントリをリストアップし、その<code>set</code>コールバックを呼び出していく。これはつまり上記で説明した<code>kvm_set_pic_irq</code>や<code>kvm_set_ioapic_irq</code>などの関数が呼ばれることを意味する。
以上の流れが割り込みとGSI、IRQ間Routingの実際の処理の部分である。</p>
<img src="./02_figs/kvm_irq_gsi_routing.svg" width="100%">
<p>ここからの話は割り込み処理に対してもう少し深掘りした内容になるが、ToyVMMを理解する上で必ずしも必要ではない内容なので、<a href="02-5_serial_console_implementation.html#toyvmm-serial-console">ToyVMM serial console</a>まで読み飛ばしてもらっても構わない。</p>
<p>折角なので、割り込みハンドラである<code>kvm_set_pic_irq</code>の処理についてもう少し見てみることにしよう。やや話が脱線してきたが、せっかくなのでキリのいいところまで深掘りして確認してみる。<br />
<code>kvm_set_pic_irq</code>は、<code>KVM_CREATE_IRQCHIP</code>で初期化した<code>kvm-&gt;arch.vpic</code>を利用して、<code>kvm_pic_set_irq</code>を呼び出しているのみである。</p>
<pre><code class="language-C">static int kvm_set_pic_irq(struct kvm_kernel_irq_routing_entry *e,
			   struct kvm *kvm, int irq_source_id, int level,
			   bool line_status)
{
	struct kvm_pic *pic = kvm-&gt;arch.vpic;
	return kvm_pic_set_irq(pic, e-&gt;irqchip.pin, irq_source_id, level);
}
</code></pre>
<p>さて、<code>kvm_pic_set_irq</code>の実装を見にいくと以下のようになっている。</p>
<pre><code class="language-C">int kvm_pic_set_irq(struct kvm_pic *s, int irq, int irq_source_id, int level)
{
	int ret, irq_level;

	BUG_ON(irq &lt; 0 || irq &gt;= PIC_NUM_PINS);

	pic_lock(s);
	irq_level = __kvm_irq_line_state(&amp;s-&gt;irq_states[irq],
					 irq_source_id, level);
	ret = pic_set_irq1(&amp;s-&gt;pics[irq &gt;&gt; 3], irq &amp; 7, irq_level);
	pic_update_irq(s);
	trace_kvm_pic_set_irq(irq &gt;&gt; 3, irq &amp; 7, s-&gt;pics[irq &gt;&gt; 3].elcr,
			      s-&gt;pics[irq &gt;&gt; 3].imr, ret == 0);
	pic_unlock(s);

	return ret;
}
</code></pre>
<p><code>pic_set_irq1</code>関数でIRQ Levelの設定を行い、<code>pic_update_irq</code>関数で<code>kvm-&gt;arch.vpic</code>に格納されている<code>kvm_pic</code>構造体の中を以下のように書き換えている。</p>
<pre><code class="language-C">/*
 * callback when PIC0 irq status changed
 */
static void pic_irq_request(struct kvm *kvm, int level)
{
	struct kvm_pic *s = kvm-&gt;arch.vpic;

	if (!s-&gt;output)
		s-&gt;wakeup_needed = true;
	s-&gt;output = level;
}
</code></pre>
<p>さらにこの上で<code>pic_unlock</code>関数を呼び出しているが、この関数の中身が地味に重要である。
<code>wakeup_needed</code>がtrueの場合、vCPUに対して<code>kvm_vcpu_kick</code>を実行している。</p>
<pre><code class="language-C">static void pic_unlock(struct kvm_pic *s)
	__releases(&amp;s-&gt;lock)
{
	bool wakeup = s-&gt;wakeup_needed;
	struct kvm_vcpu *vcpu;
	int i;

	s-&gt;wakeup_needed = false;

	spin_unlock(&amp;s-&gt;lock);

	if (wakeup) {
		kvm_for_each_vcpu(i, vcpu, s-&gt;kvm) {
			if (kvm_apic_accept_pic_intr(vcpu)) {
				kvm_make_request(KVM_REQ_EVENT, vcpu);
				kvm_vcpu_kick(vcpu);
				return;
			}
		}
	}
}

/*
 * Kick a sleeping VCPU, or a guest VCPU in guest mode, into host kernel mode.
 */
void kvm_vcpu_kick(struct kvm_vcpu *vcpu)
{
	int me;
	int cpu = vcpu-&gt;cpu;

	if (kvm_vcpu_wake_up(vcpu))
		return;

	me = get_cpu();
	if (cpu != me &amp;&amp; (unsigned)cpu &lt; nr_cpu_ids &amp;&amp; cpu_online(cpu))
		if (kvm_arch_vcpu_should_kick(vcpu))
			smp_send_reschedule(cpu);
	put_cpu();
}
</code></pre>
<p><code>smp_send_reschedule</code>を呼び出した結果として、<code>native_smp_send_reschedule</code>関数が呼ばれる。</p>
<pre><code class="language-C">/*
 * this function sends a 'reschedule' IPI to another CPU.
 * it goes straight through and wastes no time serializing
 * anything. Worst case is that we lose a reschedule ...
 */
static void native_smp_send_reschedule(int cpu)
{
	if (unlikely(cpu_is_offline(cpu))) {
		WARN_ON(1);
		return;
	}
	apic-&gt;send_IPI(cpu, RESCHEDULE_VECTOR);
}
</code></pre>
<p>コメントにもある通り、この関数を呼び出すと別のCPUに対してIPI（Inter Process Interrupt）を発行し再スケジュールを促す。
vCPUに対して割り込みを送り、仮想マシンから強制的に<code>VMExit</code>する。そしてvCPUにスケジュールする際に割り込みが挿入されることになる。</p>
<p>さて、では実際に割り込みが挿入される処理も簡単に確認して割り込みの話を一旦終えることにしよう。
<code>KVM_RUN</code>が実行されると、以下のような処理が実行されていくようである（あくまで割り込みの挿入のみに着目しているため、そのほか膨大な処理は省略している）</p>
<pre><code>kvm_arch_vcpu_ioctl_run
 -&gt; vcpu_run
 -&gt; vcpu_enter_guest
 -&gt; inject_pending_event
 -&gt; kvm_cpu_has_injectable_intr
</code></pre>
<p><code>kvm_cpu_has_injectable_intr</code>の中で<code>kvm_cpu_has_extint</code>関数が呼ばれる。この処理は今回の場合はおそらく<code>pic_irq_request</code>で設定した<code>s-&gt;output</code>の値でreturnするため、この関数は全体として<code>return 1</code>を返す。<br />
そのため、<code>inject_pending_event</code>関数の以下の処理に差し掛かる。</p>
<pre><code class="language-C">	} else if (kvm_cpu_has_injectable_intr(vcpu)) {
		/*
		 * Because interrupts can be injected asynchronously, we are
		 * calling check_nested_events again here to avoid a race condition.
		 * See https://lkml.org/lkml/2014/7/2/60 for discussion about this
		 * proposal and current concerns.  Perhaps we should be setting
		 * KVM_REQ_EVENT only on certain events and not unconditionally?
		 */
		if (is_guest_mode(vcpu) &amp;&amp; kvm_x86_ops-&gt;check_nested_events) {
			r = kvm_x86_ops-&gt;check_nested_events(vcpu, req_int_win);
			if (r != 0)
				return r;
		}
		if (kvm_x86_ops-&gt;interrupt_allowed(vcpu)) {
			kvm_queue_interrupt(vcpu, kvm_cpu_get_interrupt(vcpu),
					    false);
			kvm_x86_ops-&gt;set_irq(vcpu);
		}
	}
</code></pre>
<p>結果的に<code>kvm_x86_ops-&gt;set_irq(vcpu)</code>が呼ばれる。これはコールバック関数として<code>vmx_inject_irq</code>が実行されることになる。
この処理で、<code>VMCS</code>（<code>Virtual Machine Control Structure</code>）に<code>VMX_ENTRY_INTR_INFO_FIELD</code>を設定することで割り込みを挿入している。
<code>VMCS</code>についての説明を行なっていないが、この話を始めるとハイパーバイザーの実装についての話が必要になってくるのでここでは省略する。
将来的に、補足情報としてドキュメントに追記するかもしれない。</p>
<p>長くなったが以上がPICを例にとった割り込み処理の流れである。</p>
<h4 id="toyvmm-serial-console"><a class="header" href="#toyvmm-serial-console">ToyVMM serial console</a></h4>
<p>さて、この辺りで割り込みに関する探索を一旦切り上げて、ToyVMMの実装の話に戻ろう。
これまでの話を踏まえながら、ToyVMM側ではどのような処理を実行しており、それが裏ではどのような処理として実行されているかを整理する。
ToyVMMの中で、先に紹介した<code>register_irqfd</code>を実施する前に実は以下のような処理を行なっていた。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>vm.setup_irqchip().unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>この関数は薄いwrapperになっており、内部的には<code>create_irq_chip</code>の呼び出しと<code>create_pit2</code>の呼び出しを行う処理になっている。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(target_arch = &quot;x86_64&quot;)]
pub fn setup_irqchip(&amp;self) -&gt; Result&lt;()&gt; {
    self.fd.create_irq_chip().map_err(Error::VmSetup)?;
    let pit_config = kvm_pit_config {
        flags: KVM_PIT_SPEAKER_DUMMY,
        ..Default::default()
    };
    self.fd.create_pit2(pit_config).map_err(Error::VmSetup)
}
<span class="boring">}
</span></code></pre></pre>
<p>ここで重要なのは、<code>create_irq_chip</code>関数である。これは内部的には<code>KVM_CREATE_IRQCHIP</code>のAPIを叩いており、これによって先に話した通り、割り込みコントローラの初期化、IRQ Routingの初期化などを実施する。
上記セットアップ済みのGuest VMに対して、先に説明した<code>register_irqfd(&amp;com_evt_1_3, 4)</code>を実行することで<code>KVM_IRQFD</code> APIを叩き、先に説明した<code>kvm_irqfd_assign</code>などの処理が実施されるため、割り込みハンドラの設定などが行われる。
これで、ToyVMMからKVM APIを利用した割り込み関係のセットアップは完了である。</p>
<p>さて、改めて<code>com_evt_1_3</code>のからの割り込みについて確認してみよう。割り込みの一端は上記で見た通り<code>register_irqfd</code>によって<code>GSI=4</code>とともにKVM側に受け渡しているため、もう一端から発行されたwriteをGuest VMへのCOM1ポートへのinterruptとして取り扱うことになる。一方、問題の<code>com_evt_1_3</code>のもう一端はSerial Deviceに渡してあるためSerial Device側で実行されるeventfdへのwrite（<code>Serial::write</code>による書き込み処理後や、後述する<code>Serial::enqueue_raw_byte</code>による呼び出しで発生する）が具体的な割り込みのトリガである。
つまり、通常のサーバとSerial Deviceが行うやりとりと同じような形で、Guest VMとSoftware実装のSerial Deviceがやりとりをするような構成を構築できる。</p>
<p>また、Serial Consoleを表現するために、今回はSerial Deviceのoutputに該当する書き込み先はstdoutに設定している。そのため、<code>KVM_EXIT_IO_OUT</code>をハンドルした際の<code>THR</code>への書き込みがstdoutへの書き込みへと渡っていき、結果として標準出力にコンソールメッセージが出力され、目的のSerial Consoleとしての機能が実現される。</p>
<h4 id="標準入力でguest-vmを操作する"><a class="header" href="#標準入力でguest-vmを操作する">標準入力でGuest VMを操作する。</a></h4>
<p>最後に標準入力の内容をGuest VMに反映させてGuest VMを操作できるようにしたい。
<a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a>が提供する<code>Serial</code>構造体には、<a href="https://docs.rs/vm-superio/0.1.1/vm_superio/serial/struct.Serial.html#method.enqueue_raw_bytes"><code>enqueue_raw_bytes</code></a>というヘルパー関数が存在し、これを利用するとあまり細かいレジスタ操作や割り込みを考えずにGuest VMに対してデータを送信することができる（関数の実装がこれらの処理をうまく実施してくれる）
あとはこれを標準入力から受け取った入力をプログラムで読み取って、このメソッドにそのまま引き渡してあげるようにすると目的の操作が達成できる。</p>
<p>標準入力をraw modeへと切り替えて、メインスレッドでpollingしながら標準入力を受け取ったら<code>enqueue_raw_bytes</code>でGuest VMに対してその入力内容を送信する。
Guest VMはvCPUごとに別スレッドを起動して処理させているため、メインスレッドで標準入力をpollingすることによるGuest VMの処理への影響はない。</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let stdin_handle = io::stdin();
let stdin_lock = stdin_handle.lock();
stdin_lock
    .set_raw_mode()
    .expect(&quot;failed to set terminal raw mode&quot;);
let ctx: PollContext&lt;Token&gt; = PollContext::new().unwrap();
ctx.add(&amp;exit_evt, Token::Exit).unwrap();
ctx.add(&amp;stdin_lock, Token::Stdin).unwrap();
'poll: loop {
    let pollevents: PollEvents&lt;Token&gt; = ctx.wait().unwrap();
    let tokens: Vec&lt;Token&gt; = pollevents.iter_readable().map(|e| e.token()).collect();
    for &amp;token in tokens.iter() {
        match token {
            Token::Exit =&gt; {
                println!(&quot;vcpu requested shutdown&quot;);
                break 'poll;
            }
            Token::Stdin =&gt; {
                let mut out = [0u8; 64];
                tx.send(true).unwrap();
                match stdin_lock.read_raw(&amp;mut out[..]) {
                    Ok(0) =&gt; {
                        println!(&quot;eof!&quot;);
                    }
                    Ok(count) =&gt; {
                        stdio_serial
                            .lock()
                            .unwrap()
                            .serial
                            .enqueue_raw_bytes(&amp;out[..count])
                            .expect(&quot;failed to enqueue bytes&quot;);
                    }
                    Err(e) =&gt; {
                        println!(&quot;error while reading stdin: {:?}&quot;, e);
                    }
                }
            }
            _ =&gt; {}
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>ナイーブな実装でありあまり特別なことは行っていないので特に説明すべきことはない。<br />
単純だが以上で目的の動作が達成できる。</p>
<h2 id="check-uart-request-in-booting-linux-kernel"><a class="header" href="#check-uart-request-in-booting-linux-kernel">Check UART request in booting linux kernel.</a></h2>
<p>これまでSerial UARTのソフトウェア実装の内容とToyVMM内部での利用方法について記載した。<br />
これは実際にうまく動作するが、やはりLinux Kernel起動時のUARTのやりとりを確認してみたいところである。
幸い、VMMの仕組み上、<code>KVM_EXIT_IO</code>をハンドルする必要があるため、このハンドリング処理にデバッグコードを仕込むことでシリアルポートに送付された全てのリクエストを盗み見ることができる。<br />
ただし全ての内容を確認するのは現実的ではないので、一部だけ簡単に確認してみようと思う。</p>
<p>デバッグするために差し込んだコードの説明はここでは行わない。適切な処理箇所にデバッグコードを入れるだけのため非常に単純である。<br />
以降では、シリアルポートへのリクエストに対して、分かりやすいように以下のような3種類の書式に従って注釈をつけている。</p>
<pre><code class="language-bash">[書式1 - Read]
r($register) = $data
  - Description

・ r           = Read operation
・ $register   = デバイスのアドレス(0x3f8)を利用して計算したoffsetに対応するレジスタ
・ $data       = $registerから読み出したデータ
・ Description = 説明文

[書式2 - Write]
w($register = $data)
  - Description

・ w           = Write operation
・ $register   = デバイスのアドレス(0x3f8)を利用して計算したoffsetに対応するレジスタ
・ $data       = $registerの値に書き込むデータ
・ Description = 説明文


[書式3 - Write (character)]
w(THR = $data = 0xYY) -&gt; 'CHAR'

・ w(THR ...)  = Write operation to THR
・ $data       = $registerの値に書き込むbinaryデータ
・ 0xYY        = $dataをhexに変換したもの
・ 'CHAR'      = 0xYYをASCIIコード表に基づきcharacterに変換したもの
</code></pre>
<p>さて、以下は少し長いがOS起動時の<code>0x3f8 (COM1)</code>のレジスタに対してのリクエストを上記の書式に従ってわかりやすく書き表したものである。</p>
<pre><code class="language-bash"># 最初はbaud lateなどの初期設定を行なっている
w(IER = 0)
w(LCR = 10010011)
  - DLAB         = 1   (DLAB: DLL and DLM accessible)
  - Break signal = 0   (Break signal disabled)
  - Parity       = 010 (No parity)
  - Stop bits    = 0   (1 stop bit)
  - Data bits    = 11  (8 data bit)
w(DLL = 00001100)
w(DLM = 0)
  - DLL = 0x0C, DLM = 0x00 (Speed = 9600 bps)
w(LCR = 00010011)
  - DLAB         = 0   (DLAB : RBR, THR, and IER accessible)
  - Break signal = 0   (Break signal disabled)
  - Parity       = 010 (No parity)
  - Stop bits    = 0   (1 stop bit)
  - Data bits    = 11  (8 data bit)
w(FCR = 0)
w(MCR = 00000001)
  - Reserved            = 00
  - Autoflow control    = 0
  - Loopback mode       = 0
  - Auxiliary output 2  = 0
  - Auxiliary output 1  = 0
  - Request to send     = 0
  - Data terminal ready = 1
r(IER) = 0
w(IER = 0)

# この辺りから実際にコンソール出力をシリアルで受け取り、write（今回の場合はstdoutへのwrite）をしている様子である

# r(LSR)の内容をみて、次の文字を書いていいか判別していると思われる
r(LSR) = 01100000
  - Errornous data in FIFO         = 0
  - THR is empty, and line is idle = 1
  - THR is empty                   = 1
  - Break signal received          = 0
  - Framing error                  = 0
  - Parity error                   = 0
  - Overrun error                  = 0
  - Data available                 = 0
    - 5, 6 bitはcharacter transmitterに関わるもので、UARTが次のcharacterを受付可能かの識別に利用する
    - 5, 6 bitが立っていれば、新たなcharacterを受け付けることができる
      - Bit 6 = '1' means that all characters have been transmitted
      - Bit 5 = '1' means that UARTs is capable of receiving more characters

# 上記で、次の文字のwriteを受け付けているので、outputしたい文字を書く。
w(THR = 01011011 = 0x5b) -&gt; '['

# 以降、これの繰り返しを行っている
r(LSR) = 01100000
w(THR = 00100000 = 0x20) -&gt; ' '
# 上記の処理があと3回続く
r(LSR) = 01100000
w(THR  = 00110000 = 0x30) -&gt; '0'
r(LSR) = 01100000
w(THR  = 00101110 = 0x2e) -&gt; '.'
r(LSR) = 01100000
w(THR  = 00110000 = 0x30) -&gt; '0'
# 上記の処理があと5回続く
r(LSR) = 01100000
w(THR  = 01011101 = 0x5d) -&gt; ']'
r(LSR) = 01100000
w(THR  = 00100000 = 0x20) -&gt; ' '
r(LSR) = 01100000
w(THR  = 01001100 = 0x4c) -&gt; 'L'
r(LSR) = 01100000
w(THR  = 01101001 = 0x69) -&gt; 'i'
r(LSR) = 01100000
w(THR  = 01101110 = 0x6e) -&gt; 'n'
r(LSR) = 01100000
w(THR  = 01110101 = 0x75) -&gt; 'u'
r(LSR) = 01100000
w(THR  = 01111000 = 0x78) -&gt; 'x'
r(LSR) = 01100000
w(THR  = 00100000 = 0x20) -&gt; ' '
r(LSR) = 01100000
w(THR  = 01110110 = 0x76) -&gt; 'v'
r(LSR) = 01100000
w(THR  = 01100101 = 0x65) -&gt; 'e'
r(LSR) = 01100000
w(THR  = 01110010 = 0x72) -&gt; 'r'
r(LSR) = 01100000
w(THR  = 01110011 = 0x73) -&gt; 's'
r(LSR) = 01100000
w(THR  = 01101001 = 0x69) -&gt; 'i'
r(LSR) = 01100000
w(THR  = 01101111 = 0x6f) -&gt; 'o'
r(LSR) = 01100000
w(THR  = 01101110 = 0x6e) -&gt; 'n'
r(LSR) = 01100000
w(THR  = 00100000 = 0x20) -&gt; ' '
r(LSR) = 01100000
w(THR  = 00110100 = 0x34) -&gt; '4'
r(LSR) = 01100000
w(THR  = 00101110 = 0x2e)-&gt; '.'
r(LSR) = 01100000
w(THR  = 00110001 = 0x31) -&gt; '1'
r(LSR) = 01100000
w(THR  = 00110100 = 0x34) -&gt; '4'
r(LSR) = 01100000
w(THR  = 00101110 = 0x2e) -&gt; '.'
r(LSR) = 01100000
w(THR  = 00110001 = 0x31) -&gt; '1'
r(LSR) = 01100000
w(THR  = 00110111 = 0x37) -&gt; '7'
r(LSR) = 01100000
w(THR  = 00110100 = 0x34) -&gt; '4'
r(LSR) = 01100000
w(THR  = 00100000 = 0x20) -&gt; ' '
r(LSR) = 01100000
w(THR  = 00101000 = 0x28) -&gt; '('
r(LSR) = 01100000
w(THR  = 01000000 = 0x40) -&gt; '@'
w(LSR) = 01100000
r(THR  = 00110101 = 0x35) -&gt; '5'
r(LSR) = 01100000
w(THR  = 00110111 = 0x37) -&gt; '7'
r(LSR) = 01100000
w(THR  = 01100101 = 0x65) -&gt; 'e'
r(LSR) = 01100000
w(THR  = 01100100 = 0x64) -&gt; 'd'
r(LSR) = 01100000
w(THR  = 01100101 = 0x65) -&gt; 'e'
r(LSR) = 01100000
w(THR  = 01100010 = 0x62) -&gt; 'b'
r(LSR) = 01100000
w(THR  = 01100010 = 0x62) -&gt; 'b'
r(LSR) = 01100000
w(THR  = 00111001 = 0x39) -&gt; '9'
r(LSR) = 01100000
w(THR  = 00111001 = 0x39) -&gt; '9'
r(LSR) = 01100000
w(THR  = 01100100 = 0x64) -&gt; 'd'
r(LSR) = 01100000
w(THR  = 01100010 = 0x62) -&gt; 'b'
r(LSR) = 01100000
w(THR  = 00110111 = 0x37) -&gt; '7'
r(LSR) = 01100000
w(THR  = 00101001 = 0x29) -&gt; ')'

# 上記の出力を並べると以下のようになる。  
[    0.000000] Linux version 4.14.174 (@57edebb99db7)

# これはOSブート時に出力される一行目の内容と一致していることがわかる
</code></pre>
<p>当然ながらLinux起動時のUART requestはまだまだ続き、かつ上記に示すような単純な出力以外の処理も行われるが、ここではこれ以上の確認は行わないので気になる方は各々確認してほしい。</p>
<h2 id="reference"><a class="header" href="#reference">Reference</a></h2>
<ul>
<li><a href="https://www.lammertbies.nl/comm/info/serial-uart">Serial UART information</a></li>
<li><a href="https://en.wikibooks.org/wiki/Serial_Programming/8250_UART_Programming">Wikibooks : Serial Programming / 8250 UART Programming</a></li>
<li><a href="https://github.com/rust-vmm/vm-superio">rust-vmm/vm-superio</a></li>
<li><a href="https://en.wikipedia.org/wiki/Interrupt_request_(PC_architecture)">Interrupt request(PC architecture)</a></li>
<li><a href="https://www.kernel.org/doc/html/v4.15/admin-guide/serial-console.html">Linux Serial Console</a></li>
<li><a href="https://xzpeter.org/htmls/2017_12_07_kvm_irqfd/kvm_irqfd_implementation.html">KVM IRQFD Implementation</a></li>
<li><a href="https://rkx1209.hatenablog.com/entry/2016/01/01/101456">KVMのなかみ（KVM internals）</a></li>
<li><a href="https://syuu1228.github.io/howto_implement_hypervisor/part2.html">ハイパーバイザーの作り方~ちゃんと理解する仮想化技術~ 第2回 intel VT-xの概要とメモリ仮想化</a></li>
<li><a href="https://habr.com/en/post/446312/">External Interrupts in the x86 system. Part1. Interrupt controller evolution</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="toyvmm-implememtation"><a class="header" href="#toyvmm-implememtation">ToyVMM implememtation</a></h1>
<p>これまでの話を合わせると、必要最低限の機能を保有したVMMが作成できる。<br />
このToyVMMは以下の機能を持っているシンプルなVMMである</p>
<ul>
<li>vmlinuz, initrdを利用して、Guest OSを起動できる</li>
<li>Guest OS起動後はSerial Terminalとして入出力を受け、Guestの状態確認や操作を実施することができる。</li>
</ul>
<h2 id="run-linux-kernel-"><a class="header" href="#run-linux-kernel-">Run linux kernel !</a></h2>
<p>実際にLinux Kernelを起動する</p>
<p>まずは、<code>vmlinux.bin</code>と<code>initrd.img</code>を用意します。いずれもtoyvmmのリポジトリルートに配置する。
<code>vmlinux.bin</code>は以下を参考にダウンロードする</p>
<pre><code class="language-bash"># Download vmlinux.bin
wget https://s3.amazonaws.com/spec.ccfc.min/img/quickstart_guide/x86_64/kernels/vmlinux.bin
cp vmlinux.bin &lt;TOYVMM WORKING DIRECTORY&gt;
</code></pre>
<p><code>initrd.img</code>は、<a href="https://github.com/marcov/firecracker-initrd.git">marcov/firecracker-initrd</a>を利用し、alpineのrootfsを含むinitrd.imgを作成する。</p>
<pre><code class="language-bash"># Create initrd.img
# Using marcov/firecracker-initrd (https://github.com/marcov/firecracker-initrd)
git clone https://github.com/marcov/firecracker-initrd.git
cd firecracker-initrd
bash ./build.sh
# After above commands, initrd.img file wil be located on build/initrd.img.
# So, please move it to the working directory of toyvmm.
cp build/initrd.img &lt;TOYVMM WORKING DIRECTORY&gt;
</code></pre>
<p>以上で準備完了ある。以下のコマンドを実行しGuest VMを起動してみよう！</p>
<pre><code class="language-bash">$ make run_linux
</code></pre>
<p>ここではブートシーケンスの出力については省略する。Guest VMの起動シーケンスが標準出力に表示されていくだろう。
起動が完了すると、以下のようにAlpine Linuxの画面とともにloginが要求されるため、root/rootでログインしよう.</p>
<pre><code class="language-bash">Welcome to Alpine Linux 3.15
Kernel 4.14.174 on an x86_64 (ttyS0)

(none) login: root
Password:
Welcome to Alpine!

The Alpine Wiki contains a large amount of how-to guides and general
information about administrating Alpine systems.
See &lt;http://wiki.alpinelinux.org/&gt;.

You can setup the system with the command: setup-alpine

You may change this message by editing /etc/motd.

login[1058]: root login on 'ttyS0'
(none):~#
</code></pre>
<p>素晴らしい！確かにGuest VMを起動し操作できています！
もちろん、Guest VM内部でコマンドを実行することもできます。<br />
例えば最も基本的なlsコマンドを実行した結果は以下のようになります。</p>
<pre><code class="language-bash">(none):~# ls -lat /
total 0
drwx------    3 root     root            80 Sep 23 06:44 root
drwxr-xr-x    5 root     root           200 Sep 23 06:44 run
drwxr-xr-x   19 root     root           400 Sep 23 06:44 .
drwxr-xr-x   19 root     root           400 Sep 23 06:44 ..
drwxr-xr-x    7 root     root          2120 Sep 23 06:44 dev
dr-xr-xr-x   12 root     root             0 Sep 23 06:44 sys
dr-xr-xr-x   55 root     root             0 Sep 23 06:44 proc
drwxr-xr-x    2 root     root          1780 May  7 00:55 bin
drwxr-xr-x   26 root     root          1040 May  7 00:55 etc
lrwxrwxrwx    1 root     root            10 May  7 00:55 init -&gt; /sbin/init
drwxr-xr-x    2 root     root          3460 May  7 00:55 sbin
drwxr-xr-x   10 root     root           700 May  7 00:55 lib
drwxr-xr-x    9 root     root           180 May  7 00:54 usr
drwxr-xr-x    2 root     root            40 May  7 00:54 home
drwxr-xr-x    5 root     root           100 May  7 00:54 media
drwxr-xr-x    2 root     root            40 May  7 00:54 mnt
drwxr-xr-x    2 root     root            40 May  7 00:54 opt
drwxr-xr-x    2 root     root            40 May  7 00:54 srv
drwxr-xr-x   12 root     root           260 May  7 00:54 var
drwxrwxrwt    2 root     root            40 May  7 00:54 tmp
</code></pre>
<p>お疲れ様でした。ひとまずここまで来ればminimal VMMと言って良いものではないかと思います。
とはいえ現状以下のような問題点があります</p>
<ul>
<li>serialコンソール経由でしか操作できない -&gt; virtio-netを実装したい</li>
<li>virtio-blkを実装したい</li>
<li>PCIデバイスを扱えていない</li>
</ul>
<p>実は、ToyVMMを作成し始めた個人的な目的の一つとしては以下のような目標がありました。</p>
<ul>
<li>virtualizationの理解を深める</li>
<li>virtioについて理解を深める</li>
<li>pci passthroughについて理解を深める
<ul>
<li>vfioなどの技術について詳細を知る</li>
<li>mdev/libvfio/vdpaなどの周辺技術について知る</li>
</ul>
</li>
</ul>
<p>MinimalなVMMの作成は完了しましたが、この先VMMとしてどのように成長させていくかというのは人それぞれで多くの選択肢があると思います
ToyVMMでは今後上記のようなtopicについて扱っていきたいと考えています！
ToyVMMをベースにして別の方向に拡張するというのも面白いでしょう。もしこれを読んでくれているGeekがいればぜひ挑戦してください。そしてもしよければToyVMMにもfeedbackしてくれると大変嬉しく思います。</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
                
    </body>
</html>
